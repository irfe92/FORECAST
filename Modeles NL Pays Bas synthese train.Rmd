---
title: "Synthese NL Pays Bas"
author: "Nhu-Nguyen Ngo"
date: "16 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

remplacer base_F_6P par base_NL_F
remplacer _6P par _NL
remplacer 6 pays par Pays Bas


```{r}

#Load Library
library(rpart)				  # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)			# Enhanced tree plots
library(RColorBrewer)		# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree
library(caret)		
library(ISLR)
library(leaps)

library(glmnet) # Poly, GAM
library(boot) # Poly, GAM

library(splines)

library(caTools)
library(randomForest)

library(e1071) # SVR

library(stargazer)
library(ggplot2)
library(questionr)



# sur la base centrée réduite, sans les autres variables méteo
don<-base_NL_F_cr
head(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))

# Creation de l'echantillon train 2/3 individus et test 1/3
set.seed(1)
dim<-nrow(don)
split=2/3
train=sample(dim,split*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
test=model.matrix(Y~.,data=don[-train,])# base de test
Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]
don.train=don[train,]
don.test=don[-train,]
donYX.train=donYX[train,]
donYX.test=donYX[-train,]

names(don)

```

SELECTION VARIABLES 

27 variables: Date + Temp + cosinus + sinus + day_length + teff + seuil + T00 + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays + t1 + t2 + t3 + t4 + t5 + t6 + t7

variables liées à la température : Temp + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7


REGSUBSET forward
variables sélectionnées par  MSE: 
Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t4 + t5 + t7 + month + year + day + seuil + wday + quarter + season

variables sélectionnées par BIC: 
Date + cosinus + sinus + day_length + teff + t1 + t5 + month + day + wday +  quarter + season

REGSUBSET backward
variables sélectionnées par  MSE: 
Date + Temp + cosinus + sinus + day_length + teff + t1 + t4 + t5 + t7 + month + year + day + quarter + season 

variables sélectionnées par regsubset BW BIC: 
Date + cosinus + sinus + day_length + teff + t1 + t5 + month + day + quarter + season


COMPILATION des variables sélectionnées par regsubset : 
Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t4 + t5 + t7 + month + year + day + seuil + wday + quarter + season



```{r}


```


MODELES
```{r}


# modèle linéaire simple avec que les variables significatives RL_NL_tot2
RL_NL<-lm(Y ~ cosinus + sinus + day_length + teff + T00 + t4 + month + day + lagholidays, data=don[train,])
pred_RL_NL=predict(RL_NL, newdata=don.test, se=T)
MSE_RL_NL= mean((Y.test-predict(RL_NL,don.test))^2)


# modèle linéaire simple avec que les variables significatives sélectionnée par step
RL_NL_step<-lm(Y ~ Temp + cosinus + sinus + day_length + teff + T00 + t3 + t4 + t6 + month + year + day + jc + lagholidays + leadholidays, data = don[train,])
pred_RL_NL_step = predict(RL_NL_step, newdata=don.test, se=T)
MSE_RL_NL_step= mean((Y.test-predict(RL_NL_step,don.test))^2) 


# modèle linéaire avec interaction sur Temp en ne gardant que les variables significatives
RLI_NL<-lm(Y~ teff + month + day + lagholidays + (sinus + month) *Temp, data=don[train,]) 
pred_RLI_NL=predict(RLI_NL, newdata=don.test, se=T)
MSE_RLI_NL= mean((Y.test-predict(RLI_NL,don.test))^2)


# modèle linéaire avec interaction multiples sur les variables liées à la température (Temp, teff, seuil, T00 et t1 à t7)
# en ne gardant que les variables significatives
RLI_NL_multi <-lm(Y ~ month + day + holidays + cosinus*(t5) + month*(t1 + t2), data=don.train)
pred_RLI_NL_multi=predict(RLI_NL_multi, newdata=don.test, se=T)
MSE_RLI_NL_multi= mean((Y.test-predict(RLI_NL_multi,don.test))^2)


# modèle linéaire avec interaction sur Temp (poly 2) en ne gardant que les variables significatives
RLI_NL_P2<-lm(Y ~ Date + cosinus + sinus + day_length + teff + month + year + day + jc + lagholidays + leadholidays + I(poly(Temp, 2)) + cosinus:I(poly(Temp, 2)) + sinus:I(poly(Temp, 2)) + day_length:I(poly(Temp, 2)) + teff:I(poly(Temp, 2)) + month:I(poly(Temp, 2)) + jc:I(poly(Temp, 2)), data=don[train,]) 
pred_RLI_NL_P2=predict(RLI_NL_P2, newdata=don.test, se=T)
MSE_RLI_NL_P2= mean((Y.test-predict(RLI_NL_P2,don.test))^2)


# poly sur le critère du MSE,issu de la validation hold out train/test et k_folds
POLY_NL<- lm(formula=Y~poly(X,5, raw=T), data=donYX.train)
pred_POLY_NL=predict(POLY_NL, newdata=donYX.test, se=T) # length 383
MSE_POLY_NL= mean((Y.test-predict(POLY_NL,donYX.test))^2)
length(pred_POLY_NL$fit)


# modèle spline,CV pour choisir nombre de noeuds et natural splins vs basic splines
SP_NL=lm(Y~ns(X,df=3), data=donYX.train) 
pred_SP_NL=predict(SP_NL, newdata=donYX.test, se=T)
MSE_SP_NL= mean((Y.test-predict(SP_NL,donYX.test))^2)


# modèle GAM avec les variables sélectionnées par step
GAM_NL=lm(Y~ poly(Temp, 7) + Date + cosinus + sinus + day_length + month + year + day + jc + lagholidays + leadholidays + t2 + t3 + t4 + t6, data = don.train) 
pred_GAM_NL=predict(GAM_NL, newdata=don.test, se=T)
MSE_GAM_NL= mean((Y.test-predict(GAM_NL,don.test))^2)


# # Random Forest 
RF_NL<-randomForest(Y~., mtry = 5, data=don[train,])
pred_RF_NL = predict(RF_NL, don.test)
MSE_RF_NL= mean((Y.test-predict(RF_NL,don.test))^2)


# SVR
SVR_NL = svm(Y~.,don[train,])
pred_SVR_NL = predict(SVR_NL, don.test)
MSE_SVR_NL= mean((Y.test-predict(SVR_NL,don.test))^2)



```


SYNTHESE DES MODELES objet RF et SVR pas reconnu par stargazer
```{r}

stargazer(RL_NL, RLI_NL, RLI_NL_multi, POLY_NL, SP_NL, GAM_NL, type='text', flip=TRUE, title="Results", align=TRUE, keep=c("Date"), column.labels = c("RL", "RLI", "RLI2","poly","Spline" ,"GAM"), model.names = TRUE, single.row = TRUE)

# le R² ajusté est le plus élevé pour GAM et le plus faible pour Poly et Spline
# le residual error est le plus faible pour GAM et le plus élevé pour poly et Spline
# F-stat est le plus élevé pour Spline et le plus faible pour RLI2

```



```{r}
# comparaison des MSE entre les modèles RL, RLI, Poly, Spline, GAM, SVR
MSE_tot=c(MSE_RL_NL, MSE_RLI_NL, MSE_RLI_NL_multi,MSE_POLY_NL, MSE_SP_NL,MSE_GAM_NL,MSE_RF_NL,MSE_SVR_NL)

# graphe des MSE
graph<-barplot(MSE_tot, xlab="modèles", ylab="MSE", main="MSE des modèles",las=0)
axis(1, labels=c("Reg.Lin", "RLI","RLI2" ,"Poly" ,"SPLINE","GAM", "RF", "SVR"), at = graph)

```

```{r}

# comparaison des MSE entre les modèles RL, RLI, RL2, GAM, RF
MSE_tot_r=c(MSE_RL_NL, MSE_RLI_NL, MSE_RLI_NL_multi ,MSE_GAM_NL,MSE_RF_NL)

# graphe des MSE
graph<-barplot(MSE_tot_r, xlab="modèles", ylab="MSE", main="MSE des modèles",las=0)
axis(1, labels=c("Reg.Lin", "RLI","RLI2" ,"GAM", "RF"), at = graph)

```


MSE minimal
```{r}
which.min(MSE_tot) # c'est le modèle GAM qui présente la plus petite MSE
```


graphe des valeurs prédites selon les modèles
```{r}

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles" )
lines(don.test$Date,pred_RL_NL$fit, col="purple") # length 387
lines(don.test$Date,pred_RLI_NL_multi$fit, col="cyan") # length 387
lines(don.test$Date,pred_GAM_NL$fit, col="yellow") # length 387
lines(don.test$Date, pred_SVR_NL, col="blue") # length 387
lines(don.test$Date, pred_RF_NL, col="red") # length 387
lines(don.test$Date,pred_POLY_NL$fit, col="pink") # length 387
lines(don.test$Date,pred_SP_NL$fit, col="green") # length 387

```

```{r}
# graphes avec les 3 meilleurs modèles RLI, RF, SVR
plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles 6 pays GAM(yellow), SVR(blue), RF(red)" )
points(don.test$Date,pred_RLI_NL_multi$fit, col="yellow")
lines(don.test$Date,pred_GAM_NL$fit, col="yellow")
points(don.test$Date, pred_RF_NL, col="red")

```





