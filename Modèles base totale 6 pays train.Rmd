---
title: "Modeles base totale 6 pays"
author: "Nhu-Nguyen"
date: "27 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 PACKAGES BASE ET VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

PACKAGES
```{r}

library(rpart)				  # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)			# Enhanced tree plots
library(RColorBrewer)		# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree
library(caret)		
library(ISLR)
library(leaps)

library(glmnet) # Poly, GAM
library(boot) # Poly, GAM

library(splines)

library(stargazer)
library(ggplot2)
library(questionr)

#install.packages('leaps')
#install.packages('ISLR')


```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ARBRE DE DECISION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

base et variables pour Arbre décision NON CENTREE REDUITE, sans les autres variables météo
```{r}

# sur base totale avec tous les pays, non centrée réduite
don<-base_F_6P
# head(don)
# str(don)

# definition variables Y
library(questionr)
don <- rename.variable(don, "Conso", "Y")
Y=don$Y

head(don)
str(don)


```


ARBRE DECISION K_fold avec k=10 (par défaut)
```{r}

tree_6P_total<-rpart(Y~.,data=don)
tree_6P_total
# prp(tree_6P_total)               # A fast plot													
fancyRpartPlot(tree_6P_total, main="arbre de décision 6 pays")		# A fancy plot from rattle

# rpart choisit l'arbre par validation croisée k-fold. Par défaut k=10. On peut spécifier k avec xval=k
# si xval=nrow(don), c'est un LOOCV leave one out
# on peut spécifier le nombre minimum de données dans un noeud avec minsplit=


```


sur la BASE TOTALE avec les 6 pays BE, DE, ES, FR, NL, UK
Les groupes sont d'abord répartis par pays:
- BE séparé des autres pays: 17%
- groupe UK ES FR DE=66%
- puis NL isolé: 17%

Ensuite, le deuxième critère de séparation est t3, température retardée de 3 jours (>=12)

Ensuite, c'est le mois de l'année:
- eté: Aug,Jul,Jun,May,Sep=7%
- Hiver: jan, fev, mars, avril, nov, dec=2%

Et le teff >5.1:


NB: 
- les pays BE, DE et NL que nous retiendrons pour la suite de l'étude appartiennent à 3 groupes différents
- il 'y a pas de séparation par les jours.

ARBRE DECISION plot
```{r}
plotcp(tree_6P_total) 
# graphe qui permet de choisir le nombre de feuilles qui minimise l'erreur. 
# on prend le cp correspondant pour construire l'arbre final

```

ARBRE DECISION FINAL avec k=10
```{r}
tree_6P_totalf<-rpart(Y~.,data=don, cp=0.011)
fancyRpartPlot(tree_6P_totalf, main="arbre de décision 6 pays")

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 BASE POUR LES AUTRES MODELES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


BASE CENTREE REDUITE, sans les autres variables météo
```{r}

# base totale centrée réduite, sans les variables météo
don<-base_F_6P_cr
head(don)
dim(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))


# Creation de l'echantillon train individus et test 
set.seed(1)
dim<-nrow(don.train)
partage=2/3

train=sample(dim,partage*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage

test=model.matrix(Y~.,data=don[-train,])# base de test

Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]

don.train=don[train,]
don.test=don[-train,]

donYX.train=donYX[train,]
donYX.test=donYX[-train,]


p=ncol(don) # nombre de variables explicatives
p

names(don)

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 MODELES SELECTION DE VARIABLES REGSUBSETS
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


SELECTION DE VARIABLES AVEC REGSUBSET exhaustif à éviter
```{r}

# # SELECTION EXHAUSTIVE: A EVITER car P GRAND !! (ici 27 variables trop grand)
# # Exhaustive search will be S L O W, must specify really.big=T
# # On va obtenir 2^p modeles comprenant entre une et p variables
# # par défaut, le nombre de variable est 8. Préciser le nombre de variables avec nvmax
# 
# best_full_tot=regsubsets(Y~.,data=don[train,],nvmax=p,method='exhaustive')
# 
# # choisir les meilleures variables: evaluer chacun des modeles sur le test set et calculer la MSE
# MSE_full_tot=rep(NA,p)
# for(i in 1:p){
#   coefi=coef(best_full_tot,id=i)
#   pred=test[,names(coefi)]%*%coefi
#   MSE_full_tot[i]=mean((Y.test-pred)^2)
# }
# 
# # plot les RMSE des modeles sur le training 
# # On choisit le modele qui a la RMSE la plus petite sur le test set
# plot(sqrt(MSE_full_tot),ylab='Root MSE des p modeles',pch=19,type='b')
# which.min(MSE_full_tot) # ici, c'est le modèle à 12 variables (toutes les variables)
# 
# # Pour acceder aux coefficient du modele avec la RMSE la plus petite, on appelle la fonction coeff
# # Pour acceder aux RSS des modeles, on lance la fonction summary
# coef(best_full,12)
# summary(best_full)$rss

```


SELECTION DE VARIABLES AVEC REGSUBSET forward
```{r}

# FORWARD SELECTION: NB pas assuré d'avoir le modèle optimal, mais possible si n<p

best_FW_6P=regsubsets(Y~.,data=don.train,nvmax=p,method='forward')
FW_6P_sum<-summary(best_FW_6P)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_FW_6P=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_FW_6P,id=i)
  pred=test[,names(coefi)]%*%coefi   # matrix modele et pas don.test
  MSE_FW_6P[i]=mean((Y.test-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_FW_6P),ylab='Root MSE des p modeles FW', main="Regsubset forward sur base 6 pays",pch=19,type='b')
 


```


SELECTION DE VARIABLES AVEC REGSUBSET forward résultats MSE
```{r}
which.min(MSE_FW_6P)


```


SELECTION DE VARIABLES AVEC REGSUBSET forward coef MSE
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables )
coef(best_FW_6P,12)

# variables sélectionnées par regsubset forward: day_length + seuil + t1 + t3 + t4 + t5 + Pays + month + year  

```


SELECTION DE VARIABLES AVEC REGSUBSET forward détails
```{r}
# FW_6P_sum

```


SELECTION DE VARIABLES AVEC REGSUBSET forward rss
```{r}
# # Pour acceder aux RSS des modèles, on lance la fonction summary
# FW_6P_sum$rss


```


SELECTION DE VARIABLES AVEC REGSUBSET backward
```{r}
# selection variables BACKWARD: NB pas assuré d'avoir le modèle optimal,pas possible si n<p

best_BW_6P=regsubsets(Y~.,data=don.train,nvmax=p,method='backward')
sum_BW_6P<-summary(best_BW_6P)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_BW_6P=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_BW_6P,id=i)
  pred=test[,names(coefi)]%*%coefi  # matrix modele et pas don.test
  MSE_BW_6P[i]=mean((Y.test-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_BW_6P),ylab='Root MSE des p modeles',main="Regsubset backward sur base 6 pays",pch=19,type='b') 



```


SELECTION DE VARIABLES AVEC REGSUBSET backward résultats
```{r}
which.min(MSE_FW_6P) 
# d'après le graphe, MSE quasi-stable à partir de 6

```


SELECTION DE VARIABLES AVEC REGSUBSET backward coef
```{r}

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_6P,12) 

# variables sélectionnées par regsubset backward: day_length + seuil + t1 + t3 + t5 + t7 + Pays + year  

```


SELECTION DE VARIABLES AVEC REGSUBSET MSE
```{r}
# plot des RMSE pour les modèles FW et BW

x=c(1:p)
y1=sqrt(MSE_FW_6P)
y2=sqrt(MSE_BW_6P)
plot(x, y1, type = "l", ylim = range(c(y1, y2)), xlab = "nb de variables", ylab = "root mse", main="MSE 6 pays FW (blue) et BW (red)")
lines(x, y1, col = "blue")
lines(x, y2, col = "red")


```


SELECTION DE VARIABLES AVEC REGSUBSET RSS
```{r}

# Pour acceder aux RSS des modeles, on lance la fonction summary
# summary(best_full)$rss 
# summary(best_FW_6P)$rss
# summary(best_BW_6P)$rss


```


SELECTION DE VARIABLES AVEC REGSUBSET plot BIC
```{r}

# choix des variables selon critères BIC, R² ajusté, Cp
# graphe BIC autre: “Cp”, “adjr2”, “r2". classification des valeurs de BIC selon les modèles, en haut la plus petite valeur de BIC et en noir les variables inclusent dans le modèle
# Le $R^2$ ajusté permet de déterminer à quel point le modèle ajuste vos données lorsque vous souhaitez l'ajuster en fonction du nombre de prédicteurs inclus. La valeur du $R^2$ ajusté intègre le nombre de prédicteurs dans le modèle elle donc plus adaptée pour nous aider à choisir le modèle.

# graphe BIC
plot(best_FW_6P, scale="bic", main=" BIC pour Regsubset FW 6 pays") 



```


SELECTION DE VARIABLES AVEC REGSUBSET FW plot R²
```{r}
# graphe R² ajusté
plot(best_FW_6P, scale="adjr2", main=" R² Ajuste pour Regsubset FW 6 pays")

 
```


SELECTION DE VARIABLES AVEC REGSUBSET FW plot Cp
```{r}


# graphe Cp
plot(best_FW_6P, scale="Cp", main=" Cp pour Regsubset FW 6 pays")


```


SELECTION DE VARIABLES AVEC REGSUBSET forward comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_FW_6P)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)
# names(which(reg.summary$which[min.rss,]==TRUE))
# names(which(reg.summary$which[max.adjr2,]==TRUE))
# names(which(reg.summary$which[min.cp,]==TRUE))
# names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset FW 6 pays")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

SELECTION DE VARIABLES AVEC REGSUBSET FW Bic coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_FW_6P,15) 

# variables sélectionnées par regsubset FW BIC: Date + day_length + seuil + t1 + t3 + t4 + t5 + Pays + month + year + wday + quarter


```




SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_BW_6P)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)

# names(which(reg.summary$which[min.rss,]==TRUE))
# names(which(reg.summary$which[max.adjr2,]==TRUE))
# names(which(reg.summary$which[min.cp,]==TRUE))
# names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset BW 6 pays")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


SELECTION DE VARIABLES AVEC REGSUBSET BW comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

SELECTION DE VARIABLES AVEC REGSUBSET BW Bic coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_6P,14) 

# variables sélectionnées par regsubset BW BIC: Temp + day_length + seuil + t1 + t3 + t5 + t6+ t7 + Pays + year 


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES LASSO POUR SELECTION DE VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES OLS SANS INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


On cherche à prédire la consommation (Y) en fonction des autres variables


OLS SANS INTERACTION avec toutes les variables résultats
```{r}

# OLS sans interaction sur base centrée réduite
# modèle linéaire simple sur Y, avec toutes les variables
# R² ajust 0.8642 F Stat 1002 Residual standard error: 0.3685

RL_6P_tot<-lm(Y~.,data=don.train)
RL_6P_tot_sum<-summary(RL_6P_tot)
RL_6P_tot_sum


```

OLS SANS INTERACTION avec toutes les variables résidus
```{r}
# le graphe des résidus présente une structure avec 3 groupes distincts
plot(RL_6P_tot) 

```


OLS SANS INTERACTION en ne gardant que les variables significatives
```{r}

# selection des variables significatives à la main, en en gardant que les pvalue significatives
# variables signficatives: Temp + day_length + teff + seuil + T00 + t1 + t3 + t5 + t6 + t7 + Pays + day
# R² ajust 0.8659,F Stat 462, Residual standard error assez élevé : 0.3656

RL_6P_tot1<-lm(Y~ Temp + day_length + teff + seuil + T00 + t1 + t3 + t5 + t6 + t7 + Pays + day, data=don.train)
RL_6P_tot1.sum<-summary(RL_6P_tot1)
RL_6P_tot1.sum

# teff et T00 ne sont plus significatifs

```


OLS SANS INTERACTION en ne gardant que les variables significatives
```{r}
# en enlevant teff et TOO qui ne sont plus significatifs
RL_6P_tot2<-lm(Y~ Temp + day_length + seuil + t1 + t3 + t5 + t6 + t7 + Pays + day, data=don.train)
RL_6P_tot2.sum<-summary(RL_6P_tot2)
RL_6P_tot2.sum


```


OLS SANS INTERACTION en ne gardant que les variables significatives: résidus
```{r}
# graphe résidus vs fitted encore très structurés avec 3 groupes
plot(RL_6P_tot2) 


```

OLS SANS INTERACTION step
```{r}
# selection des variables significatives avec step
# step picks the best model from the one-term-dropped models and repeats the process until no further improvement in the model can be made by dropping a term. 
# The test parameter is optional, the default criteria is "AIC". It can also take the values "F" and "LRT".
# graphe résidus vs fitted incurvé
step(RL_6P_tot, test="F")

```


OLS SANS INTERACTION modèle issu de step et plot résidus
```{r}

RL_6P_step<-lm(formula = Y ~ Date + Temp + cosinus + day_length + teff + t1 + t3 + t5 + t6 + t7 + Pays + year + jc, data = don.train)

# graphe des résidus avec une structure en trois groupes
plot(RL_6P_step)


```


OLS SANS INTERACTION synthèse
```{r}

# comparaison avec modèle linéaire issu de step
# R² ajusté step légèrement meilleur que le modèle en ne gardant directement que les  variables significative (step à 0.866 vs 0.863), mais égal à celui du modèle total
# F stat step moins élevé que RL_6P_tot2 mais supérieur au modèle total
# residual std error step moins élevé que RL_6P_tot1 mais égal modèle total. Mais il est globalement élevé pour les 3 modèles
stargazer(RL_6P_tot,RL_6P_tot2,RL_6P_step,type='text', flip=TRUE, title="Results", keep=c("Date","meteo"), column.labels = c("tot", "tot2","step"))


```


ANOVA
```{r}

# anova: the returned information for the F-test is the difference in the sum of squares between the models, the F-statistic for this difference, and the p-value for the F-statistic.
anova(RL_6P_tot,RL_6P_tot2) # la différence semble significative entre tot et tot2
anova(RL_6P_tot2,RL_6P_step) # la différence semble significative entre step et tot2


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES OLS AVEC INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

"Date"         "Y"            "Temp"         "cosinus"      "sinus"        "day_length"   "teff"         "seuil"       
 [9] "T00"          "t1"           "t2"           "t3"           "t4"           "t5"           "t6"           "t7"          
[17] "Pays"         "month"        "year"         "day"          "weekend"      "wday"         "quarter"      "season"      
[25] "holidays"     "jc"           "lagholidays"  "leadholidays"

OLS AVEC INTERACTION SIMPLE résultats
```{r}
# OLS AVEC INTERACTION entre la température et les autres variables

RLI_6P_temp<-lm(Y~(Date + cosinus + sinus + day_length + teff + seuil + T00 + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)*Temp ,data=don.train) 
RLI_6P_temp_sum<-summary(RLI_6P_temp)
RLI_6P_temp_sum

# les variables significatives sont cosinus + day_length + teff + seuil+ Pays + month + (seuil + Pays + month) *Temp

```


OLS AVEC INTERACTION SIMPLE residus
```{r}
# le graphe des résidus s'améliore mais reste encore structuré en 2 groupes
plot(RLI_6P_temp)

```

OLS AVEC INTERACTION SIMPLE avec TEMP, en ne gardant que les variables signficatives
```{r}
# modèle OLS avec interaction avec seulement les variables significatives
# les variables significatives sont cosinus + day_length + teff + seuil+ Pays + month + ( seuil + Pays + month) *Temp
# R² ajusté très faible à 0.9798, F-Stat à 7982, residuak sd error à 0.1422
RLI_6P_temp1<-lm(Y~ cosinus + day_length + teff + seuil+ Pays + month + ( seuil + Pays + month) *Temp, data=don.train) 
RLI_6P_temp1_sum<-summary(RLI_6P_temp1)
RLI_6P_temp1_sum

```


OLS AVEC INTERACTION SIMPLE vec TEMP, en ne gardant que les variables signficatives résidus
```{r}
# le graphe des résidus présente encore une structure mais qui semble moins forte
plot(RLI_6P_temp1)


```


OLS AVEC INTERACTION multiples en séparant les variables liées à la température des autres variables
```{r}

RLI_6P_temp_multi<-lm(Y~(Date + cosinus + sinus + day_length + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)* (Temp + + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7),data=don.train) 
RLI_6P_temp_multi_sum<-summary(RLI_6P_temp_multi)
RLI_6P_temp_multi_sum


```


OLS AVEC INTERACTION multiples en séparant les variables liées à la température des autres variables
```{r}
# en ne gardant que les variables significatives: cosinus + sinus + day_length + Pays + month + t5 + t6 + date*t5 + date*t6 + cosinus*(t3 + t7) + sinus*(t6 + t7) + day_length*(Temp + teff + seuil + t2 + t3) + Pays*(Temp + teff + T00 + t1 + t2 + t3 + t4 + t6 + t7) + month*(Temp + seuil + T00)
RLI_6P_temp_multi1<-lm(Y ~ cosinus + sinus + day_length + Pays + month + t5 + t6 + Date*(t5 + t6) + cosinus*(t3 + t7) + sinus*(t6 + t7) + day_length*(Temp + teff + seuil + t2 + t3) + Pays*(Temp + teff + T00 + t1 + t2 + t3 + t4 + t6 + t7) + month*(Temp + seuil + T00),data=don.train) 

RLI_6P_temp_multi1_sum<-summary(RLI_6P_temp_multi1)

RLI_6P_temp_multi1_sum

```


OLS AVEC INTERACTION multiples en séparant les variables liées à la température des autres variables
```{r}

# en ne gardant que les variables significatives: cosinus + day_length + Pays + month + t5 + t6 + Date*t5 + cosinus*t3 + sinus*t7 + day_length*(Temp + teff + seuil + t2 + t3) + Pays*(Temp + teff + T00 + t1 + t2 + t3 + t4 + t6 + t7) + month*(Temp + seuil + T00)
RLI_6P_temp_multi2 <-lm(Y ~ cosinus + day_length + Pays + month + t5 + t6 + Date*t5 + cosinus*t3 + sinus*t7 + day_length*(Temp + teff + seuil + t2 + t3) + Pays*(Temp + teff + T00 + t1 + t2 + t3 + t4 + t6 + t7) + month*(Temp + seuil + T00), data=don.train) 

RLI_6P_temp_multi2_sum<-summary(RLI_6P_temp_multi2)

RLI_6P_temp_multi2_sum

```



OLS comparaison régression linéaire sans et avec interaction
```{r}
# comparaison modèles linéaire sans et avec interaction: les stats sont meilleures pour le modèle avec interaction
# R² ajusté plus élevé pour RLI avec interaction que pour les RL sans interaction, et légèrement meilleur pour interaction multiple RLI2
# residual std error nettement plus faible pour RLI (0.141) et RL2 (0.109) que les RL sans interaction (0.37)
# F-stat plus élevé pour pour RLI (4206) que RL sans interaction (<1078)
stargazer(RL_6P_tot, RL_6P_tot2, RL_6P_step, RLI_6P_temp1, RLI_6P_temp_multi2, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("tot","tot2","step","RLI", "RLI2"))

# ainsi, pour la base avec 6 pays, la RL avec interaction semble améliorer les stats

```


OLS AVEC INTERACTION entre Temp (poly degré 2) et les autres variables
```{r}

RLI_6P_P2_tot<-lm(Y~(Date + cosinus + sinus + day_length + teff + seuil + T00 + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)*I(poly(Temp,2)),data=don.train) 
RLI_6P_P2_tot_sum<-summary(RLI_6P_P2_tot)
RLI_6P_P2_tot_sum



```

OLS AVEC INTERACTION entre Temp (poly degré 2) et les autres variables
```{r}
# les variables significatives sont cosinus + day_length + teff + seuil + Pays + month + year + lagholidays + leadholidays + (seuil + T00 +  Pays + month)*I(poly(Temp,2))

RLI_6P_P2_tot1<-lm(Y~ cosinus + day_length + teff + seuil + Pays + month + year + lagholidays + leadholidays + (seuil + T00 +  Pays + month)*I(poly(Temp,2)), data=don.train) 
RLI_6P_P2_tot1_sum<-summary(RLI_6P_P2_tot1)
RLI_6P_P2_tot1_sum

```


comparaison modèles linéaire avec interaction simple sur toutes les variables, avec seulement les variables significatives
```{r}
# faible hausse du R² ajusté de 0.98 à 0.984
# faible  baisse du Residual std error de 0.139 à 0.125
# hausse de F stat de 4206 (RLI_6P_temp1) à 4621
stargazer(RLI_6P_temp1,RLI_6P_multi, RLI_6P_P2_tot1 ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RLI","RLI multi", "RLI P2"))


```

Graphes modèles RL et RLI
```{r}
pred_RL_6P_tot1=predict(RL_6P_tot1, newdata=don.test, se=T)
pred_RLI_6P_temp1=predict(RLI_6P_temp1, newdata=don.test, se=T)
pred_RLI_6P_P2_tot1=predict(RLI_6P_P2_tot1, newdata=don.test, se=T)
pred_RLI_6P_multi2=predict(RLI_6P_multi2, newdata=don.test, se=T)

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RL et RLI 6 PAYS" )
lines(don.test$Date,pred_RL_6P_tot1$fit, col="blue")
lines(don.test$Date,pred_RLI_6P_temp1$fit, col="red")
lines(don.test$Date,pred_RLI_6P_P2_tot1$fit, col="green")

plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RL sur 6 PAYS" )  # les valeurs extrèmes ne sont pas bien prédites
lines(don.test$Date,pred_RL_6P_tot1$fit, col="blue")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI simple sur 6 PAYS" )
lines(don.test$Date,pred_RLI_6P_temp1$fit, col="red")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RLI poly2 sur 6 PAYS" )  # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_6P_P2_tot1$fit, col="green")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI multiple sur 6 PAYS" )   # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_6P_multi2$fit, col="yellow")

```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES POLYNOMIAL
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

POLYNOME base et variables sur la base centrée réduite

Modèles avec cible=Conso en fonction d'un polynome sur Temp

POLYNOME détermination du degré par cross validation hold out train / test
```{r}

# # CROSS VALIDATION HOLD OUT TRAIN/TEST
# set.seed(1)
# dim<-nrow(donYX)
# train<-sample(dim,2*dim/3)
# donYX.train=donYX[train,]
# donYX.test=donYX[-train,]
# Y.test=Y[-train]

d=20 # degré max de polynome à tester
MSE_poly_6P=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX.train)
  MSE_poly[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_poly),ylab="MSE", main='Root MSE 6 pays selon le degré de polynome',pch=19,type='b')


```

POLYNOME détermination du degré par cross validation hold out resultats
```{r}
which.min(MSE_poly) 

```


POLYNOME détermination du degré par cross validation hold out modèle retenu et résidus
```{r}

#modèle retenu par hold out
poly10_6P_tot<- lm(formula=Y~poly(X,10, raw=T), data=donYX.train)
poly10_6P_tot_sum<- summary(poly10_6P_tot)
MSE_poly10_6P_tot= mean((Y.test-predict(poly10_6P_tot,donYX.test))^2)

# le graphe des résidus vs fitted a toujours une structure en 3 groupes
plot(poly10_6P_tot)

```


POLYNOME détermination du degré par cross validation K-fold
```{r}


# CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
POLY_cv.error_6P=as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX.train)
POLY_cv.error_6P[i]<-cv.glm(donYX.test,glm.fit,K=10)$delta[1]
}

plot(POLY_cv.error_6P, pch=19,type='b')

```

POLYNOME détermination du degré par cross validation K-fold résulats
```{r}
which.min(POLY_cv.error_6P) 

```



POLYNOME détermination du degré par cross validation K-fold modèle retenu et résidus
```{r}

#modèle retenu par K_fold
poly1_6P_tot<- lm(formula=Y~poly(X,1, raw=T), data=donYX.train)
MSE_poly1_6P_tot= mean((Y.test-predict(poly1_6P_tot,donYX.test))^2)

# le graphe des résidus vs fitted a toujours une structure en 3 groupes
plot(poly1_6P_tot)

```


POLYNOME détermination du degré par cross validation LOOCV à éviter, trop long
```{r}
# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
# library(boot)
# d=10 # degré de polynome 
# cv.error=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~poly(X,i),data = donYX) 
#   cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }
# plot(cv.error, type="l") 

```


POLYNOME comparaison RL et poly
```{r}

# COMPARAISON DES MODELES
#modèle retenu par hold out
poly10_6P_tot<- lm(formula=Y~poly(X,10, raw=T), data=donYX.train)
poly10_6P_tot_sum<- summary(poly10_6P_tot)
MSE_poly10_6P_tot= mean((Y.test-predict(poly10_6P_tot,donYX.test))^2)

#modèle retenu par K_fold
poly1_6P_tot<- lm(formula=Y~poly(X,1, raw=T), data=donYX.train)
poly1_6P_tot_sum<- summary(poly1_6P_tot)
MSE_poly1_6P_tot= mean((Y.test-predict(poly1_6P_tot,donYX.test))^2)

#comparaison des modèles linéaire total avec poly
# R² ajusté à 0.087 pour poly10 et 0.086 pour poly6, plus petit par rapport au modèle linéaire (0.86)
# résidual sdt error beaucoup plus élevé que dans RL (0.374), poly10 (0.955) poly 6(0.956)
# F stat plus faible pour les poly(<67) que pour modèle linéaire (3036)
stargazer(RL_6P_tot1,poly10_6P_tot, poly1_6P_tot, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","poly10", "poly1"))




```

```{r}
# en comparant les MSE, 
diff_POLY_6P_tot=MSE_poly10_6P_tot - MSE_poly1_6P_tot
diff_POLY_6P_tot # MSE_poly10_6P_tot < MSE_poly6_6P_tot
# 
# nous retiendrons poly10 sur le critère du MSE
POLY_6P<- lm(formula=Y~poly(X,10, raw=T), data=donYX.train)
POLY_6P_sum<- summary(POLY_6P)
MSE_POLY_6P_tot= mean((Y.test-predict(POLY_6P,donYX.test))^2)


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES SPLINES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

SPLINE Conso en fonction de la température

SPLINES sur base centrée réduite et variables

```{r}

# don<-base_F_6P_cr
# don <- rename.variable(don, "Conso", "Y")
# 
# #creation des variables Y et X
# Y=don$Y 
# X=don$Temp
# donYX=data.frame(cbind(Y,X))
# str(donYX)
# nrow(donYX)
# length(X)
# length(Y)
# 
# # Creation de l'echantillon train 2/3 individus et test 1/3
# set.seed(1)
# dim<-nrow(don)
# train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
# test=model.matrix(Y~.,data=don[-train,])# base de test
# Y.train=Y[train]
# X.train=X[train]
# Y.test=Y[-train]
# X.test=X[-train]
# don.train=don[train,]
# don.test=don[-train,]
# donYX.train=donYX[train,]
# donYX.test=donYX[-train,]

```


SPLINES choix du degré de liberté/noeuds par CV hold out pour natural splines
```{r}

# CHOIX DU DEGRE DE LIBERTE df (et donc du nombre de noeuds) par cross validation HOLD OUT TRAIN/TEST 
# l'option df produit des splines avec des noeuds placés sur les quantiles
# on n'obtient pas les mêmes noeuds en bs et ns, pour un même degré de liberté
# attr() pour avoir les noeuds issus de df

# # noeuds avec basic splines
# attr(bs(X,df=3),"knots") # pas de noeud
# attr(bs(X,df=4),"knots") # un seul noeud à 50% = 2 intervalles + 2 frontières min et max
# attr(bs(X,df=5),"knots") # 2 noeuds à 1/3 et 2/3 = 3 intervalles + 2 frontières min et max
# attr(bs(X,df=6),"knots") # 3 noeuds à 25%, 50% et 75% = 4 intervalles + 2 frontières min et max
# 
# # noeuds avec natural splines
# attr(ns(X,df=1),"knots") #  pas de noeud
# attr(ns(X,df=2),"knots") #  un seul noeud à 50%
# attr(ns(X,df=3),"knots") #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
# attr(ns(X,df=4),"knots") #  3 noeuds à 25% (5.8), 50% (10.2),75% (15.5)
# attr(ns(X,df=5),"knots") #  4 noeuds à 20% (4.9), 40% (8.5),60% (12.2), 80% (16.5)


# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
MSE_SP_6P_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(X,df=i), data=donYX.train)
  MSE_SP_6P_ns[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_SP_6P_ns),ylab="MSE", main='Root MSE 6 pays selon le degré de liberté du spline',pch=19,type='b')


```


SPLINES choix du degré de liberté/noeuds résultats
```{r}

which.min(MSE_SP_6P_ns)
# c'est le modèle avec un degré de liberté 8 qui a la plus petite MSE

```

SPLINES choix du degré de liberté: nombre de noeuds
```{r}
attr(ns(X,df=8),"knots")

```


SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}


# pour basic spline, recherche degré df qui minimise le MSE 

DF=15 # df max à tester
MSE_SP_6P_bs=rep(0,DF)
for(i in 4:DF) {
  model <- lm(Y~bs(X,df=i), data=donYX.train)
  MSE_SP_6P_bs[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_SP_6P_bs),ylab="MSE", main='Root MSE selon le degré de liberté du spline',pch=19,type='b')

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines résultat
```{r}
which.min(MSE_SP_6P_bs)+3 # le test démarre à df=4

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}
attr(ns(X,df=4),"knots")
 

```


SPLINES choix entre natural splines et basic splines par CV hold out 
```{r}

# CHOIX ENTRE BASIC SPLINES ET NATURAL SPLINES, celui qui minimise le MSE

#natural splines ns
# ns() ne marche que si les variables sont numériques. Les variables qualitatives seront transformées en dummy variables
attr(ns(X,df=8),"knots")  # 7 noeuds à12.5% 25% 37.5% 50% 62.5% 75% 87.5%
fit_ns_6P_tot=lm(Y~ns(X,df=3), data=donYX.train)
plot(fit_ns_6P_tot)
MSE_SP_6P_ns <- mean((Y.test-predict(fit_ns_6P_tot,donYX.test))^2)

#basic splines bs: on prend le df qui donne les mêmes noeuds que natural spline 
attr(bs(X,df=4),"knots") # 3 noeuds
fit_bs_6P_tot=lm(Y~bs(X,df=5), data=donYX.train)
plot(fit_bs_6P_tot)
MSE_SP_6P_bs <- mean((Y.test-predict(fit_bs_6P_tot,donYX.test))^2)


diff_6P_bs_ns=MSE_SP_6P_bs-MSE_SP_6P_ns
diff_6P_bs_ns # MSE_SP_6P_bs < MSE_bs_6P_ns 
# => avec les mse, on choisirait bs


```


SPLINES choix entre natural splines et basic splines par CV hold out comparaison
```{r}


#comparaison des stats des résultats entre basic et natural splines
stargazer(fit_bs_6P_tot, fit_ns_6P_tot, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("bs", "ns"))
# => avec les stat des modèles, choix de ns car F-stat plus grand qu bs. Le R² ajusté et residual std error sont égaux entre ns et bs

# les stats du modèles de spline ne sont pas bonnes: R² très faible, residual error très élevé
# il faudrait essayer Régression multivariée par spline adaptative. Mais package Polymars n'est plus accessible


```


SPLINES choix entre natural splines et basic splines par CV hold out résultats et résidus
```{r}

# modèle spline sur toute la base BE
# en minimisant MSE, on retient spline bs avec df=1 trouvé par cross validation hold out
SP_6P=lm(Y~bs(X,df=4), data=donYX.train) #  3 noeuds 
pred_SP_6P=predict(SP_6P, newdata=donYX.test, se=T)
MSE_SP_6P= mean((Y.test-predict(SP_6P,donYX.test))^2)
plot(SP_6P) # graphe des résidus vs fitted a toujours une structure en 3 groupes


```


SPLINES graphes et smooting splines
```{r}

# graphes de conso vs température
plot(X.test,Y.test, xlab = "Temp", ylab="Conso")
points (X.test,pred_SP_6P$fit, col="blue") 

# graphe de conso vs date
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="Spline 6 pays, fit (bleu)" )
lines(don.test$Date,pred_SP_6P$fit, col="blue") 


# SMOOTHING SPLINE
SM_6P=smooth.spline(Y.test,X.test,df=3) # on spécifie df=6 et le lambda est déterminé de sorte à obtenir df=6
SM_6P_cv=smooth.spline(Y.test,X.test,cv=TRUE) # lambda est choisi par cross validation

plot(SM_6P, main="smooth spline") 
plot(SM_6P_cv, main="cv") 

# #comparaison des résultats entre Spline df3, smoothing spline df3 et smoothing spline avec lambda par cv
# stargazer(SP_6P, SM_6P, SM_6P_cv, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("SP", "SM", "SMcv"), model.names = TRUE)
```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES GAM
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



GAM base centrée réduite et variables
```{r}

# library(splines) 
# library(questionr)
# 
# don<-base_F_6P_cr
# don <- rename.variable(don, "Conso", "Y")
# 
# #creation des variables Y et X
# Y=don$Y 
# X=don$Temp
# donYX=data.frame(cbind(Y,X))
# str(donYX)
# nrow(donYX)
# length(X)
# length(Y)
# 
# # data set train et test
# set.seed(1)
# d<-nrow(donYX)
# train<-sample(d,2*d/3)
# # test=donYX[-train,]
# 
# # Creation de l'echantillon train 2/3 individus et test 1/3
# set.seed(1)
# dim<-nrow(don)
# train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
# test=model.matrix(Y~.,data=don[-train,])# base de test
# Y.train=Y[train]
# X.train=X[train]
# Y.test=Y[-train]
# X.test=X[-train]
# don.train=don[train,]
# don.test=don[-train,]
# donYX.train=donYX[train,]
# donYX.test=donYX[-train,]


```

GAM détermination du polynome par CV K-fold avec toutes les variables : 

message erreur prediction from a rank-deficient fit may be misleading

```{r}
# library(boot)
# en enlevant les variables liées à la température: + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7

d=15 # degré de poly à tester
GAM_cv.error_6P=rep(0,d)
for (i in 1:d) { 
  glm.fit= glm(Y~ poly(Temp,i) + Date + cosinus + sinus + day_length + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7, data = don) 
  GAM_cv.error_6P[i]=cv.glm(don, glm.fit, K=10 )$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(GAM_cv.error_6P, main="GAM 6 pays cv.error selon degré polynome",pch=19,type='b') 


```

GAM détermination du polynome par CV K-fold résultats
```{r}
which.min(GAM_cv.error_6P) 

```

GAM détermination du polynome par CV K-fold modèle retenu 
```{r}

# modèle GAM avec polynôme sur la température 

GAM_6P=glm(Y~ poly(Temp,7) + Date + cosinus + sinus + day_length + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7, data = don) 

pred_GAM_6P=predict(GAM_6P, newdata=don.test, se=T)

summary(GAM_6P)


```

GAM détermination du polynome par CV K-fold modèle retenu en ne gardant que les variables significatives
```{r}

GAM_6P_1=glm(Y~ poly(Temp,7) + cosinus + day_length + Pays + T00 + t1 + t2 + t3 + t4 + t5 + t6, data = don) 

summary(GAM_6P_1)

```


GAM détermination du polynome par CV K-fold modèle retenu en ne gardant que les variables significatives
```{r}

GAM_6P_2= glm(Y~ poly(Temp,7) + cosinus + day_length + Pays + T00 + t1 + t3 + t5 + t6, data = don) 
MSE_GAM_6P_2= mean((Y.test-predict(GAM_6P_2,don.test))^2)
summary(GAM_6P_2)

```


GAM résidus
```{r}
# le graphe des résidus présente toujours une structure en 3 groupes
plot(GAM_6P_2) 


```



GAM détermination du polynome par CV K-fold avec compilation des variables sélectionnées par regsubset
```{r}

# détermination du degré du polynome par cross validation, 
# il y a trop de variables,le modèle ne tourne pas, il faut réduire
# en utilisant les variables sélectionnées par regsubset: Date + day_length + Pays + month + year + wday + quarter
# sans les variales liées à la température: (seuil + t1 + t3 + t4 + t5 + t6 + t7)

library(boot)
d=15 # degré de poly à tester
GAM_cv.error_6P_reg=rep(0,d)
for (i in 1:d) { 
  glm.fit=glm(Y~ poly(Temp,i) + Date + day_length + Pays + month + year + wday + quarter + seuil + t1 + t3 + t4 + t5 + t6 + t7, data = don) 
  GAM_cv.error_6P_reg[i]=cv.glm(don,glm.fit, K=10)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(GAM_cv.error_6P_reg, main="GAM 6 pays cv.error selon degré polynome",pch=19,type='b') 

```


GAM détermination du polynome par CV K-fold  avec compilation des variables sélectionnées par regsubset résultats
```{r}
which.min(GAM_cv.error_6P_reg) 

```

GAM détermination du polynome par CV K-fold avec compilation des variables sélectionnées par regsubset modèle retenu 
```{r}

# modèle GAM avec polynôme degré 1 sur la température 

GAM_6P_reg=lm(Y~ poly(Temp,7) + Date + day_length + Pays + month + year + wday + quarter + seuil + t1 + t3 + t4 + t5 + t6 + t7, data = don.train) 

summary(GAM_6P_reg)


```

GAM détermination du polynome par CV K-fold avec compilation des variables sélectionnées par regsubset modèle retenu 
```{r}
# en enlevant les variables non significatives
GAM_6P_reg1=lm(Y~ poly(Temp,7) + day_length + Pays + month + wday + t1 + t3 + t4 + t5 + t6, data = don.train) 
# pred_GAM_6P_reg=predict(GAM_6P_reg, newdata=don.test, se=T)
summary(GAM_6P_reg1)

MSE_GAM_6P_reg1= mean((Y.test-predict(GAM_6P_reg1,don.test))^2)

```


GAM avec compilation des variables sélectionnées par regsubset  résidus
```{r}
# le graphe des résidus présente toujours une structure en 3 groupes
plot(GAM_6P_reg1) 


```



GAM comparaison des modèles 
```{r}

GAM_6P_2= glm(Y~ poly(Temp,7) + cosinus + day_length + Pays + T00 + t1 + t3 + t5 + t6, data = don.train) 
MSE_GAM_6P_2= mean((Y.test-predict(GAM_6P_2,don.test))^2)

GAM_6P_reg1=lm(Y~ poly(Temp,7) + day_length + Pays + month + wday + t1 + t3 + t4 + t5 + t6, data = don.train) 
MSE_GAM_reg1= mean((Y.test-predict(GAM_6P_reg1,don.test))^2)

diff=MSE_GAM_6P_2-MSE_GAM_6P_reg1
diff 

which.min(c(MSE_GAM_6P_2, MSE_GAM_6P_reg1)) 

```

GAM modèle retenu
```{r}
GAM_6P=lm(Y~ poly(Temp,7) + cosinus + day_length + Pays + T00 + t1 + t3 + t5 + t6, data = don.train) 

```


GAM valeurs prédites
```{r}
pred_GAM_6P=predict(GAM_6P, newdata=don.test, se=T)
# graphe des valeurs prédites par GAM sur la Belgique
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="GAM" )
lines(don.test$Date,pred_GAM_6P$fit, col="yellow")


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES RANDOM FOREST
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


RANDOM FOREST base et variables
```{r}

# RANDOM FOREST BELGIQUE
# on peut régler deux éléments : 
# ntree: le nombre d’arbres construits par l’algorithme 
# mtry: le nombre de variables testées à chaque division. 
# la valeur par défaut de mtry correspond à la racine carrée du nombre de variables

library(caTools)
library(randomForest)
library(ggplot2)
library(questionr)

don<-base_F_6P_cr
head(don)
dim(don)
sqrt(ncol(don)) # = valeur mtry par défaut soit 5 pour base BE

# création de variable Y
don <- rename.variable(don, "Conso", "Y")
head(don)


# train & test datasets
#éviter les valeurs manquantes
set.seed(1)
dim<-nrow(don)
index<-sample(dim,2*dim/3)
don.train=don[index,]
don.test=don[-index,]
Y.test=Y[-index]

```

RANDOM FOREST modelisation
```{r}

# modelisation sur train, par défaut ntree=500
RF_6P<-randomForest(Y~., data=don.train, ntree = 500, mtry = 5)
# summary(RF_6P_tot_train)
print(RF_6P)
# names(RF_6P_tot) 
# "call"            "type"            "predicted"       "mse"             "rsq"            
# "oob.times"       "importance"      "importanceSD"    "localImportance" "proximity"      
# "ntree"           "mtry"            "forest"          "coefs"           "y"              
# "test"            "inbag"           "terms" 
```

RANDOM FOREST MSE plot
```{r}

# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 100 environ
plot(RF_6P$mse, xlab = "nombre d'arbres", ylab = "MSE")

```

RANDOM FOREST choix de mtry par CV hold out
```{r}

# CHOIX DE MTRY PAR CV HOLD OUT

# train & test datasets
set.seed(1)
dim<-nrow(don)
index<-sample(dim,2*dim/3)
don.train=don[index,]
don.test=don[-index,]
Y.test=Y[-index]

# boucle de test.très long
m=15 # mtry max à tester. 
MSE_RF_6P=rep(0,m)
for(i in 1:m) {
  model <- randomForest(Y~., data=don.train, mtry = i)
  MSE_RF_6P[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# graphe de MSE
plot(MSE_RF_6P, xlab="mtry", ylab="MSE", main="MSE selon mtry", type="b")

```

RANDOM FOREST choix de mtry par CV résultats
```{r}

which.min(MSE_RF_6P) 


```


RANDOM FOREST choix de ntree par CV: résultats pas stables
```{r}


# # CHOIX DE NTREE PAR CV HOLD OUT
# set.seed(1)
# dim<-nrow(don)
# index<-sample(dim,2*dim/3)
# train=don[index,]
# test=don[-index,]
# 
# 
# # résultats très instables
# # tests sur c(50,100,150,200,250,300,350,400,450,500) min MSE pour 100 250 450 300 250 400 300 350 200 250
# # tests sur c(100,200,300,400,500,600,700,800,900,1000) 
# # min MSE pas stable à ntree=200 700 300 100 900 200 200 800 300 700 300 200 500 900  700  600  600 1000
# # tests sur c(500,1000,1500,2000,2500,3000), min MSE pour 1000 2500 2000 1500  500 3000
# # test sur c(1000,2500,5000), min MSE pour 2500
# # test sur c(1000,2000,2500,3000,4000,5000) min MSE pour 2500 2000 1000 2500 1000 1000
# # test sur c(1000,2000,2500,3000,4000,5000,7000) min MSE pour 2000, 2000, 1000, 2000, 7000
# # test sur c(1000,2000,3000,4000,5000,6000) min MSE pour 4000 3000 3000 2000 2000
# # test sur c(100,200,300,700,1000,2000,3000,4000) min MSE 3000 2000 4000  200 3000 4000 700 100 4000 100
# # test sur c(50,100,150,200,250,300,350,400,450,500,600,700,800,900,1000,2000,2500,3000,300,4000,5000,7000)
# # min MSE 800 200 50 250 200 2000 50 100 300 250 450 350 200 500 1000 100 250 900 2500 800 300 350 450 100 1000
# # 350 900 300 250 100 900 350 350 100 300 600 350 350 900 150 150 350 700  50 200
# # 300  450  400  300  200  100  100  450  300  300 2000  350  250  350  600  450  350 50 2500 300
# # test sur c(50,100,150,200,250,300,350,400,450,500)  min MSE pour 350 150 400 100 200 350 400 150 200 400 450 150 450 400 100 400 300 200 450 150 300 100 300 300 300 100 200 100 350 100
# 
# # seq(100,500,by=20) 400 500 380 160 440 220 260 440 480 400 260 260 260  NA 260 260  NA 480 260 260  NA  NA  NA 260  NA 260  NA  NA 260  NA
# 
# Ntree=seq(100,500,by=20)  # ntree à tester
# d=length(Ntree)
# nb=30 # nombre de tests de cross validation
# MSE_RF_6P.tree=rep(NA,d*nb)
# res_ntree=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE
# 
# for (j in 1:nb) {
#   
#   for(i in 1:d) {
#     model <- randomForest(Y~., data=train, mtry = 7, ntree=Ntree[i])
#     MSE_RF_6P.tree[i+j-1] <- mean((test$Y-predict(model,test))^2)
#   }  
#   
#   res_ntree[j]=Ntree[which.min(MSE_RF_6P.tree)]
#  
# }
# 
# res_ntree
# # plot(MSE_RF_6P.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")
# 
# # graphe des MSE du choix de ntree
# Ntree[which.min(MSE_RF_6P.tree)]
# plot(MSE_RF_6P.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")




```

RANDOM FOREST prediction
```{r}
RF_6P_tot<-randomForest(Y~., mtry = 10, data=don.train)

# prediction
RF_6P_tot_pred<-predict(RF_6P_tot,don.test)
RF_6P_tot_pred_sum<-summary(RF_6P_tot_pred)
# RF_6P_tot_pred_sum

MSE_RF_6P_tot= mean((Y.test-predict(RF_6P_tot,don.test))^2)

# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_point(aes(x = don.test$Date, y = Y.test),
             colour = 'red') +
  geom_line(aes(x = don.test$Date, y = RF_6P_tot_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```

vérifier la performance du modele random forest
```{r}

# faire cross validation

# a faire compare the Out of Bag Sample Errors and Error on Test set
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error","Test Error"),pch=19, col=c("red","blue"))

# DYGRAPH
install.packages("dygraphs")
library(dygraphs)



```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES SVR
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



SVR base et variables

```{r}

# install.packages("e1071")
# Load Library
library(caTools)
library(e1071)
library(questionr)

don<-base_tot_F_cr
head(don)
dim(don)


don <- rename.variable(don, "Conso", "Y")
head(don)

```


SVR modelisation train/test
```{r}

# train and test
# éviter les valeurs manquantes
set.seed(1)
split=sample.split(don$Y, SplitRatio=2/3)
don.train=subset(don,split==TRUE)
don.test=subset(don,split==FALSE)
Y.test=subset(don,split==FALSE)

#Regression with SVM
SVR_6P_tot = svm(Y~.,don.train)
MSE_SVR_6P_tot= mean((Y.test-predict(SVR_6P_tot,don.test))^2)

#Predict using SVM regression
pred_svr = predict(SVR_6P_tot, don.test)

#Overlay SVM Predictions on Scatter Plot
plot(don.test$Date, Y.test)
lines(don.test$Date, pred_svr, col="purple")



```


SVR names
```{r}
names(SVR_6P_tot)


```


SVR residuals
```{r}

plot(SVR_6P_tot$residuals)


```






