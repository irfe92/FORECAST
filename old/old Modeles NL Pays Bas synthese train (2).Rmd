---
title: "Synthese 6 pays"
author: "NNN"
date: "16 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

remplace base
remplacer modeles


```{r}
# COMPARAISON DES MODELES

#Load Library
# install.packages("stargaze")
library(stargazer)
library(splines) 
library(randomForest)
library(e1071)
library(ISLR)
library(leaps)
library(questionr)

# sur la base centrée réduite, sans les autres variables méteo
don<-base_NL_F_cr
head(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))

# Creation de l'echantillon train 2/3 individus et test 1/3
set.seed(1)
dim<-nrow(don)
train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
test=model.matrix(Y~.,data=don[-train,])# base de test
Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]
don.train=don[train,]
don.test=don[-train,]
donYX.train=donYX[train,]
donYX.test=donYX[-train,]

```

SELECTION VARIABLES REGSUBSET
```{r}

# variables sélectionnées par regsubset forward: Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t5 + t6 + t7 + month + year + day + leadholidays + wday + quarter + season

# variables sélectionnées par regsubset backward: Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t5 + t7 + month + year + day + quarter + season

```


MODELES
```{r}


# modèle linéaire simple avec que les variables significatives RL_tot2
RL_tot<-lm(Y ~ Temp + day_length + seuil + t1 + t2 + t3 + t4 + t5 + Pays, data=don[train,])
pred_RL_tot=predict(RL_tot, newdata=don.test, se=T)
mse_RL_tot= mean((Y.test-predict(RL_tot,don.test))^2)

# modèle linéaire simple avec que les variables significatives sélectionnée par step
RL_tot_step<-lm(formula = Y ~  Temp + day_length + teff + T00 + t1 + t2 + t3 + t4 + t5 + t6 + Pays + month + year + jc, data = don[train,])
mse_RL_tot_step= mean((Y.test-predict(RL_tot_step,don.test))^2) 


# modèle linéaire avec interaction en ne gardant que les variables significatives
RLI_tot<-lm(Y~ cosinus + day_length + teff + seuil+ Pays + month + day + ( seuil + Pays + month) *Temp,data=don[train,]) 
pred_RLI_tot=predict(RLI_tot, newdata=don.test, se=T)
mse_RLI_tot= mean((Y.test-predict(RLI_tot,don.test))^2)


# poly sur le critère du MSE,issu de la validation hold out train/test et k_folds
POLY_tot<- lm(formula=Y~poly(X,10, raw=T), data=donYX.train)
pred_POLY_tot=predict(POLY_tot, newdata=donYX.test, se=T) # length 383
mse_POLY_tot= mean((Y.test-predict(POLY_tot,donYX.test))^2)
length(pred_POLY_tot$fit)

# modèle spline,CV pour choisir nombre de noeuds et natural splins vs basic splines
SP_tot=lm(Y~bs(X,df=1), data=donYX.train) 
pred_SP_tot=predict(SP_tot, newdata=donYX.test, se=T)
mse_SP_tot= mean((Y.test-predict(SP_tot,donYX.test))^2)


# modèle GAM 
GAM_tot=lm(Y~poly(Temp,7) + day_length + seuil + T00 + t1 + t3 + t5 + t6+ Pays + month + day,data = don) 
pred_GAM_tot=predict(GAM_tot, newdata=don.test, se=T)
mse_GAM_tot= mean((Y.test-predict(GAM_tot,don.test))^2)


# Random Forest , avec mtry choisi par CV hold out, ntree=500 par défaut
RF_tot<-randomForest(Y~., mtry = 10, data=don[train,])
pred_RF_tot = predict(RF_tot, don.test)
mse_RF_tot= mean((Y.test-predict(RF_tot,don.test))^2)


# SVR
SVR_tot = svm(Y~.,don[train,])
pred_SVR_tot = predict(SVR_tot, don.test)
mse_SVR_tot= mean((Y.test-predict(SVR_tot,don.test))^2)



```


SYNTHESE DES MODELES objet RF et SVR pas reconnu par stargazer
```{r}

stargazer(RL_tot,RLI_tot,POLY_tot,SP_tot, GAM_tot, type='text', flip=TRUE, title="Results", align=TRUE, keep=c("Date"), column.labels = c("RL", "RLI","poly","Spline" ,"GAM"), model.names = TRUE, single.row = TRUE)

# le R² ajusté est le plus élevé pour RLI (0.98) et le plus faible pour Poly et Spline à 0.09
# le residual error est le plus faible pour RLI (0.14) et le plus élevé pour poly et Spline (0.95)
# F-stat est le plus élevé pour RLI (5427) et le plus faible pour poly (14)

```



```{r}
# comparaison des MSE entre les modèles RL, RLI, Poly, Spline, GAM, SVR
mse_tot=c(mse_RL_tot, mse_RLI_tot, mse_POLY_tot, mse_SP_tot,mse_GAM_tot,mse_RF_tot,mse_SVR_tot)

# graphe des MSE
graph<-barplot(mse_tot, xlab="modèles", ylab="MSE", main="MSE des modèles NL",las=0)
axis(1, labels=c("Reg.Lin", "RL Inter", "Poly" ,"SPLINE","GAM", "RF", "SVR"), at = graph)

```

```{r}

# comparaison des MSE entre les modèles RL, RLI, GAM, RF, SVR
mse_tot_r=c(mse_RL_tot, mse_RLI_tot, mse_GAM_tot,mse_RF_tot,mse_SVR_tot)

# graphe des MSE
graph<-barplot(mse_tot_r, xlab="modèles", ylab="MSE", main="MSE des modèles NL",las=0)
axis(1, labels=c("Reg.Lin", "RL Inter", "GAM", "RF", "SVR"), at = graph)

```


MSE minimal
```{r}
which.min(mse_tot) # c'est le modèle 6 ie RF qui présente la plus petite MSE
```


graphe des valeurs prédites selon les modèles
```{r}

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles NL" )
lines(don.test$Date,pred_RL_tot$fit, col="purple") # length 387
lines(don.test$Date,pred_RLI_tot$fit, col="cyan") # length 387
lines(don.test$Date,pred_GAM_tot$fit, col="yellow") # length 387
lines(don.test$Date, pred_SVR_tot, col="blue") # length 387
lines(don.test$Date, pred_RF_tot, col="red") # length 387
lines(don.test$Date,pred_POLY_tot$fit, col="pink") # length 387
lines(don.test$Date,pred_SP_tot$fit, col="green") # length 387

```

```{r}
# graphes avec les 3 meilleurs modèles RLI, RF, SVR
plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles NL, GAM(yellow), SVR(blue), RF(red)" )
lines(don.test$Date,pred_RLI_tot$fit, col="yellow")
lines(don.test$Date, pred_SVR_tot, col="blue")
lines(don.test$Date, pred_RF_tot, col="red")

```





