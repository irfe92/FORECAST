---
title: "Modeles NL Pays Bas"
author: "Nhu-Nguyen"
date: "27 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 PACKAGES BASE ET VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

remplacer base
remplacer modeles


base centrée réduite, sans les autres variables météo
```{r}

#install.packages('leaps')
#install.packages('ISLR')
library(ISLR)
library(leaps)
library(questionr)
library(stargazer)
library(ggplot2)

# base totale centrée réduite, sans les variables météo
don<-base_NL_F_cr
head(don)
dim(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))

# Creation de l'echantillon train 2/3 individus et test 1/3
set.seed(1)
dim<-nrow(don)
train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
test=model.matrix(Y~.,data=don[-train,])# base de test

p=ncol(don) # nombre de variables explicatives
p

names(don)

```

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 MODELES SELECTION DE VARIABLES REGSUBSETS
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



SELECTION DE VARIABLES AVEC REGSUBSET exhaustif à éviter
```{r}

# SELECTION EXHAUSTIVE: A EVITER car P GRAND !! (ici 27 variables trop grand)
# Exhaustive search will be S L O W, must specify really.big=T
# On va obtenir 2^p modeles comprenant entre une et p variables
# par défaut, le nombre de variable est 8. Préciser le nombre de variables avec nvmax

best_full_tot=regsubsets(Y~.,data=don[train,],nvmax=p,method='exhaustive')

# choisir les meilleures variables: evaluer chacun des modeles sur le test set et calculer la MSE
mse.full_tot=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_full_tot,id=i)
  pred=test[,names(coefi)]%*%coefi
  mse.full_tot[i]=mean((don$Y[-train]-pred)^2)
}

# plot les RMSE des modeles sur le training 
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.full_tot),ylab='Root MSE des p modeles',pch=19,type='b')
which.min(mse.full_tot) # ici, c'est le modèle à 12 variables (toutes les variables)

# Pour acceder aux coefficient du modele avec la RMSE la plus petite, on appelle la fonction coeff
# Pour acceder aux RSS des modeles, on lance la fonction summary
coef(best_full,12)
summary(best_full)$rss

```


SELECTION DE VARIABLES AVEC REGSUBSET forward
```{r}

# FORWARD SELECTION: NB pas assuré d'avoir le modèle optimal, mais possible si n<p

best_fw_tot=regsubsets(Y~.,data=don[train,],nvmax=p,method='forward')
fw_sum_tot<-summary(best_fw_tot)

# pour chacun des modeles sur le test set, calculer la MSE
mse.fw_tot=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_fw_tot,id=i)
  pred=test[,names(coefi)]%*%coefi
  mse.fw_tot[i]=mean((don$Y[-train]-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.fw_tot),ylab='Root MSE des p modeles FW', main="Regsubset forward NL",pch=19,type='b')
 


```

SELECTION DE VARIABLES AVEC REGSUBSET forward résultats
```{r}
which.min(mse.fw_tot) # ici, c'est le modèle à 27 variables
# d'après le graphe MSE, si on veut un modèle sparse, on pourrait prendre 15 car le MSE baisse peu après

```

SELECTION DE VARIABLES AVEC REGSUBSET forward coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables )
coef(best_fw_tot,27)

# variables sélectionnées par regsubset forward: Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t5 + t6 + t7 + month + year + day + leadholidays + wday + quarter + season

```

SELECTION DE VARIABLES AVEC REGSUBSET forward détails
```{r}
fw_sum_tot

```



SELECTION DE VARIABLES AVEC REGSUBSET forward rss
```{r}
# Pour acceder aux RSS des modèles, on lance la fonction summary
# fw_sum_tot$rss


```


SELECTION DE VARIABLES AVEC REGSUBSET backward
```{r}
# selection variables BACKWARD: NB pas assuré d'avoir le modèle optimal,pas possible si n<p


best_bw_tot=regsubsets(Y~.,data=don[train,],nvmax=p,method='backward')
sum_bw_tot<-summary(best_bw_tot)

# pour chacun des modeles sur le test set, calculer la MSE
mse.bw_tot=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_bw_tot,id=i)
  pred=test[,names(coefi)]%*%coefi
  mse.bw_tot[i]=mean((don$Y[-train]-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.bw_tot),ylab='Root MSE des p modeles',main="Regsubset backward NL",pch=19,type='b') 



```

SELECTION DE VARIABLES AVEC REGSUBSET backward résultats
```{r}
which.min(mse.fw_tot) #ici, c'est le modèle à 27 variables 
# d'après le graphe, MSE quasi-stable à partir de 18

```


SELECTION DE VARIABLES AVEC REGSUBSET backward coef
```{r}

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables à la place de 2)
coef(best_bw_tot,27) 

# variables sélectionnées par regsubset backward: Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t5 + t7 + month + year + day + quarter + season

```


SELECTION DE VARIABLES AVEC REGSUBSET MSE
```{r}
# plot des RMSE pour les modèles FW et BW

x=c(1:p)
x
y1=sqrt(mse.fw_tot)
y2=sqrt(mse.bw_tot)
plot(x, y1, type = "l", ylim = range(c(y1, y2)), xlab = "nb de variables", ylab = "root mse", main="FW (blue) et BW (red)")
lines(x, y1, col = "blue")
lines(x, y2, col = "red")


```


SELECTION DE VARIABLES AVEC REGSUBSET RSS
```{r}

# Pour acceder aux RSS des modeles, on lance la fonction summary
# summary(best_full_tot)$rss 
summary(best_fw_tot)$rss
summary(best_bw_tot)$rss


```


SELECTION DE VARIABLES AVEC REGSUBSET plot BIC
```{r}

# choix des variables selon critères BIC, R² ajusté, Cp
# graphe BIC autre: “Cp”, “adjr2”, “r2". classification des valeurs de BIC selon les modèles, en haut la plus petite valeur de BIC et en noir les variables inclusent dans le modèle
# Le $R^2$ ajusté permet de déterminer à quel point le modèle ajuste vos données lorsque vous souhaitez l'ajuster en fonction du nombre de prédicteurs inclus. La valeur du $R^2$ ajusté intègre le nombre de prédicteurs dans le modèle elle donc plus adaptée pour nous aider à choisir le modèle.

# graphe BIC
plot(best_fw_tot, scale="bic", main=" BIC pour Regsubset FW ") 



```


SELECTION DE VARIABLES AVEC REGSUBSET plot R²
```{r}
# graphe R² ajusté
plot(best_fw_tot, scale="adjr2", main=" R² Ajuste pour Regsubset FW")

 
```


SELECTION DE VARIABLES AVEC REGSUBSET plot Cp
```{r}


# graphe Cp
plot(best_fw_tot, scale="Cp", main=" Cp pour Regsubset FW")


```


SELECTION DE VARIABLES AVEC REGSUBSET forward comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifiez l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_fw_tot)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)
min.rss
max.adjr2
min.cp
min.bic # 14
names(which(reg.summary$which[min.rss,]==TRUE))
names(which(reg.summary$which[max.adjr2,]==TRUE))
names(which(reg.summary$which[min.cp,]==TRUE))
names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


SELECTION DE VARIABLES AVEC REGSUBSET forward comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

SELECTION DE VARIABLES AVEC REGSUBSET backward comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifiez l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_bw_tot)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)
min.rss
max.adjr2
min.cp
min.bic # 14
names(which(reg.summary$which[min.rss,]==TRUE))
names(which(reg.summary$which[max.adjr2,]==TRUE))
names(which(reg.summary$which[min.cp,]==TRUE))
names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


SELECTION DE VARIABLES AVEC REGSUBSET backward comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES LASSO POUR SELECTION DE VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES OLS SANS INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


On cherche à prédire la consommation (Y) en fonction des autres variables


OLS SANS INTERACTION avec toutes les variables résultats
```{r}

# OLS sans interaction sur base centrée réduite

# modèle linéaire simple sur Y, avec toutes les variables
# R² ajust 0.9674 F Stat 905 Residual standard error: 0.1888
# graphe résidus vs fitted incurvé
RL_tot<-lm(Y~.,data=don)
RL_tot_sum<-summary(RL_tot)
RL_tot_sum


```

OLS SANS INTERACTION avec toutes les variables résidus
```{r}
# le graphe des résidus présente une structure avec 3 groupes distincts
plot(RL_tot) 

```


OLS SANS INTERACTION en ne gardant que les variables significatives
```{r}

# selection des variables significatives à la main, en en gardant que les pvalue significatives
# 11 variables signficatives: Temp + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + Pays
# R² ajust 0.8642,F Stat 1002, Residual standard error assez élevé : 0.3685

RL_tot1<-lm(Y~ Temp + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + Pays, data=don)
RL_tot1.sum<-summary(RL_tot1)
RL_tot1.sum

# teff et T00 ne sont plus significatifs

```


OLS SANS INTERACTION en ne gardant que les variables significatives
```{r}
# en enlevant teff et TOO qui ne sont plus significatifs
RL_tot2<-lm(Y~ Temp + day_length + seuil + t1 + t2 + t3 + t4 + t5 + Pays, data=don)
RL_tot2.sum<-summary(RL_tot2)
RL_tot2.sum


```


OLS SANS INTERACTION en ne gardant que les variables significatives: résidus
```{r}
# graphe résidus vs fitted encore très structurés avec 3 groupes
plot(RL_tot2) 


```

OLS SANS INTERACTION step
```{r}
# selection des variables significatives avec step
# step picks the best model from the one-term-dropped models and repeats the process until no further improvement in the model can be made by dropping a term. 
# The test parameter is optional, the default criteria is "AIC". It can also take the values "F" and "LRT".
# graphe résidus vs fitted incurvé
step(RL_tot_tot, test="F")

```


OLS SANS INTERACTION modèle step et plot résidus
```{r}

RL_tot_step<-lm(formula = Y ~ Temp + day_length + teff + T00 + t1 + t2 + t3 + 
    t4 + t5 + t6 + Pays + month + year + jc, data = don)

# graphe des résidus avec une structure en trois groupes
plot(RL_tot_step)


```


OLS SANS INTERACTION synthèse
```{r}

# comparaison avec modèle linéaire issu de step
# R² ajusté step légèrement meilleur que le modèle en ne gardant directement que les  variables significative (step à 0.864 vs 0.86), mais égal à celui du modèle total
# F stat moins élevé que RL_tot2 mais supérieur au modèle total
# residual std error moins élevé que RL_tot1 mais égal modèle total. Mes il est globalement élevé pour les 3 modèles
stargazer(RL_tot_tot,RL_tot2,RL_tot_step,type='text', flip=TRUE, title="Results", keep=c("Date","meteo"), column.labels = c("tot", "tot2","step"))


```


ANOVA
```{r}

# anova: the returned information for the F-test is the difference in the sum of squares between the models, the F-statistic for this difference, and the p-value for the F-statistic.
anova(RL_tot_tot,RL_tot2) # la différence semble significative entre tot et tot2
anova(RL_tot2,RL_tot_step) # la différence semble significative entre step et tot2


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES OLS AVEC INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

"Date"         "Y"            "Temp"         "cosinus"      "sinus"        "day_length"   "teff"         "seuil"       
 [9] "T00"          "t1"           "t2"           "t3"           "t4"           "t5"           "t6"           "t7"          
[17] "Pays"         "month"        "year"         "day"          "weekend"      "wday"         "quarter"      "season"      
[25] "holidays"     "jc"           "lagholidays"  "leadholidays"

OLS AVEC INTERACTION SIMPLE résultats
```{r}
# OLS AVEC INTERACTION entre la température et les autres variables

RLI_tot<-lm(Y~(Date + cosinus + sinus + day_length + teff + seuil + T00 + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)*Temp ,data=don) 
RLI_tot_sum<-summary(RLI_tot)
RLI_tot_sum

# les variables significatives sont cosinus + day_length + teff + seuil+ Pays + month + day + ( seuil + Pays + month) *Temp

```


OLS AVEC INTERACTION SIMPLE residus
```{r}
# le graphe des résidus est encore très structuré en 3 groupes
plot(RLI_tot)

```

OLS AVEC INTERACTION SIMPLE avec TEMP, en ne gardant que les variables signficatives
```{r}
# modèle OLS avec interaction avec seulement les variables significatives
# les variables significatives sont cosinus + day_length + teff + seuil+ Pays + month + day + ( seuil + Pays + month) *Temp
# R² ajusté très faible à 0.9798, F-Stat à 7982, residuak sd error à 0.1422
RLI_tot1<-lm(Y~ cosinus + day_length + teff + seuil+ Pays + month + day + ( seuil + Pays + month) *Temp,data=don) 
RLI_tot1_sum<-summary(RLI_tot1)
RLI_tot1_sum

```



OLS AVEC INTERACTION SIMPLE avec seulement les variables signficatives résidus
```{r}
# le graphe des résidus présente encore une structure mais qui semble moins forte
plot(RLI_tot1)


```


OLS comparaison simple et interaction
```{r}

# comparaison modèles linéaire sans et avec interaction: les stats sont meilleures pour le modèle avec interaction
# R² ajusté plus élevé pour RL avec interaction RLI (0.98) que pour les RL sans interaction (0.86)
# residual std error plus faible pour RLI (0.142) que les RL sans interaction (0.37)
# F-stat plus élevé pour pour RLI (7982) que RL sans interaction (<3541)
stargazer(RL_tot_tot,RL_tot2,RL_tot_step,RLI_tot1,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("tot","tot2","step","RLI"))

# ainsi, pour la base avec 6 pays, la RL avec interaction ne présente pas d'intérêt par rapport à celle sans interaction

```


OLS comparaison simple et interaction MSE min
```{r}

mse_RL_tot_tot= mean((don$Y-predict(RL_tot_tot,don))^2,na.rm=TRUE) # prediction from a rank-deficient fit may be misleading 

mse_RL_tot2= mean((don$Y-predict(RL_tot2,don))^2, na.rm=TRUE) 

mse_RL_tot_step= mean((don$Y-predict(RL_tot_step,don))^2, na.rm=TRUE) 

mse_RLI_tot= mean((don$Y-predict(RLI_tot,don))^2, na.rm=TRUE)

mse_RLI_tot1= mean((don$Y-predict(RLI_tot1,don))^2, na.rm=TRUE)


mse.BE.RL=c(mse_RL_tot_tot,mse_RL_tot2,mse_RL_tot_step,mse_RLI_tot,mse_RLI_tot1)
which.min(mse.BE.RL) # c'est le 1er RL_tot qui présente la plus petite MSE, avec toutes les variables





```

OLS comparaison simple et interaction MSE plot
```{r}
# graphe avec étiquettes horizontale (las=1)
graph<-barplot(mse.BE.RL, xlab="modèles", ylab="MSE", main="MSE des modèles RL",las=0)
axis(1, labels=c("tot", "tot2", "step", "RLI", "RLI1"), at = graph)

```


OLS AVEC INTERACTION entre Temp (poly degré 2) et les autres variables
```{r}

RLI_P2_tot<-lm(Y~(Date + cosinus + sinus + day_length + teff + seuil + T00 + Pays + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)*I(poly(Temp,2)),data=don) 
RLI_P2_tot_sum<-summary(RLI_P2_tot)
RLI_P2_tot_sum

# les variables significatives sont cosinus + day_length + teff + seuil + Pays + month + day + lagholidays +(cosinus + seuil + T00 + day_length + Pays + month)*I(poly(Temp,2))

```

```{r}
# les variables significatives sont cosinus + day_length + teff + seuil + Pays + month + day + lagholidays +(cosinus + seuil + T00 + day_length + Pays + month)*I(poly(Temp,2))

RLI_P2_tot1<-lm(Y~ cosinus + day_length + teff + seuil + Pays + month + day + lagholidays +(cosinus + seuil + T00 + day_length + Pays + month)*I(poly(Temp,2)), data=don) 
RLI_P2_tot1_sum<-summary(RLI_P2_tot1)
RLI_P2_tot1_sum

```



```{r}
# comparaison modèles linéaire avec interaction simple sur toutes les variables, avec seulement les variables significatives, interaction poly (Temp,2) sur toutes les variables, avec seulement les variables significatives,
# faible hausse du R² ajusté de 0.98 à 0.984
# faible  baisse du Residual std error de 0.142 à 0.125
# baisse sensible de F stat de 7982 (RLI_tot1) à 6485
stargazer(RLI_tot,RLI_tot1, RLI_P2_tot,RLI_P2_tot1 ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RLI","RLI1", "P2", "P2_tot1"))

# l'ajout du poly degré 2 dans l'interaction n'améliore pas significativement les stats R² et residual error mais dégrade sensiblement F-stat
# il ne semble pas intéressant de mettre la variable Temp en polynome dans l'interaction



```


```{r}
pred_RL_tot1=predict(RL_tot1, newdata=don, se=T)
pred_RLI_tot1=predict(RLI_tot1, newdata=don, se=T)
pred_RLI_P2_tot1=predict(RLI_P2_tot1, newdata=don, se=T)

# graphe des valeurs prédites selon les modèles
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="modèles RL et RLI sur NL" )
lines(don$Date,pred_RL_tot1$fit, col="blue")
lines(don$Date,pred_RLI_tot1$fit, col="red")
lines(don$Date,pred_RLI_P2_tot1$fit, col="green")

plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="modèle RL sur NL" )
lines(don$Date,pred_RL_tot1$fit, col="blue")

# graphe des valeurs prédites selon les modèles
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="modèle RLI simple sur NL" )
lines(don$Date,pred_RLI_tot1$fit, col="red")

# graphe des valeurs prédites selon les modèles
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="modèles RLI poly2 sur NL" )
lines(don$Date,pred_RLI_P2_tot1$fit, col="green")

```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES POLYNOMIAL
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


Modèles avec cible=Conso en fonction d'un polynome sur Temp

POLYNOME base et variables
```{r}

library(glmnet)
library(boot)
library(stargazer)

# sur la base centrée réduite
don<-base_NL_F_cr

# definition variables Y et X
library(questionr)
don <- rename.variable(don, "Conso", "Y")
head(don)
dim(don)

# regression polynomiale entre Y=conso et X=Temp
Y=don$Y
X=don$Temp
donYX=data.frame(cbind(Y,X))
head(donYX)

```


POLYNOME détermination du degré par cross validation hold out train / test
```{r}


# CROSS VALIDATION HOLD OUT TRAIN/TEST
set.seed(1)
dim<-nrow(donYX)
train<-sample(dim,2*dim/3)
test=donYX[-train,]

d=20 # degré max de polynome à tester
mse.poly=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX[train,])
  mse.poly[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.poly),ylab="MSE", main='Root MSE selon le degré de polynome',pch=19,type='b')


```

POLYNOME détermination du degré par cross validation hold out resultats
```{r}
which.min(mse.poly) # degré 10

```


POLYNOME détermination du degré par cross validation hold out modèle retenu et résidus
```{r}

#modèle retenu par hold out
poly10_tot<- lm(formula=Y~poly(X,10, raw=T), data=don)
poly10_tot_sum<- summary(poly10_tot)
mse_poly10_tot= mean((Y-predict(poly10_tot,don))^2)

# le graphe des résidus vs fitted a toujours une structure en 3 groupes
plot(poly10_tot)

```


POLYNOME détermination du degré par cross validation K-fold
```{r}


# CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
cv.error=as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX)
cv.error[i]<-cv.glm(donYX,glm.fit,K=10)$delta[1]
}

plot(cv.error, pch=19,type='b')

```

POLYNOME détermination du degré par cross validation K-fold résulats
```{r}
which.min(cv.error) # ici c'est avec le degré 6 que l'erreur est la plus faible

```



POLYNOME détermination du degré par cross validation K-fold modèle retenu et résidus
```{r}

#modèle retenu par K_fold
poly6_tot<- lm(formula=Y~poly(X,6, raw=T), data=don)
poly6_tot_sum<- summary(poly6_tot)
mse_poly6_tot= mean((Y-predict(poly6_tot,don))^2)

# le graphe des résidus vs fitted a toujours une structure en 3 groupes
plot(poly6_tot)

```


POLYNOME détermination du degré par cross validation LOOCV à éviter, trop long
```{r}
# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
# library(boot)
# d=10 # degré de polynome 
# cv.error=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~poly(X,i),data = donYX) 
#   cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }
# plot(cv.error, type="l") 

```


POLYNOME comparaison RL et poly
```{r}


# COMPARAISON DES MODELES
#modèle retenu par hold out
poly10_tot<- lm(formula=Y~poly(X,10, raw=T), data=don)
poly10_tot_sum<- summary(poly10_tot)
mse_poly10_tot= mean((Y-predict(poly10_tot,don))^2)

#modèle retenu par K_fold
poly6_tot<- lm(formula=Y~poly(X,6, raw=T), data=don)
poly6_tot_sum<- summary(poly6_tot)
mse_poly6_tot= mean((Y-predict(poly6_tot,don))^2)

#comparaison des modèles linéaire total avec poly
# R² ajusté à 0.087 pour poly10 et 0.086 pour poly6, plus petit par rapport au modèle linéaire (0.86)
# résidual sdt error beaucoup plus élevé que dans RL (0.374), poly10 (0.955) poly 6(0.956)
# F stat plus faible pour les poly(<67) que pour modèle linéaire (3036)
stargazer(RL_tot1,poly10_tot, poly6_tot, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","poly10", "poly6"))




```

```{r}
# en comparant les MSE, 
diff_poly_tot=mse_poly10_tot - mse_poly6_tot
diff_poly_tot # mse_poly10_tot < mse_poly6_tot
# 
# nous retiendrons poly10 sur le critère du MSE
poly_tot<- lm(formula=Y~poly(X,10, raw=T), data=don)
poly_tot_sum<- summary(poly_tot)
mse_poly_tot= mean((Y-predict(poly_tot,don))^2)


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES SPLINES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


SPLINES base et variables
```{r}

# SPLINE Conso en fonction de la température

library(splines)
library(stargazer)
library(questionr)

don<-base_NL_F_cr
don <- rename.variable(don, "Conso", "Y")

#creation des variables Y et X
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
str(donYX)
nrow(donYX)
length(X)
length(Y)

# data set train et test
set.seed(1)
d<-nrow(donYX)
train<-sample(d,2*d/3)
test=donYX[-train,]

```


SPLINES choix du degré de liberté/noeuds par CV hold out pour natural splines
```{r}

# CHOIX DU DEGRE DE LIBERTE df (et donc du nombre de noeuds) par cross validation HOLD OUT TRAIN/TEST 
# l'option df produit des splines avec des noeuds placés sur les quantiles
# on n'obtient pas les mêmes noeuds en bs et ns, pour un même degré de liberté
# attr() pour avoir les noeuds issus de df

# # noeuds avec basic splines
# attr(bs(X,df=3),"knots") # pas de noeud
# attr(bs(X,df=4),"knots") # un seul noeud à 50% = 2 intervalles + 2 frontières min et max
# attr(bs(X,df=5),"knots") # 2 noeuds à 1/3 et 2/3 = 3 intervalles + 2 frontières min et max
# attr(bs(X,df=6),"knots") # 3 noeuds à 25%, 50% et 75% = 4 intervalles + 2 frontières min et max
# 
# # noeuds avec natural splines
# attr(ns(X,df=1),"knots") #  pas de noeud
# attr(ns(X,df=2),"knots") #  un seul noeud à 50%
# attr(ns(X,df=3),"knots") #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
# attr(ns(X,df=4),"knots") #  3 noeuds à 25% (5.8), 50% (10.2),75% (15.5)
# attr(ns(X,df=5),"knots") #  4 noeuds à 20% (4.9), 40% (8.5),60% (12.2), 80% (16.5)


# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
mse_SP_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(X,df=i), data=donYX[train,])
  mse_SP_ns[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse_SP_ns),ylab="MSE", main='Root MSE selon le degré de liberté du spline',pch=19,type='b')


```


SPLINES choix du degré de liberté/noeuds résultats
```{r}

which.min(mse_SP_ns)
# c'est le modèle avec un degré de liberté 8 qui a la plus petite MSE

```

SPLINES choix du degré de liberté: nombre de noeuds
```{r}
attr(ns(X,df=8),"knots")

```


SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}


# pour basic spline, recherche degré df qui minimise le MSE 

DF=15 # df max à tester
mse_SP_bs=rep(0,DF)
for(i in 4:DF) {
  model <- lm(Y~bs(X,df=i), data=donYX[train,])
  mse_SP_bs[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse_SP_bs),ylab="MSE", main='Root MSE selon le degré de liberté du spline',pch=19,type='b')

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines résultat
```{r}
which.min(mse_SP_bs)

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}
attr(ns(X,df=1),"knots")
# pas de noeud 

```


SPLINES choix entre natural splines et basic splines par CV hold out 
```{r}

# CHOIX ENTRE BASIC SPLINES ET NATURAL SPLINES, celui qui minimise le MSE

#natural splines ns
# ns() ne marche que si les variables sont numériques. Les variables qualitatives seront transformées en dummy variables
attr(ns(X,df=8),"knots")  # 7 noeuds à12.5% 25% 37.5% 50% 62.5% 75% 87.5%
fit_ns_tot=lm(Y~ns(X,df=3), data=donYX[train,])
plot(fit_ns_tot)
mse.SP_ns <- mean((test$Y-predict(fit_ns_tot,test))^2)
# pred_ns_tot=predict(fit_ns_tot, newdata=list(X=test$X), se=T)

#basic splines bs: on prend le df qui donne les mêmes noeuds que natural spline 
attr(bs(X,df=1),"knots") # pas de noeud
fit_bs_tot=lm(Y~bs(X,df=5), data=donYX[train,])
plot(fit_bs_tot)
mse.SP_bs <- mean((test$Y-predict(fit_bs_tot,test))^2)
# pred_bs_tot=predict(fit_bs_tot, newdata=list(X=test$X), se=T)

diff_bs_ns=mse.SP_bs-mse.SP_ns
diff_bs_ns # mse.SP_bs < mse_bs_ns 
# => avec les mse, on choisirait bs


```


SPLINES choix entre natural splines et basic splines par CV hold out comparaison
```{r}


#comparaison des stats des résultats entre basic et natural splines
stargazer(fit_bs_tot, fit_ns_tot, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("bs", "ns"))
# => avec les stat des modèles, choix de ns car F-stat plus grand à 149 (bs=90). Le R² ajusté et residual std error sont égaux entre ns et bs

# les stats du modèles de spline ne sont pas bonnes: R² très faible (0.08), residual error très élevé (0.95)
# il faudrait essayer Régression multivariée par spline adaptative. Mais package Polymars n'est plus accessible


```


SPLINES choix entre natural splines et basic splines par CV hold out résultats et résidus
```{r}

# modèle spline sur toute la base BE
# en minimisant MSE, on retient spline bs avec df=1 trouvé par cross validation hold out
SP_tot=lm(Y~bs(X,df=1), data=donYX) #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
pred_SP_tot=predict(SP_tot, newdata=list(X=donYX$X), se=T)
mse_SP_tot= mean((Y-predict(SP_tot,donYX))^2)
plot(SP_tot) # graphe des résidus vs fitted a toujours une structure en 3 groupes


```


SPLINES graphes et smooting splines
```{r}

# graphes de conso vs température
plot(donYX$X,donYX$Y, xlab = "Temp", ylab="Conso")
points (donYX$X,pred_SP_tot$fit, col="blue") 

# graphe de conso vs date
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="Spline sur Belgique,Y et fit (bleu)" )
lines(don$Date,pred_SP_tot$fit, col="blue") 


# SMOOTHING SPLINE
SM_tot=smooth.spline(don$Y,don$X,df=3) # on spécifie df=6 et le lambda est déterminé de sorte à obtenir df=6
SM_tot_cv=smooth.spline(don$Y,don$X,cv=TRUE) # lambda est choisi par cross validation

plot(SM_tot, main="smooth spline") # forme en V arrondie
plot(SM_tot_cv, main="cv") # sinusoide

# #comparaison des résultats entre Spline df3, smoothing spline df3 et smoothing spline avec lambda par cv
# stargazer(SP_tot, SM_tot, SM_tot_cv, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("SP", "SM", "SMcv"), model.names = TRUE)
```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES GAM
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



GAM base et variables
```{r}


library(splines) 
library(questionr)

don<-base_NL_F_cr
don <- rename.variable(don, "Conso", "Y")

#creation des variables Y et X
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
str(donYX)
nrow(donYX)
length(X)
length(Y)

# data set train et test
set.seed(1)
d<-nrow(donYX)
train<-sample(d,2*d/3)
test=donYX[-train,]

```


GAM détermination du polynome par CV K-fold (avec variables sélectionnées par regsubset forward)
```{r}


# détermination du degré du polynome par cross validation, 
# il y a trop de variables,le modèle ne tourne pas, il faut réduire
# en utilisant les variables sélectionnées par regsubset forward: Date + Temp + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6+ Pays + month + year + day + wday + quarter 

library(boot)
d=15 # degré de spline à tester
cv.error=rep(0,d)
for (i in 1:d) { 
  glm.fit=glm(Y~poly(Temp,i) + Date + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6+ Pays + month + year + day + wday + quarter,data = don) 
  cv.error[i]=cv.glm(don,glm.fit, K=10)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(cv.error, main="cv.error selon degré polynome",pch=19,type='b') 

```

GAM détermination du polynome par CV K-fold résultats (avec variables sélectionnées par regsubset forward)
```{r}
which.min(cv.error) # degré 7

```


GAM détermination du polynome par CV K-fold modèle retenu (avec variables sélectionnées par regsubset forward)
```{r}

# modèle GAM avec polynôme degré 7 sur la température 

gam_tot_fw=lm(Y~poly(Temp,7) + Date + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6+ Pays + month + year + day + wday + quarter,data = don) 

pred_gam_tot_fw=predict(gam_tot_fw, newdata=don, se=T)

summary(gam_tot_fw)

# les variables qui ne sont pas significatives: Date, teff, year, wday, quarter

```

GAM détermination du polynome par CV K-fold modèle retenu 1 (avec variables sélectionnées par regsubset forward)
```{r}
# modèle GAM avec polynôme retenu 
# suppresionn des variables qui ne sont pas significatives: Date, teff, year, wday, quarter

gam_tot_fw1=lm(Y~poly(Temp,7) + day_length + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6+ Pays + month + day,data = don) 

summary(gam_tot_fw1)

# des variables non significatives: t2, t4

```


GAM détermination du polynome par CV K-fold modèle retenu 2 (avec variables sélectionnées par regsubset forward)
```{r}
# modèle GAM avec polynôme retenu 
# suppresionn des variables qui ne sont pas significatives: t2, t4

gam_tot_fw2=lm(Y~poly(Temp,7) + day_length + seuil + T00 + t1 + t3 + t5 + t6+ Pays + month + day,data = don) 

summary(gam_tot_fw2)

# des variables non significatives:

```


GAM résidus
```{r}
# le graphe des résidus présente toujours une structure en 3 groupes
plot(gam_tot_fw2) 


```


GAM détermination du polynome par CV K-fold (avec variables sélectionnées par regsubset backward)
```{r}


# détermination du degré du polynome par cross validation, 
# trop de variables,
# variables sélectionnées par regsubset backward: Date + Temp + day_length + teff + seuil + T000 + t1 + t2 + t3 + t4 + t5 + Pays + month + year + day + quarter

library(boot)
d=15 # degré de spline à tester
cv.error=rep(0,d)
for (i in 1:d) { 
  glm.fit=glm(Y~poly(Temp,i) + Date + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + Pays + month + year + day + quarter,data = don) 
  cv.error[i]=cv.glm(don,glm.fit, K=10)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(cv.error, main="cv.error selon degré polynome",pch=19,type='b') 

```

GAM détermination du polynome par CV K-fold résultats (avec variables sélectionnées par regsubset backward)
```{r}
which.min(cv.error)

```


GAM détermination du polynome par CV K-fold modèle retenu (avec variables sélectionnées par regsubset backward)
```{r}

# modèle GAM avec polynôme sur la température 

gam_tot_bw=lm(Y~poly(Temp,7) + Date + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + Pays + month + year + day + quarter,data = don) 

pred_gam_tot_bw=predict(gam_tot_fw, newdata=don, se=T)

summary(gam_tot_bw)

# les variables qui ne sont pas significatives: Date, year, quarter

```

GAM détermination du polynome par CV K-fold modèle retenu (avec variables sélectionnées par regsubset backward)
```{r}
# modèle GAM avec polynôme retenu 
# suppresionn des  variables qui ne sont pas significatives: Date, year, quarter

gam_tot_bw1=lm(Y~poly(Temp,7) + day_length + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + Pays + month + day ,data = don) 

summary(gam_tot_bw1)

# des variables non significatives: t4

```


GAM détermination du polynome par CV K-fold modèle retenu (avec variables sélectionnées par regsubset backward)
```{r}
# modèle GAM avec polynôme retenu 
# suppresionn des variables qui ne sont pas significatives: t4

gam_tot_bw2=lm(Y~poly(Temp,7) + day_length + teff + seuil + T00 + t1 + t2 + t3 + t5 + Pays + month + day ,data = don) 

summary(gam_tot_bw2)


```


GAM résidus
```{r}
# le graphe des résidus présente toujours une structure en 3 groupes
plot(gam_tot_fw2) 


```


GAM comparaison des modèles issus des variables FW et BW
```{r}

gam_tot_fw2=lm(Y~poly(Temp,7) + day_length + seuil + T00 + t1 + t3 + t5 + t6+ Pays + month + day,data = don.train) 
gam_tot_bw2=lm(Y~poly(Temp,7) + day_length + teff + seuil + T00 + t1 + t2 + t3 + t5 + Pays + month + day ,data = don.train) 

mse_gam_tot_fw2= mean((Y.test-predict(gam_tot_fw2,don.test))^2)
mse_gam_tot_bw2= mean((Y.test-predict(gam_tot_bw2,don.test))^2)

diff=mse_gam_tot_fw2-mse_gam_tot_bw2
diff # <0 donc c'est fw2 qui est à retenir

which.min(c(mse_gam_tot_fw2,mse_gam_tot_bw2)) 

```

GAM modèle retenu
```{r}
gam_tot_fw2=lm(Y~poly(Temp,7) + day_length + seuil + T00 + t1 + t3 + t5 + t6+ Pays + month + day,data = don) 

```


GAM valeurs prédites
```{r}
pred_gam_tot_fw2=predict(gam_tot_fw2, newdata=don, se=T)
# graphe des valeurs prédites par GAM sur la Belgique
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="GAM" )
lines(don$Date,pred_gam_tot_fw2$fit, col="yellow")


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES RANDOM FOREST
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


RANDOM FOREST base et variables
```{r}

# RANDOM FOREST BELGIQUE
# on peut régler deux éléments : 
# ntree: le nombre d’arbres construits par l’algorithme 
# mtry: le nombre de variables testées à chaque division. 
# la valeur par défaut de mtry correspond à la racine carrée du nombre de variables

library(caTools)
library(randomForest)
library(ggplot2)
library(questionr)

don<-base_NL_F_cr
head(don)
dim(don)
sqrt(ncol(don)) # = valeur mtry par défaut soit 5 pour base BE

# création de variable Y
don <- rename.variable(don, "Conso", "Y")
head(don)

# train and test base BE
# prendre base.nona pour éviter les valeurs manquantes
set.seed(1)
split=sample.split(don$Y, SplitRatio=2/3)
train=subset(don,split==TRUE)
test=subset(don,split==FALSE)

```

RANDOM FOREST modelisation
```{r}

# modelisation sur train, par défaut ntree=500
RF_tot_train<-randomForest(Y~., data=train, ntree = 500, mtry = 5)
# summary(RF_tot_train)
print(RF_tot_train)
# names(RF_tot) 
# "call"            "type"            "predicted"       "mse"             "rsq"            
# "oob.times"       "importance"      "importanceSD"    "localImportance" "proximity"      
# "ntree"           "mtry"            "forest"          "coefs"           "y"              
# "test"            "inbag"           "terms" 
```

RANDOM FOREST MSE plot
```{r}

# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 100 environ
plot(RF_tot_train$mse, xlab = "nombre d'arbres", ylab = "MSE")

```

RANDOM FOREST choix de mtry par CV hold out
```{r}

# CHOIX DE MTRY PAR CV HOLD OUT

# train & test datasets
set.seed(1)
dim<-nrow(don)
index<-sample(dim,2*dim/3)
train=don[index,]
test=don[-index,]

# boucle de test
m=20 # mtry max à tester. Par défaut ntree=500
mse.rf=rep(0,m)
for(i in 1:m) {
  model <- randomForest(Y~., data=train, mtry = i)
  mse.rf[i] <- mean((test$Y-predict(model,test))^2)
  }

# graphe de MSE
plot(mse.rf, xlab="mtry", ylab="MSE", main="MSE selon mtry", type="b")

```

RANDOM FOREST choix de mtry par CV résultats
```{r}

which.min(mse.rf) # mtry=7 


```


RANDOM FOREST choix de ntree par CV: résultats pas stables
```{r}


# CHOIX DE NTREE PAR CV HOLD OUT
set.seed(1)
dim<-nrow(don)
index<-sample(dim,2*dim/3)
train=don[index,]
test=don[-index,]


# résultats très instables
# tests sur c(50,100,150,200,250,300,350,400,450,500) min MSE pour 100 250 450 300 250 400 300 350 200 250

# tests sur c(100,200,300,400,500,600,700,800,900,1000) 
# min MSE pas stable à ntree=200 700 300 100 900 200 200 800 300 700 300 200 500 900  700  600  600 1000

# tests sur c(500,1000,1500,2000,2500,3000), min MSE pour 1000 2500 2000 1500  500 3000
# test sur c(1000,2500,5000), min MSE pour 2500
# test sur c(1000,2000,2500,3000,4000,5000) min MSE pour 2500 2000 1000 2500 1000 1000
# test sur c(1000,2000,2500,3000,4000,5000,7000) min MSE pour 2000, 2000, 1000, 2000, 7000
# test sur c(1000,2000,3000,4000,5000,6000) min MSE pour 4000 3000 3000 2000 2000
# test sur c(100,200,300,700,1000,2000,3000,4000) min MSE 3000 2000 4000  200 3000 4000 700 100 4000 100

# test sur c(50,100,150,200,250,300,350,400,450,500,600,700,800,900,1000,2000,2500,3000,300,4000,5000,7000)
# min MSE 800 200 50 250 200 2000 50 100 300 250 450 350 200 500 1000 100 250 900 2500 800 300 350 450 100 1000
# 350 900 300 250 100 900 350 350 100 300 600 350 350 900 150 150 350 700  50 200
# 300  450  400  300  200  100  100  450  300  300 2000  350  250  350  600  450  350 50 2500 300

# test sur c(50,100,150,200,250,300,350,400,450,500)  min MSE pour 350 150 400 100 200 350 400 150 200 400 450 150 450 400 100 400 300 200 450 150 300 100 300 300 300 100 200 100 350 100

# seq(100,500,by=20) 400 500 380 160 440 220 260 440 480 400 260 260 260  NA 260 260  NA 480 260 260  NA  NA  NA 260  NA 260  NA  NA 260  NA

Ntree=seq(100,500,by=20)  # ntree à tester
d=length(Ntree)
nb=30 # nombre de tests de cross validation
mse.rf.tree=rep(NA,d*nb)
res_ntree=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE

for (j in 1:nb) {
  
  for(i in 1:d) {
    model <- randomForest(Y~., data=train, mtry = 7, ntree=Ntree[i])
    mse.rf.tree[i+j-1] <- mean((test$Y-predict(model,test))^2)
  }  
  
  res_ntree[j]=Ntree[which.min(mse.rf.tree)]
 
}

res_ntree
# plot(mse.rf.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")

# graphe des MSE du choix de ntree
Ntree[which.min(mse.rf.tree)]
plot(mse.rf.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")



# CV avec randomforest pour sélectionner des variables
# donX <- don[,!colnames(don)=="Y"] #supprimer la colonne X2
# head(donX)
# nrow(donX)
# length(don$Y)
# rfcv(don[train,], train$Y, cv.fold=5, scale="log", step=0.5, mtry=function(p) max(1, floor(sqrt(p))))


# # prediction sur test
# RF_tot_pred_test<-predict(RF_tot,test)



```

RANDOM FOREST prediction
```{r}
RF_tot<-randomForest(Y~., mtry = 10, data=don)

# prediction
RF_tot_pred<-predict(RF_tot,don)
RF_tot_pred_sum<-summary(RF_tot_pred)
# RF_tot_pred_sum

mse_RF_tot= mean((Y-predict(RF_tot,don))^2)

# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_point(aes(x = don$Date, y = don$Y),
             colour = 'red') +
  geom_line(aes(x = don$Date, y = RF_tot_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```

vérifier la performance du modele random forest
```{r}

# faire cross validation

# a faire compare the Out of Bag Sample Errors and Error on Test set
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error","Test Error"),pch=19, col=c("red","blue"))

# DYGRAPH
install.packages("dygraphs")
library(dygraphs)



```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES SVR
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



SVR base et variables

```{r}

# install.packages("e1071")
# Load Library
library(caTools)
library(e1071)
library(questionr)

don<-base_tot_F_cr
head(don)
dim(don)


don <- rename.variable(don, "Conso", "Y")
head(don)

```


SVR modelisation train/test
```{r}

# train and test base BE
# éviter les valeurs manquantes
set.seed(1)
split=sample.split(don$Y, SplitRatio=2/3)
train=subset(don,split==TRUE)
test=subset(don,split==FALSE)


#Regression with SVM
svr_tot = svm(Y~.,don)
mse_svr_tot= mean((Y-predict(svr_tot,don))^2)

#Predict using SVM regression
pred_svr = predict(svr_tot, don)

#Overlay SVM Predictions on Scatter Plot
plot(don$Date, don$Y)
lines(don$Date, pred_svr, col="purple")



```


SVR names
```{r}
names(svr_tot)


```


SVR residuals
```{r}

plot(svr_tot$residuals)


```






