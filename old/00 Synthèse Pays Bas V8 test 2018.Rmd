---
title: "Synthese NL Pays Bas"
author: "Nhu-Nguyen Ngo"
date: "16 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

remplacer nom fichier
remplacer title
remplacer base: base_NL_F
remplacer suffixe: _NL
remplacer nom: Pays Bas


# PACKAGES
```{r}

# DONNEES VISUALISATION
library(stargazer)
library(ggplot2)
library(questionr)
library(dplyr)
library(lubridate)      # pour les dates
library(dummies)        # création de variables dummies (pour bestglm)
library(forecast)       # plot sympa des résidus
library(corrplot)       # plot de la matrice de corrélation
library(PerformanceAnalytics)


# TREE
library(rpart)				  # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)			# Enhanced tree plots
library(RColorBrewer)		# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree


# selection de variable
library(bestglm)
library(leaps)          # regsubset


# cross validation
library(stats)          # fonction glm
library(caret)

# CLUSTERING
library(cluster)
library(fastcluster)


# MODELES
library(ISLR)
library(glmnet)         # Poly, GAM
library(boot)           # boostraping
library(splines)
library(caTools)
library(randomForest)
library(e1071)          # SVR
library(nnet)           # reseau neurones
library(neuralnet)
library(mlbench)
library(gbm)
library(xgboost)

# paralellisation
library(doParallel)
library(foreach)


```



# BASE DE DONNEES ET FORMATAGE VARIABLES TRAIN TEST 
```{r}

# sur la base centrée réduite, sans les autres variables méteo
don <- base_NL_F_cr

dim(don)

# suppression des variales liées à la température teff, seuil, T00
don<-don[,-which(colnames(don)== "teff")] 
don<-don[,-which(colnames(don)== "seuil")] 
don<-don[,-which(colnames(don)== "T00")] 
head(don)

# creation des variables Y (variable cible) et X
don<- rename.variable(don, "Conso", "Y")
head(don)
dim(don)

# Creation de l'echantillon train 2/3 et test 1/3
# set.seed(1)
# dim<-nrow(don)
# split=2/3
# train=sample(dim,split*dim,replace=FALSE)

# Creation de l'echantillon train (avant 2018-01-05) et test (après 2018-01-05)
train <- which(don$Date < "2018-01-05")
don.train=don[train,]
don.test=don[-train,]

dim(don.train)
dim(don.test)
head(don.test)

# variables pour modèles polynomial et splines
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]
donYX.train=donYX[train,]
donYX.test=donYX[-train,]

# matrice avec que les variables prédictives
donX=don[, which(colnames(don)!="Y")]
donX.train=donX[train,]
donX.test=donX[-train,]

# model matrice sur base de test
test=model.matrix(Y~.,data=don[-train,])



names(don)

```

fonction mape Mean Absolute Percentage Error
```{r}
# Y variable cible
# model = fit du model
# don.test : base de test

fun_mape = function (Y,model, don.test) {
  error <- Y-predict(model,don.test)
  mape <- mean(abs(error/Y))*100
  return(mape)
}


```



# MODELES OLS
```{r}

# SANS INTERACTION ============================================================================================================================

# modèle linéaire entre Y  et Temp et les variables month, year, day
RL_NL <- lm(Y~  Temp + month + year + day, data=don.train)
pred_RL_NL=predict(RL_NL, newdata=don.test, se=T)
MSE_RL_NL= mean((Y.test-predict(RL_NL,don.test))^2)
MAPE_RL_NL = fun_mape(Y.test,RL_NL, don.test)


# résidus
plot(RL_NL)
checkresiduals(RL_NL)

# AVEC INTERACTION ============================================================================================================================


# modèle linéaire avec interaction entre Temp et les variables month, year, day ----------------------------------------------------------------
RLI_NL <- lm(Y~(month + year + day)*Temp ,data=don.train)
pred_RLI_NL=predict(RLI_NL, newdata=don.test, se=T)
MSE_RLI_NL= mean((Y.test-predict(RLI_NL,don.test))^2)
MAPE_RLI_NL = fun_mape(Y.test,RLI_NL, don.test)

# résidus
plot(RLI_NL)
checkresiduals(RLI_NL)


# modèle linéaire avec interaction multiples entre les variables (Temp  et ses lags t1 à t7) et les variables month, year, day ------------------
RLI_NL_multi <- lm(Y~(month + year + day)* (Temp + t1 + t2 + t3 + t4 + t5 + t6 + t7), data=don.train) 
pred_RLI_NL_multi=predict(RLI_NL_multi, newdata=don.test, se=T)
MSE_RLI_NL_multi= mean((Y.test-predict(RLI_NL_multi,don.test))^2)
MAPE_RLI_NL_multi = fun_mape(Y.test,RLI_NL_multi, don.test)

# résidus
plot(RLI_NL_multi)
checkresiduals(RLI_NL_multi)


# modèle linéaire avec interaction entre poly(Temp,2) et les autres variables ----------------------------------------------------------------
RLI_NL_P2<-lm(Y~ (month + year + day)*I(poly(Temp, 2)), data=don.train) 
pred_RLI_NL_P2=predict(RLI_NL_P2, newdata=don.test, se=T)
MSE_RLI_NL_P2= mean((Y.test-predict(RLI_NL_P2,don.test))^2)
MAPE_RLI_NL_P2 = fun_mape(Y.test,RLI_NL_P2, don.test)

# résidus
plot(RLI_NL_P2)
checkresiduals(RLI_NL_P2)

```



# MODELE POLYNOMIAL SIMPLE
Conso en fonction d'un polynome de Temp
```{r}

# choix du degré (5) du polynome choisi par CV (hold out et k_fold) en minimisant le MSE
d=20 # degré max de polynome à tester
err_poly_NL=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX.train)
  err_poly_NL[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot(err_poly_NL,ylab="MSE", main=' MSE Pays Bas selon le degré de polynome',pch=19,type='b')

poly_NL_deg=which.min(err_poly_NL) 
poly_NL_deg # 4


# MODELE RETENU
POLY_NL<- lm(formula=Y~poly(Temp,poly_NL_deg, raw=T), data=don.train)
pred_POLY_NL=predict(POLY_NL, newdata=don.test, se=T) 
MSE_POLY_NL= mean((Y.test-predict(POLY_NL,don.test))^2)
MAPE_POLY_NL = fun_mape(Y.test,POLY_NL, don.test)

# résidus
plot(POLY_NL)
checkresiduals(POLY_NL)

```



# MODELES SPLINES SIMPLE
Conso en fonction d'un spline de Temp
```{r}
# pour natural spline? CV pour choisir le degré de liberté (donc le nombre de noeuds) qui minimise le MSE
DF=15 # df max à tester
MSE_SP_NL_CV=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(Temp,df=i), data=don.train)
  MSE_SP_NL_CV[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# plot(sqrt(MSE_SP_NL_CV),ylab="MSE", main=' MSE Pays Bas selon le degré de liberté du spline',pch=19,type='b')

# On choisit le modele qui a la MSE la plus petite sur le test set
SP_NL_df=which.min(MSE_SP_NL_CV)
SP_NL_df # 3

attr(ns(X,df=SP_NL_df),"knots") # 2 noeuds


# modèle retenu: natural spline, df=3 (2 noeuds)
SP_NL <- lm ( Y~ ns(Temp, df = SP_NL_df), data=don.train)
pred_SP_NL=predict(SP_NL, newdata=don.test, se=T)
MSE_SP_NL= mean((Y.test-predict(SP_NL,don.test))^2)
MAPE_SP_NL = fun_mape(Y.test,SP_NL, don.test)

# résidus
plot(SP_NL)
checkresiduals(SP_NL)

```



# MODELE GAM SPLINE
Conso en fonction d'un spline sur Temp et la somme des variables month, year, day
```{r}
# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
MSE_GAM_NL_SP_CV=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(Temp,df=i) + month + year + day, data=don.train)
  MSE_GAM_NL_SP_CV[i] <- mean((Y.test-predict(model,don.test))^2)
  }


# Plot(MSE_GAM_NL_SP_CV, ylab="MSE", main=' MSE Pays Bas selon le degré de liberté du spline',pch=19,type='b')

# On choisit le DF qui a la MSE la plus petite sur le test set
GAM_NL_SP_df=which.min(MSE_GAM_NL_SP_CV)
GAM_NL_SP_df # 2
attr(ns(X,df=GAM_NL_SP_df),"knots") # 1 noeud # besoin de X=Temp

# modèle GAM retenu par MSe
GAM_NL_SP=lm(Y~ns(Temp,df=GAM_NL_SP_df) + month + year + day, data=don.train)
pred_GAM_NL_SP=predict(GAM_NL_SP, newdata=don.test, se=T)
MSE_GAM_NL_SP= mean((Y.test-predict(GAM_NL_SP,don.test))^2)
MAPE_GAM_NL_SP = fun_mape(Y.test,GAM_NL_SP, don.test)

# résidus
plot(GAM_NL_SP)
checkresiduals(GAM_NL_SP)

```



MODELE RANDOM FOREST
avec mtry, ntree et nodesize choisis par CV hold out
```{r}

# CHOIX DE MTRY PAR CV -----------------------------------------------------------------------------------
set.seed(1)
m=15 # mtry max à tester. 
MSE_RF_NL_mtry=rep(0,m)
for(i in 1:m) {
  set.seed(1)
  model <- randomForest(Y~., data=don.train, mtry = i)
  MSE_RF_NL_mtry[i] <- mean((Y.test-predict(model,don.test))^2)
  }

RF_NL_mtry= which.min(MSE_RF_NL_mtry) 
RF_NL_mtry  # 7
# plot(MSE_RF_NL_mtry, xlab="mtry", ylab="MSE", main="MSE selon mtry", type="b")



# CHOIX DE NTREE PAR CV  -----------------------------------------------------------------------------------
Ntree=seq(100,1000,by=100)  # ntree à tester
d=length(Ntree)
nb=1 # nombre de tests de cross validation
MSE_RF_NL_tree=rep(NA,d*nb)
res_ntree=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE

for (j in 1:nb) {

  for(i in 1:d) {
    set.seed(1)
    model <- randomForest(Y~., data=don.train, mtry = RF_NL_mtry, ntree=Ntree[i])
    MSE_RF_NL_tree[i+j-1] <- mean((don.test$Y-predict(model,don.test))^2)
  }

  res_ntree[j]=Ntree[which.min(MSE_RF_NL_tree)]

}

RF_NL_ntree = Ntree[which.min(MSE_RF_NL_tree)] # 300
RF_NL_ntree
# barplot(MSE_RF_NL_tree, xlab="ntree", ylab="MSE", ylim = range(MSE_RF_NL_tree), main="MSE selon ntree")



# CHOIX DE NODESIZE PAR CV  -----------------------------------------------------------------------------------
n_list=seq(from=1,to=10,by=1)  # nodesize à tester
d=length(n_list)
nb=1 # nombre de tests de cross validation
MSE_RF_NL_node=rep(NA,d*nb)
res_node=rep(NA,nb)   # résultat de la CV qui minimise la MSE

for (j in 1:nb) {
  
  for(i in 1:d) {
    set.seed(1)
    model <- randomForest(Y~., data=don.train,mtry = which.min(MSE_RF_NL_mtry), ntree=RF_NL_ntree, nodesize = n_list[i])
    MSE_RF_NL_node[i+j-1] <- mean((Y.test-predict(model,don.test))^2)
    names(MSE_RF_NL_node)[i] <- paste(as.character(n_list[i]),"node",sep="_")
  }

  res_node[j]=n_list[which.min(MSE_RF_NL_node)]

}

RF_NL_node = which.min(MSE_RF_NL_node) # 5
# barplot(MSE_RF_NL_node, xlab="ntree", ylab="MSE", ylim = range(MSE_RF_NL_node) , names = names(MSE_RF_NL_node) ,main="MSE selon nodesize",las=0)



# MODELE FINAL  ----------------------------------------------------------------------------------------------
RF_NL<-randomForest(Y~., mtry = RF_NL_mtry, ntree= RF_NL_ntree, nodesize = RF_NL_node ,data=don.train)
pred_RF_NL = predict(RF_NL, don.test)
MSE_RF_NL= mean((Y.test-predict(RF_NL,don.test))^2)
MAPE_RF_NL = fun_mape(Y.test,RF_NL, don.test)

# # résidus : la saisonnalité n'a pas été bien captée: le graphe des résidus est sinusoidal
res_RF_NL=don.test$Y-RF_NL$predicted
checkresiduals(res_RF_NL)

# # importances des variables
# # plot
# varImpPlot(RF_NL_fin)
# 
# # liste variable par importance
# RF_NL_fin$importance
# 
# # liste variable par importance ordonnée
# RF_NL_fin$importance[order(RF_NL_fin$importance[, 1], decreasing = TRUE), ]



```



MODELE SVR
```{r}
# Modèle
SVR_NL = svm(Y~.,don.train)
pred_SVR_NL = predict(SVR_NL, don.test)
MSE_SVR_NL= mean((Y.test-predict(SVR_NL,don.test))^2)
MAPE_SVR_NL = fun_mape(Y.test,SVR_NL, don.test)

# résidus
# plot(SVR_NL_tot$residuals)
res_SVR_NL=don.test$Y-pred_SVR_NL
checkresiduals(res_SVR_NL) # beaucoup d'autocorrélation, la distribution presque gaussienne mais pas centrée



```



# MODELE RESEAUX DE NEURONES
```{r}

# choix des paramètres size et decay par CV avec caret
controlList <- trainControl(method = "cv", number = 5)
tuneMatrix <- expand.grid(size = c(1, 2, 3, 4, 5, 6), decay = seq(from = 0, to = 0.5, by=0.1))

set.seed(1)
NN_NL_cv <- train(x = don.train[ , colnames(don.train) != "Y"],
                   y = don.train[ , colnames(don.train) == "Y"],
                   method = "nnet",
                   linout = TRUE,
                   trace = FALSE,
                   maxit = 100,
                   tuneGrid = tuneMatrix,
                   trControl = controlList)


#  MODELE RETENU
# print(NN_NL_cv$finalModel)
set.seed(1)
NN_NL <- NN_NL_cv$finalModel
pred_NN_NL <- predict(NN_NL, newdata = don.test)
MSE_NN_NL <- mean((pred_NN_NL - don.test$Y)^2)
MAPE_NN_NL = fun_mape(Y.test, NN_NL, don.test)

# tune values
NL_TV=NN_NL_cv$finalModel$tuneValue
str(NL_TV) #  size (5) et decay (0.5)


# résidus
res_NN_NL=Y.test-pred_NN_NL
checkresiduals(res_NN_NL[,1]) # la distribution n'est pas vraiment gaussienne

```


XGBOOST
```{r}
don <- base_NL_F_cr

# creation des variables Y (variable cible)
don<- rename.variable(don, "Conso", "Y")
head(don)

# nom des variables facteurs à convertir en dummies variables
ohe_vars <- names(don)[which(sapply(don, is.factor))]

# conversion en en dummies variables
dummies <- dummyVars(~., data = don)
don_ohe <- as.data.frame(predict(dummies, newdata = don))

# remplacer les variables facteurs par les dummies
don <- cbind(don[, -c(which(colnames(don) %in% ohe_vars))], don_ohe)

# Creation de l'echantillon train (avant 2018-01-05) et test (après 2018-01-05)
train <- which(don$Date < "2018-01-05")
Xtrain <- don[train, ]
Xtest <- don[-train, ]

# modelisation
XGB_NL <- xgboost(data = data.matrix(Xtrain), label = Xtrain$Y,
  booster = "gbtree", objective = "reg:linear", eval_metric = "rmse",
  learning_rate = 0.05, 
  subsample = 0.5, seed = 1, # subsample default value=1. Setting to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting. 
  silent = 1, nrounds = 500, verbose = 0)

# prédiction
pred_XGB_NL= predict(XGB_NL, data.matrix(Xtest))
MSE_XGB_NL=mean((Y.test-pred_XGB_NL)^2)
MAPE_XGB_NL = fun_mape(Y.test, XGB_NL, data.matrix(Xtest))

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="XGB Pays Bas" )
lines(don.test$Date,pred_XGB_NL, col="purple") 

# résidus
checkresiduals(Y.test-pred_XGB_NL)

```



SYNTHESE DES MODELES 

# MAPE plot
```{r}

# comparaison des MAPE entre les modèles 
MAPE_NL_tot=c(MAPE_RL_NL, MAPE_RLI_NL, MAPE_RLI_NL_multi, MAPE_RLI_NL_P2, MAPE_POLY_NL, MAPE_SP_NL, MAPE_GAM_NL_SP, MAPE_RF_NL, MAPE_SVR_NL, MAPE_NN_NL, MAPE_XGB_NL)

# graphe des MAPE
graph<-barplot(MAPE_NL_tot, xlab="modèles", ylab="MAPE %", main="MAPE des modèles Pays Bas",las=0)
axis(1, labels=c("RL", "RLI","multi", "P2" ,"Poly" ,"SP", "GAM" ,"RF", "SVR", "NN", "XGB"), at = graph)

```


```{r}
# comparaison des MAPE entre les modèles
MAPE_NL_tot=c(MAPE_GAM_NL_SP, MAPE_RF_NL, MAPE_SVR_NL, MAPE_NN_NL, MAPE_XGB_NL)

# graphe des MAPE
graph<-barplot(MAPE_NL_tot, xlab="modèles", ylab="MAPE %", main="MAPE des modèles Pays Bas",las=0)
axis(1, labels=c("GAM" ,"RF", "SVR", "NN", "XGB"), at = graph)


```


# MSE plot
```{r}

# comparaison des MSE entre les modèles 
MSE_NL_tot=c(MSE_RL_NL, MSE_RLI_NL, MSE_RLI_NL_multi, MSE_RLI_NL_P2, MSE_POLY_NL, MSE_SP_NL, MSE_GAM_NL_SP, MSE_RF_NL, MSE_SVR_NL, MSE_NN_NL, MSE_XGB_NL)

# graphe des MSE
graph<-barplot(MSE_NL_tot, xlab="modèles", ylab="MSE", main="MSE des modèles Pays Bas",las=0)
axis(1, labels=c("RL", "RLI","multi", "P2" ,"Poly" ,"SP", "GAM" ,"RF", "SVR", "NN", "XGB"), at = graph)

```

# MSE minimal
```{r}
which.min(MSE_NL_tot) # c'est le modèle XGB qui présente la plus petite MSE
```

# MSE plots meilleurs modèles 
```{r}

# comparaison des MSE entre les meilleurs modèles
MSE_NL_r=c(MSE_GAM_NL_SP, MSE_RF_NL, MSE_SVR_NL, MSE_NN_NL, MSE_XGB_NL)

# graphe des MSE
graph<-barplot(MSE_NL_r, xlab="modèles", ylab="MSE",ylim=c(MSE_XGB_NL, MSE_GAM_NL_SP) ,main="MSE des modèles", las=0)
axis(1, labels=c("GAM_SP" ,"RF", "SVR", "NN", "XGB"), at = graph)


```


objet RF et SVR pas reconnu par stargazer
```{r}
# on enlève RLI_P2 ainsi que POLY et Splines simples dont les MSE est plus de 2 fois suppérieure à celle des autres 
stargazer(RL_NL, RLI_NL, RLI_NL_multi, RLI_NL_P2, GAM_NL_SP, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("RL", "RLI", "multi","P2","GAM"), keep = c("Date"), model.names = TRUE, single.row = TRUE)

# le R² ajusté est le plus élevé pour RLI Multi
# le residual error est le plus faible pour RLI Multi
# F-stat est le plus élevé pour GAM

```




# graphe des valeurs prédites selon les modèles
```{r}

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles Pays Bas" )
lines(don.test$Date,pred_RL_NL$fit, col="purple") 
lines(don.test$Date,pred_RLI_NL$fit, col="orange") 
lines(don.test$Date,pred_RLI_NL_multi$fit, col="cyan") 
lines(don.test$Date,pred_POLY_NL$fit, col="pink") 
lines(don.test$Date,pred_SP_NL$fit, col="green") 
lines(don.test$Date,pred_GAM_NL_SP$fit, col="bisque")
lines(don.test$Date, pred_RF_NL, col="red") 
lines(don.test$Date, pred_SVR_NL, col="blue") 
lines(don.test$Date, pred_NN_NL, col="aquamarine") 
lines(don.test$Date, pred_XGB_NL, col="tomato") 

```

```{r}
# graphes avec les 3 meilleurs modèles GAM, RF, SVR
plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles NN(aquamarine) RF (red) SVR (blue)" )
lines(don.test$Date, pred_NN_NL, col="aquamarine") 
lines(don.test$Date, pred_RF_NL, col="red") 
lines(don.test$Date, pred_SVR_NL, col="blue")



```


```{r}
plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles SVR (blue)" )
lines(don.test$Date, pred_SVR_NL, col="blue")


plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles XGB (tomato)" )
lines(don.test$Date, pred_XGB_NL, col="tomato")  

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles NN(aquamarine)" )
lines(don.test$Date, pred_NN_NL, col="aquamarine") 


```


Résidus XGB
```{r}
checkresiduals(Y.test-pred_XGB_NL)

```

Résidus SVR
```{r}
res_SVR_NL=don.test$Y-pred_SVR_NL
checkresiduals(res_SVR_NL)
# résidus moyens, avec quelques autocorrélations et une distribution, non gaussienne 

```

Résidus réseaux de neurones
```{r}
res_NN_NL=Y.test-pred_NN_NL
checkresiduals(res_NN_NL[,1])
# résidus pas bons, avec saisonnalité, beaucoup d'autocorrélation

```



