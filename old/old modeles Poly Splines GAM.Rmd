---
title: "Polynomes Splines GAM"
author: "Nhu-Nguyen"
date: "14 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

REGRESSION POLYNOMIALE ENTRE Y=CONSO ET X=Temp

Avec la validation croisée train/test, on trouve que le degré du polynome qui présente la plus petite MSE est 5.
La valeur de R² ajustée n'est cependant pas très élevée
Adjusted R-squared:  0.08201 
F-statistic: 124.3
le graphe des résidus n'est pas satisfaisant


Avec la validation croisée K-fold, l'erreur la plus petite est pour le polynome de degré 6
Multiple R-squared:  0.08271,	Adjusted R-squared:  0.08192 
F-statistic: 103.6 on 6 and 6892 DF,  p-value: < 2.2e-16

POLY SUR BASE TOTALE
```{r}

# POLY SUR BASE TOTALE

library(glmnet)
library(boot)
library(stargazer)

# sur la base totale avec tous les pays, centrée réduite, sans les variables autres que météo
don<-base_F_6P_cr

# definition variables Y et X
library(questionr)
don <- rename.variable(don, "Conso", "Y")
head(don)
dim(don)

# regression polynomiale entre Y=conso et X=Temp
Y=don$Y
X=don$Temp
donYX=data.frame(cbind(Y,X))
head(donYX)

# CROSS VALIDATION HOLD OUT TRAIN/TEST
set.seed(1)
dim<-nrow(donYX)
train<-sample(dim,2*dim/3)
test=donYX[-train,]

d=15 # degré max de polynome à tester
mse.poly=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX[train,])
  mse.poly[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set, ici c'est pour le degré 5
plot(sqrt(mse.poly),ylab="MSE", main='Root MSE selon le degré de polynome',pch=19,type='b')


```

```{r}
which.min(mse.poly) # degré 10
```



```{r}
#modèle poly10 sur base totale
poly10_total <- lm(formula=Y~poly(X,10, raw=T), data=don)
poly10_total_sum<- summary(poly10_total)
# le graphe des résidus vs fitted est très structuré, avec 3 groupes de données
plot(poly10_total)



```


```{r}
# CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
cv.error=as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX)
cv.error[i]<-cv.glm(donYX,glm.fit,K=10)$delta[1]
}

plot(cv.error, type="l")


```


```{r}
which.min(cv.error) # ici c'est avec le degré 6 que l'erreur est la plus faible
```


```{r}

poly6_total <- lm(formula=Y~poly(X,6, raw=T), data=don)
poly6_total_sum<- summary(poly6_total)
plot(poly6_total)


# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
# library(boot)
# d=10 # degré de polynome 
# cv.error=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~poly(X,i),data = donYX) 
#   cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }

# plot(cv.error, type="l") 




```


```{r}

# COMPARAISON DES MODELES
# issu de la validation hold out train/test: degré 10
poly10_total<- lm(formula=Y~poly(X,10, raw=T), data=don)

#issu de la validation k-fold: degré 6
poly6_total<- lm(formula=Y~poly(X,6, raw=T), data=don)

#comparaison des modèles linéaire total avec poly10 et poly6
# R² ajusté très faible par rapport au modèle linéaire total sur tous les pays (0.86)
# peu de différence dans le résidual sdt error poly10=0.955et poly6=0.956, nettement plus élevé que celui du modèle linéaire total (0.374)
# F stat beaucoup plus faible que pour modèle linéaire total (3036), vs poly10 (67) et poly6 (110)
stargazer(RL_F1,poly10_total, poly6_total, type='text', flip=TRUE, title="Results", keep=c("Date"),  column.labels = c("RL", "poly10","poly6"))

# s'il fallait retenir un modèle polynomial, cela serait celui de degré 6
# toutefois, il semble peu intéressant de retenir un modèle uniquement polynomial sur la température


```


SPLINES sur base totale

```{r}

# SPLINE SUR BASE TOTALE

library(splines)
library(stargazer)

# sur la base totale avec tous les pays, centrée réduite
don<-base_F_6P_cr

# definition variables Y et X
library(questionr)
don <- rename.variable(don, "Conso", "Y")
head(don)

# creation des variables Y et X
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
str(donYX)
nrow(donYX)
length(X)
length(Y)

# data set train et test
set.seed(1)
d<-nrow(donYX)
train<-sample(d,2*d/3)
test=donYX[-train,]


#basic splines bs, natural splines ns
# noeuds=c(,)
# l'option df produit des splines avec des noeuds placés sur les quantiles 25 50 et 75
attr(bs(X,df=6),"knots") #donne le noeuds issus de df
bs_total=lm(Y~bs(X,df=6), data=donYX[train,])
pred_bs_total=predict(bs_total, newdata=list(X=test$X), se=T)
# names(pred) # fit"            "se.fit"         "df"             "residual.scale"
# str(pred)

# le graphe des résidus vs fitted est très structuré, avec 3 groupes distincts de données
plot(bs_total) # on observe des résidus vs fitted très structuré avec 3 groupes distincts



```

```{r}
plot(test$X,test$Y, xlab = "Temp", ylab="Conso") # on retrouve 3 groupes de données
points(test$X, pred_bs_total$fit, col="blue") 

# Remarques:
# les prédictions n'ont été faites que pour le groupe intermédiaire
# cela conforte l'idée de faire un modèle par pays

plot(X,Y, xlab = "Temp", ylab="Conso")


# modèle sur toutes les données de la base totale
ns_total=lm(Y~ns(X,df=3), data=donYX) #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
pred_ns_total=predict(ns_total, newdata=list(X=donYX$X), se=T)
# plot(SP_total)

# graphe de conso vs date
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="Spline sur la base totale" )
lines(don$Date,pred_ns_total$fit, col="blue") 
# Remarques:
# les prédictions n'ont été faites que pour le groupe intermédiaire. Il y a des pays qui ne sont pas prédits, ceux qui ont des niveaux de consommation plus élevés avec plus d'amplitude: probalement les pays où il fait plus froid.
# cela conforte l'idée de faire des groupes de pays et un modèle par groupe de pays et/ou par pays
# c'est bizarre, il y a des prédictions sur la période 2012 et 2015 où il n'y a pas de données réelles
```


```{r}

```



POLYNOME SUR BASE BELGIQUE
```{r}
# POLY SUR BELGIQUE

library(glmnet)
library(boot)
library(stargazer)

# sur la base BELGIQUE
don<-base_BE_F_cr

# definition variables Y et X
library(questionr)
don <- rename.variable(don, "Conso", "Y")
head(don)
dim(don)

# regression polynomiale entre Y=conso et X=meteo
Y=don$Y
X=don$Temp
donYX=data.frame(cbind(Y,X))
head(donYX)

# CROSS VALIDATION HOLD OUT TRAIN/TEST
set.seed(1)
dim<-nrow(donYX)
train<-sample(dim,2*dim/3)
test=donYX[-train,]

d=10 # degré max de polynome à tester
mse.poly=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX[train,])
  mse.poly[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set, ici c'est pour le degré 5
plot(sqrt(mse.poly),ylab="MSE", main='Root MSE selon le degré de polynome',pch=19,type='b')


```


```{r}

which.min(mse.poly) # degré 5

#modèle poly5 sur base BE
poly5_BE<- lm(formula=Y~poly(X,5, raw=T), data=don)
poly5_BE_sum<- summary(poly5_BE)
mse_poly5_BE= mean((Y-predict(poly5_BE,don))^2)
# le graphe des résidus vs fitted a moins de structure
plot(poly5_BE)

```

```{r}

# CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
cv.error=as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX)
cv.error[i]<-cv.glm(donYX,glm.fit,K=10)$delta[1]
}

plot(cv.error, type="l")

```

```{r}
which.min(cv.error) # ici c'est avec le degré 5 que l'erreur est la plus faible

#modèle poly5 sur base BE
poly5_BE<- lm(formula=Y~poly(X,5, raw=T), data=don)
poly5_BE_sum<- summary(poly5_BE)
mse_poly5_BE= mean((Y-predict(poly5_BE,don))^2)
# le graphe des résidus vs fitted a moins de structure
plot(poly5_BE)

```



```{r}

# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
# library(boot)
# d=10 # degré de polynome 
# cv.error=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~poly(X,i),data = donYX) 
#   cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }
# plot(cv.error, type="l") 


# COMPARAISON DES MODELES
# issu de la validation hold out train/test: degré 5
poly5_BE<- lm(formula=Y~poly(X,5, raw=T), data=don)
poly5_BE_sum<- summary(poly5_BE)
mse_poly5_BE= mean((Y-predict(poly5_BE,don))^2)

#issu de la validation k-fold: degré 5
poly5_BE<- lm(formula=Y~poly(X,5, raw=T), data=don)
poly5_BE_sum<- summary(poly5_BE)
mse_poly5_BE= mean((Y-predict(poly5_BE,don))^2)

#comparaison des modèles linéaire total avec polY5
# R² ajusté à 0.906 pour poly5, plus petit par rapport au modèle linéaire BE (0.965)
# résidual sdt error beaucoup plus élevé que dans RL (0.194), poly5 (0.32)
# F stat plus élevé que pour poly5 (2236) que pour modèle linéaire (1117)
stargazer(RL_BE1,poly5_BE, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","poly5"))

# # en comparant les MSE, celui de poly7 est supérieur à celui de poly9
# diff_poly_BE=mse_poly7_BE - mse_poly9_BE
# diff_poly_BE
# 
# # nous retiendrons poly9 pour BE sur le critère du MSE
# poly_BE<- lm(formula=Y~poly(X,9, raw=T), data=don)
# poly_BE_sum<- summary(poly_BE)
# mse_poly_BE= mean((Y-predict(poly_BE,don))^2)


```


```{r}

```



SPLINES SUR Belgique Conso en fonction de la température

```{r}
# SPLINE SUR BELGIQUE

library(splines)
library(stargazer)
library(questionr)

don<-base_BE_F_cr
don <- rename.variable(don, "Conso", "Y")

#creation des variables Y et X
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
str(donYX)
nrow(donYX)
length(X)
length(Y)

# data set train et test
set.seed(1)
d<-nrow(donYX)
train<-sample(d,2*d/3)
test=donYX[-train,]

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour natural splines
```{r}
# CHOIX DU DEGRE DE LIBERTE df (et donc du nombre de noeuds) par cross validation HOLD OUT TRAIN/TEST 
# l'option df produit des splines avec des noeuds placés sur les quantiles
# on n'obtient pas les mêmes noeuds en bs et ns, pour un même degré de liberté
# attr() pour avoir les noeuds issus de df

# noeuds avec basic splines
attr(bs(X,df=3),"knots") # pas de noeud
attr(bs(X,df=4),"knots") # un seul noeud à 50% = 2 intervalles + 2 frontières min et max
attr(bs(X,df=5),"knots") # 2 noeuds à 1/3 et 2/3 = 3 intervalles + 2 frontières min et max
attr(bs(X,df=6),"knots") # 3 noeuds à 25%, 50% et 75% = 4 intervalles + 2 frontières min et max

# noeuds avec natural splines
attr(ns(X,df=1),"knots") #  pas de noeud
attr(ns(X,df=2),"knots") #  un seul noeud à 50% 
attr(ns(X,df=3),"knots") #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
attr(ns(X,df=4),"knots") #  3 noeuds à 25% (5.8), 50% (10.2),75% (15.5)
attr(ns(X,df=5),"knots") #  4 noeuds à 20% (4.9), 40% (8.5),60% (12.2), 80% (16.5)


# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
mse_SP_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(X,df=i), data=donYX[train,])
  mse_SP_ns[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse_SP_ns),ylab="MSE", main='Root MSE selon le degré de liberté du spline',pch=19,type='b')


```

SPLINES choix du degré de liberté/noeuds résultats
```{r}
which.min(mse_SP_ns)
# c'est le modèle avec un degré de liberté 3 qui a la plus petite MSE

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines : ne marche pas
```{r}
# pour basic spline, recherche degré df qui minimise le MSE => ne fonctionne pas
# DF=15 # df max à tester ne marche pas avec bs
# mse_SP_bs=rep(0,DF)
# for(i in 4:DF) {
#   model <- lm(Y~bs(X,df=i), data=donYX[train,])
#   ms_.SP_bs[i] <- mean((test$Y-predict(model,test))^2)
#   }
# 
# # plot les RMSE des modeles sur le training et sur le test set
# # On choisit le modele qui a la RMSE la plus petite sur le test set
# plot(sqrt(mse_SP_bs),ylab="MSE", main='Root MSE selon le degré de liberté du spline',pch=19,type='b')
# which.min(mse_SP_bs)

```

SPLINES choix entre natural splines et basic splines par CV hold out 
```{r}
# CHOIX ENTRE BASIC SPLINES ET NATURAL SPLINES, celui qui minimise le MSE

#natural splines ns
# ns() ne marche que si les variables sont numériques. Les variables qualitatives seront transformées en dummy variables
attr(ns(X,df=3),"knots")  # noeuds à 33% et 66%
fit_ns_BE=lm(Y~ns(X,df=3), data=donYX[train,])
plot(fit_ns_BE)
mse.SP_ns <- mean((test$Y-predict(fit_ns_BE,test))^2)
# pred_ns_BE=predict(fit_ns_BE, newdata=list(X=test$X), se=T)

#basic splines bs: on prend le df qui donne les mêmes noeuds que natural spline 
attr(bs(X,df=5),"knots") # noeuds à 33% et 66%
fit_bs_BE=lm(Y~bs(X,df=5), data=donYX[train,])
plot(fit_bs_BE)
mse.SP_bs <- mean((test$Y-predict(fit_bs_BE,test))^2)
# pred_bs_BE=predict(fit_bs_BE, newdata=list(X=test$X), se=T)

diff_bs_ns=mse.SP_bs-mse.SP_ns
diff_bs_ns # mse.SP_bs> mse_bs_ns 
# => avec les mse, on choisirait ns

# le modèle spline retenu est natural spline, degré 3
# le graphe des résidus vs fitted semble peu structuré
fit_ns_BE=lm(Y~ns(X,df=3), data=donYX[train,])
plot(fit_ns_BE)
mse.SP_ns <- mean((test$Y-predict(fit_ns_BE,test))^2)


```


SPLINES choix entre natural splines et basic splines par CV hold out comparaison
```{r}

#comparaison des stats des résultats entre basic et natural splines
stargazer(fit_bs_BE, fit_ns_BE, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("bs", "ns"))
# => avec les stat des modèles, choix de ns car F-stat plus grand à 2400 (bs=1444). Le R² ajusté et residual std error sont égaux entre ns et bs


```


SPLINES choix entre natural splines et basic splines par CV hold out résultats
```{r}

# modèle spline sur toute la base BE
# on retient spline ns avec df=3 trouvé par cross validation hold out
SP_BE=lm(Y~ns(X,df=3), data=donYX) #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
pred_SP_BE=predict(SP_BE, newdata=list(X=donYX$X), se=T)
mse_SP_BE= mean((Y-predict(SP_BE,donYX))^2)
plot(SP_BE) # graphe des résidus vs fitted n'a quasiment pas de structure


```


SPLINES graphes et smooting splines
```{r}
# graphes de conso vs température
plot(test$X,test$Y, xlab = "meteo", ylab="Conso")
points (test$X,pred_ns_BE$fit, col="blue") 

# graphe de conso vs date
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="Spline sur Belgique" )
lines(don$Date,pred_SP_BE$fit, col="blue") 


# SMOOTHING SPLINE
SM_BE=smooth.spline(don$Y,don$X,df=3) # on spécifie df=6 et le lambda est déterminé de sorte à obtenir df=6
SM_BE_cv=smooth.spline(don$Y,don$X,cv=TRUE) # lambda est choisi par cross validation

plot(SM_BE) # forme en V arrondie
plot(SM_BE_cv) # sinusoide

# #comparaison des résultats entre Spline df3, smoothing spline df3 et smoothing spline avec lambda par cv
# stargazer(SP_BE, SM_BE, SM_BE_cv, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("SP", "SM", "SMcv"), model.names = TRUE)
```




GAM sur la Belgique base et variables
```{r}

# GAM SUR BELGIQUE

# install.packages("gam")
# library(gam)

library(splines) 

don<-base_BE_F_cr
don <- rename.variable(don, "Conso", "Y")

#creation des variables Y et X
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
str(donYX)
nrow(donYX)
length(X)
length(Y)

# data set train et test
set.seed(1)
d<-nrow(donYX)
train<-sample(d,2*d/3)
test=donYX[-train,]
```


GAM détermination du polynome par CV K-fold
```{r}

# détermination du degré du polynome par cross validation, 
# trop de variables, on enlève progressivement jusqu'à ce que cela fonctionne: seuil, T00, Date, year, quarter, season, sinus, cosinus, weekend
library(boot)
d=15 # degré de spline à tester
cv.error=rep(0,d)
for (i in 1:d) { 
  glm.fit=glm(Y~poly(Temp,i) + day_length + teff + month + day + holidays + jc + lagholidays + leadholidays,data = don) 
  cv.error[i]=cv.glm(don,glm.fit, K=10)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(cv.error, type="l", main="cv.error selon degré polynome") 

```

GAM détermination du polynome par CV K-fold résultats
```{r}
which.min(cv.error) # degré 7

# modèle GAM avec polynôme degré 7 sur la température 
# sur toute la base_BE
gam_BE=lm(Y~poly(Temp,7) + day_length + teff + month + day + holidays + jc + lagholidays + leadholidays,data = don) 
pred_gam_BE=predict(gam_BE, newdata=don, se=T)
summary(gam_BE)


```

GAM résidus
```{r}
mse_gam_BE= mean((Y-predict(gam_BE,don))^2)
plot(gam_BE) # le graphe des résidus n'a quasiment pas de structure avec une forte concentration dans les petites valeurs de fitted
```


GAM valeurs prédites
```{r}
# graphe des valeurs prédites par GAM sur la Belgique
plot(don$Date, don$Y, xlab = "date", ylab="Conso", main="GAM sur la Belgique" )
lines(don$Date,pred_gam_BE$fit, col="yellow")

```



