---
title: "Exploration données 3"
author: "Nhu-Nguyen"
date: "21 mars 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

EXPLORATIOON DES DONNEES SUR BASE TOTALE

La base totale sans valeurs manquantes (base.nona) comprend 6899 observations. 
Les 4 variables initiales sont:
- id: identification des pays
- conso: la consommation d'électricité par pays
- date: du 08/01/2015 et finit au 16/03/2018
- météo: température du jour

Nous avons créé 9 variables supplémentaires:
- jours de la semaine
- mois
- tmoy1 à tmoy7: températures retardées

Le graphe de la conso (Y) en fonction de la température fait apparaitre 3 groupes de données avec des comportements différents

Le graphe de la conso (Y) en fonction de la date fait apparaitre 3 groupes de données avec des comportements différents: 
- un groupe avec de fortes valeurs de conso et de fortes variations
- un groupe avec des valeurs moyennes de conso et des variations moyennes
- un groupe avec des valeurs faibles de conso et des faibles variations
L'évolution de la conso semble saisonnier.

Il faudrait standardiser les données 

EXPLORATION DES DONNEES par pays
La base totale concerne 6 pays, avec des tailles différentes:
-BE: 1149 observations
-DE: 1159 observations
-ES: 791 observations
-FR: 1523 observations
-NL:1160 observations
-UK: 1165 observations
 
 La visualisation de quelques graphes type (consommation vs température) et boxplot de la température suggèrent des différences selon les pays.
 
 Nous proposerons donc des modèles par pays pour tenir compte de ces différences, qui peuvent provenir:
 - de climat différents
 - qui engendrent des normes de constructions différentes: dans les pays plus froids, les maisons sont mieux isolées, ce qui peut réduire la consommation d'électricité
 - des pratiques ou résistance au froid différentes
 

```{r}
library(stargazer)

 # graohe de la conso en fonction de la température
plot(base.nona$meteo,base.nona$conso) # 3 groupes de données distincts
plot(base.nona$conso,base.nona$meteo)

# graphe de la conso selon la date
plot(base.nona$Date,base.nona$conso) # 3 groupes de données distincts

# graphe conso en fonction du mois: nb les mois ne sont plus rangés de janvier à décembre
plot(base.nona$mois,base.nona$conso)

plot(base.nona$mois,base.nona$meteo)


# PAR PAYS
summary(base_BE)
summary(base_DE)
summary(base_ES)
summary(base_FR)
summary(base_NL)
summary(base_UK)

par(mfrow=c(3,2))
plot(base_BE$conso,base_BE$meteo)
plot(base_DE$conso,base_DE$meteo)
plot(base_ES$conso,base_ES$meteo)
plot(base_FR$conso,base_FR$meteo)
plot(base_NL$conso,base_NL$meteo)
plot(base_UK$conso,base_UK$meteo)

par(mfrow=c(3,2))
boxplot(base_BE$meteo)
boxplot(base_DE$meteo)
boxplot(base_ES$meteo)
boxplot(base_FR$meteo)
boxplot(base_NL$meteo)
boxplot(base_UK$meteo)

par(mfrow=c(3,2))
boxplot(base_BE$conso)
boxplot(base_DE$conso)
boxplot(base_ES$conso)
boxplot(base_FR$conso)
boxplot(base_NL$conso)
boxplot(base_UK$conso)

```

REGRESSION LINEAIRE

Sur l'ensemble de la base (avec tous les pays), les variables significatives sont celles de:
- la température, ce qui est logique
- des pays (UK, ES, FR, DE, BE): ce qui plaide pour un modèle par pays. A noter que le pays NL n'apparait pas
- de certains mois: les mois d'hiver (novembre, décembre, février,janvier, mars) avec un coefficient positif et le mois de mai (moins significatif, avec un coefficient négatif)
- de certains jours correspondant au week end (samedi et dimanche)

NB: les températures retardées n'apparaissent pas

Le graphe des résidus montre un structure, le modèle devrait pouvoir être amélioré.

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   67644311   35982950   1.880  0.06016 .  
idUK        -105793674    2481655 -42.630  < 2e-16 ***
idES         -87897529    3424100 -25.670  < 2e-16 ***
idFR         -94410874    2543731 -37.115  < 2e-16 ***
idDE        -104845284    2489183 -42.120  < 2e-16 ***
idBE         274224254    2486399 110.290  < 2e-16 ***
meteo         -2453494     461937  -5.311 1.12e-07 ***
moisDec       20564769    3807358   5.401 6.84e-08 ***
moisFeb       28171803    3836556   7.343 2.33e-13 ***
moisJan       31269376    3847650   8.127 5.18e-16 ***
moisMar       15719202    3666531   4.287 1.83e-05 ***
moisMay       -9080947    3807695  -2.385  0.01711 *  
moisNov       14864326    3696175   4.022 5.84e-05 ***
jourSat       -7257008    2693413  -2.694  0.00707 ** 
jourSun       -8602780    2688577  -3.200  0.00138 ** 

Residual standard error: 59620000 on 6867 degrees of freedom
  (30361 observations deleted due to missingness)
Multiple R-squared:  0.851,	Adjusted R-squared:  0.8503 
F-statistic:  1265 on 31 and 6867 DF,  p-value: < 2.2e-16


En enlevant les variables de températures retardées, on améliore la F statistics à 1650 (vs 1265 avant le modèle linéaire total) avec peu de perte sur le R2 ajusté à 0.8507 (vs 0.8503 dans le modèle linéaire total)

On retrouve les mêmes variables significatives, avec en plus la variable date (qui n'était pas significative dans le modèle total):
Date              4063       2072   1.961  0.04990 *  
idUK        -105971509    2478021 -42.765  < 2e-16 ***
idES         -88338844    3185104 -27.735  < 2e-16 ***
idFR         -94808960    2470906 -38.370  < 2e-16 ***
idDE        -105099413    2485913 -42.278  < 2e-16 ***
idBE         275267338    2482190 110.897  < 2e-16 ***
meteo         -2982329     250469 -11.907  < 2e-16 ***
moisDec       20638470    3736988   5.523 3.46e-08 ***
moisFeb       28303540    3706756   7.636 2.55e-14 ***
moisJan       31349425    3637772   8.618  < 2e-16 ***
moisMar       15900123    3565189   4.460 8.33e-06 ***
moisMay       -9109448    3788046  -2.405  0.01621 *  
moisNov       14855390    3698271   4.017 5.96e-05 ***
jourSat       -7195591    2677924  -2.687  0.00723 ** 
jourSun       -8580437    2677512  -3.205  0.00136 ** 

Residual standard error: 59720000 on 6922 degrees of freedom
  (30313 observations deleted due to missingness)
Multiple R-squared:  0.8512,	Adjusted R-squared:  0.8507 
F-statistic:  1650 on 24 and 6922 DF,  p-value: < 2.2e-16

Le graphe des résidus montre un structure, le modèle devrait pouvoir être amélioré.

```{r}
# modeles lineaires avec jours, mois et les temperatures retardees

#sur la base totale
reglin_total<-lm(conso~.,data=base)
reglin_total.sum<-summary(reglin_total)
reglin_total.sum
plot(reglin_total)

# sur la base totale, avec seulement les variables significatives date, id, mois et jour
base1<-base[,c(1:6)]
head(base1)

reglin1<-lm(conso~.,data=base1)
reglin1.sum<-summary(reglin1)
reglin1.sum
plot(reglin1)

#visualistion des résultats avec stargazer
stargazer(reglin_total, type='text', flip=TRUE)

# récupération uniquement des coef
str(coef(summary(reglin_total)))
head(coef(summary(reglin_total)))

# uniquement les coef estimés et sd error
model.summary = coef(summary(reglin_total))[, 1:2]
stargazer(model.summary, type='text', flip=TRUE)

```


VISUALISATION DES RESULTATS DES MODELES
```{r}
library(stargazer)

# regression lineaire avec tous les pays
stargazer(reglin_total, type='text', flip=TRUE)

# récupération uniquement des coef
str(coef(summary(reglin_total)))
head(coef(summary(reglin_total)))

# uniquement les coef estimés et sd error
model.summary = coef(summary(reglin_total))[, 1:2]
stargazer(model.summary, type='text', flip=TRUE)

# modèles par pays avec toutes les variables
# les 3 pays retenus
stargazer(reglin_BE,reglin_DE,reglin_NL,type='text', flip=TRUE)

# les 3 pays non étudiés
stargazer(reglin_ES,reglin_FR,reglin_UK,type='text', flip=TRUE)


# modèles par pays avec uniquement les variables significatives
# les 3 pays retenus
stargazer(reglin_BE1,reglin_DE1,reglin_NL1,type='text', flip=TRUE)

# les 3 pays non étudiés
stargazer(reglin_ES1,reglin_FR1,reglin_UK1,type='text', flip=TRUE)

```




UN MODELE LINEAIRE PAR PAYS: BELGIQUE

Le modèle linéaire sur toutes les variables (yc températures retardées) fait ressortir les variables significatives suivantes, 
- les mêmes que celles sur la base totale (avec tous les pays): meteo, les mois d'hiver (novembre, décembre, janvier, février, mars), le jours du we (samedi et dimanche)
- de nouvelles variables: mois d'octobre, septembre, mercredi et jeudi, date et température retardée d'un jour et de 7 jours

Le R2 ajusté est meilleur à 0.9609 mais la F-Stat est moins élevé à 1088.

Le graphe des résidus présente une légère structure, moins prononcée que dans le modèle avec tous les pays

             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 154518133   48692765   3.173 0.001548 ** 
Date            22718       2860   7.944 4.71e-15 ***
meteo       -11247435     481953 -23.337  < 2e-16 ***
moisDec      93713639    4888240  19.171  < 2e-16 ***
moisFeb     119339602    4942871  24.144  < 2e-16 ***
moisJan     132155536    4903878  26.949  < 2e-16 ***
moisMar      62871738    4725285  13.305  < 2e-16 ***
moisMay     -23102305    5032786  -4.590 4.92e-06 ***
moisNov      74987132    4807214  15.599  < 2e-16 ***
moisOct      12496162    4829618   2.587 0.009795 ** 
moisSep     -16174104    5379920  -3.006 0.002702 ** 
jourSat     -31944182    3501222  -9.124  < 2e-16 ***
jourSun     -34253828    3501607  -9.782  < 2e-16 ***
jourThu       8989655    3507506   2.563 0.010507 *  
jourWed      10945345    3523386   3.106 0.001941 ** 
tmoy1        -2378481     643826  -3.694 0.000231 ***
tmoy7        -1456679     474085  -3.073 0.002173 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 31790000 on 1125 degrees of freedom
Multiple R-squared:  0.9618,	Adjusted R-squared:  0.9609 
F-statistic:  1088 on 26 and 1125 DF,  p-value: < 2.2e-16



En enlevant les variables non significatives, on améliore la F-stat à 1290 (vs 1088) en dégradant le R2 ajusté à 0.9502 (vs 0.9609 dans le modèle total). Le graphe des résidus présente encore une légère structure. Le modèle devrait pouvoir être amélioré.

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 147023870   49698978   2.958 0.003158 ** 
Date            22721       2919   7.783 1.59e-14 ***
meteo       -11084265     486328 -22.792  < 2e-16 ***
moisDec      96302064    4977068  19.349  < 2e-16 ***
moisFeb     123643681    5009016  24.684  < 2e-16 ***
moisJan     137018347    4957570  27.638  < 2e-16 ***
moisMar      66047639    4802222  13.754  < 2e-16 ***
moisMay     -25529073    5125737  -4.981 7.33e-07 ***
moisNov      76023504    4905412  15.498  < 2e-16 ***
moisOct      11139151    4926328   2.261 0.023940 *  
moisSep     -20472963    5458652  -3.751 0.000185 ***
jourSat     -32395320    3564029  -9.090  < 2e-16 ***
jourSun     -34527276    3565397  -9.684  < 2e-16 ***
jourThu       9278746    3570111   2.599 0.009471 ** 
jourWed      10564624    3591349   2.942 0.003331 ** 
tmoy1        -4176888     487998  -8.559  < 2e-16 ***
tmoy7        -2824921     294377  -9.596  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 32460000 on 1130 degrees of freedom
Multiple R-squared:   0.96,	Adjusted R-squared:  0.9592 
F-statistic:  1290 on 21 and 1130 DF,  p-value: < 2.2e-16


```{r}
# BELGIQUE
reglin_BE<-lm(conso~.,data=base_BE)
reglin_BE.sum<-summary(reglin_BE)
# names(reglin_BE)
# names(reglin_BE.sum)
reglin_BE.sum
plot(reglin_BE)

#extraction des coefficients significatifs
coef_BE<-reglin_BE.sum$coefficients[,4]
which(coef_BE<0.05)

# modèle avec les variables significatives
reglin_BE1<-lm(conso~Date+meteo+mois+jour+tmoy1+tmoy7, data=base_BE)
reglin_BE1.sum<-summary(reglin_BE1)
reglin_BE1.sum
plot(reglin_BE1)

```

MODELE SUR L ALLEMAGNE

Le modèle linéaire sur toutes les variables (yc températures retardées) fait ressortir les variables significatives suivantes, 
- les mêmes que celles sur la base totale (avec tous les pays): meteo, les mois d'hiver (novembre, décembre, janvier, février, mars), le jours du we (samedi et dimanche)
- de nouvelles variables: aout, juillet, octobre, mercredi et jeudi, date et température retardée d'un jour et de 7 jours

Le R2 ajusté est meilleur à 0.9609 mais la F-Stat est moins élevé à 1088.


Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 1549.97407  419.72436   3.693 0.000233 ***
Date           0.13747    0.02455   5.599 2.71e-08 ***
meteo       -133.97819    5.32545 -25.158  < 2e-16 ***
moisAug      225.10855   54.40124   4.138 3.77e-05 ***
moisDec      304.98140   43.39304   7.028 3.63e-12 ***
moisFeb      250.91160   45.11203   5.562 3.34e-08 ***
moisJan      238.39399   45.63326   5.224 2.09e-07 ***
moisJul      298.27631   55.90545   5.335 1.15e-07 ***
moisNov      250.57875   42.01834   5.964 3.31e-09 ***
moisOct      131.47867   40.94121   3.211 0.001359 ** 
jourSat     -212.33597   30.61455  -6.936 6.83e-12 ***
jourSun     -248.23799   30.45881  -8.150 9.70e-16 ***
jourThu       64.22431   30.69331   2.092 0.036624 *  
tmoy1         36.56389    7.99315   4.574 5.31e-06 ***
tmoy2        -18.89211    8.39751  -2.250 0.024661 *  

---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 272.2 on 1115 degrees of freedom
Multiple R-squared:  0.9134,	Adjusted R-squared:  0.9114 
F-statistic: 452.6 on 26 and 1115 DF,  p-value: < 2.2e-16


En ne gardant que les variables significatives, F-Stat meilleur à 452

Estimate Std. Error t value Pr(>|t|)    
(Intercept) 1478.01171  418.63759   3.531 0.000432 ***
Date           0.13947    0.02455   5.682 1.70e-08 ***
meteo       -133.58782    5.26424 -25.376  < 2e-16 ***
moisAug      184.61495   51.13003   3.611 0.000319 ***
moisDec      324.13191   42.51025   7.625 5.20e-14 ***
moisFeb      276.61793   43.51503   6.357 2.99e-10 ***
moisJan      265.32634   43.78386   6.060 1.86e-09 ***
moisJul      253.03442   52.03487   4.863 1.32e-06 ***
moisNov      254.87241   41.98837   6.070 1.75e-09 ***
moisOct      121.37784   40.72567   2.980 0.002941 ** 
jourSat     -210.33877   30.25775  -6.952 6.12e-12 ***
jourSun     -245.74198   30.16808  -8.146 9.98e-16 ***
jourThu       65.30708   30.52656   2.139 0.032623 *  
tmoy1         35.71667    7.55301   4.729 2.55e-06 ***
tmoy2        -17.60812    5.21989  -3.373 0.000768 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 272.3 on 1120 degrees of freedom
Multiple R-squared:  0.913,	Adjusted R-squared:  0.9113 
F-statistic: 559.5 on 21 and 1120 DF,  p-value: < 2.2e-16



```{r}

# ALLEMAGNE
reglin_DE<-lm(conso~.,data=base_DE)
reglin_DE.sum<-summary(reglin_DE)
# names(reglin_BE)
# names(reglin_BE.sum)
reglin_DE.sum
plot(reglin_DE)

# modèle avec les variables significatives, F-Stat meilleur
reglin_DE1<-lm(conso~Date+meteo+mois+jour+tmoy1+tmoy2, data=base_DE)
reglin_DE1.sum<-summary(reglin_DE1)
reglin_DE1.sum
plot(reglin_DE1)

```

MODELE LINEAIRE SUR L ESPAGNE

Sur toutes les variables, les variables significatives sur beaucoup plus de mois et de jour. Pas de températures retardées

              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -8.706e+02  1.437e+02  -6.057 2.19e-09 ***
Date         1.120e-01  8.318e-03  13.459  < 2e-16 ***
meteo       -1.509e+01  1.512e+00  -9.985  < 2e-16 ***
moisAug      5.785e+01  1.508e+01   3.837 0.000135 ***
moisDec      9.119e+01  1.067e+01   8.544  < 2e-16 ***
moisFeb      1.215e+02  9.765e+00  12.439  < 2e-16 ***
moisJan      1.262e+02  1.007e+01  12.540  < 2e-16 ***
moisJul      1.121e+02  1.457e+01   7.695 4.42e-14 ***
moisJun      7.301e+01  1.298e+01   5.625 2.61e-08 ***
moisMar      5.619e+01  9.463e+00   5.938 4.39e-09 ***
moisNov      7.530e+01  9.570e+00   7.868 1.24e-14 ***
moisSep      5.290e+01  1.238e+01   4.273 2.18e-05 ***
jourMon      1.825e+01  6.658e+00   2.741 0.006268 ** 
jourSat     -1.030e+02  6.652e+00 -15.482  < 2e-16 ***
jourSun     -1.087e+02  6.656e+00 -16.335  < 2e-16 ***
jourThu      2.127e+01  6.638e+00   3.204 0.001412 ** 
jourTue      2.743e+01  6.657e+00   4.121 4.19e-05 ***
jourWed      2.409e+01  6.659e+00   3.618 0.000316 ***
 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 49.65 on 758 degrees of freedom
Multiple R-squared:  0.9264,	Adjusted R-squared:  0.9238 
F-statistic: 366.7 on 26 and 758 DF,  p-value: < 2.2e-16


En enlevant les variables non significatives (toutes les températures retardées)

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -9.144e+02  1.450e+02  -6.305 4.86e-10 ***
Date         1.126e-01  8.423e-03  13.367  < 2e-16 ***
meteo       -1.920e+01  8.230e-01 -23.325  < 2e-16 ***
moisAug      3.172e+01  1.298e+01   2.444 0.014748 *  
moisDec      1.027e+02  1.031e+01   9.958  < 2e-16 ***
moisFeb      1.321e+02  9.410e+00  14.040  < 2e-16 ***
moisJan      1.385e+02  9.626e+00  14.384  < 2e-16 ***
moisJul      8.873e+01  1.292e+01   6.867 1.35e-11 ***
moisJun      5.399e+01  1.187e+01   4.547 6.33e-06 ***
moisMar      6.359e+01  9.355e+00   6.797 2.15e-11 ***
moisNov      7.920e+01  9.648e+00   8.209 9.47e-16 ***
moisSep      3.494e+01  1.110e+01   3.148 0.001708 ** 
jourMon      1.939e+01  6.727e+00   2.883 0.004047 ** 
jourSat     -1.025e+02  6.722e+00 -15.250  < 2e-16 ***
jourSun     -1.082e+02  6.724e+00 -16.099  < 2e-16 ***
jourThu      2.074e+01  6.708e+00   3.092 0.002059 ** 
jourTue      2.814e+01  6.727e+00   4.183 3.21e-05 ***
jourWed      2.411e+01  6.726e+00   3.585 0.000358 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 50.29 on 765 degrees of freedom
Multiple R-squared:  0.9238,	Adjusted R-squared:  0.9219 
F-statistic: 487.8 on 19 and 765 DF,  p-value: < 2.2e-16


```{r}

# ESPAGNE
reglin_ES<-lm(conso~.,data=base_ES)
reglin_ES.sum<-summary(reglin_ES)
# names(reglin_BE)
# names(reglin_BE.sum)
reglin_ES.sum
plot(reglin_ES)

# modèle avec les variables significatives, F-Stat meilleur
reglin_ES1<-lm(conso~Date+meteo+mois+jour, data=base_ES)
reglin_ES1.sum<-summary(reglin_ES1)
reglin_ES1.sum
plot(reglin_ES1)

```

MODELE LINEAIRE SUR LA FRANCE

Avec toutes les variables
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 1248.04768  121.65365  10.259  < 2e-16 ***
Date           0.04580    0.00705   6.497 1.12e-10 ***
meteo        -54.66184    2.32294 -23.531  < 2e-16 ***
moisAug       68.84477   19.77475   3.481 0.000513 ***
moisDec      409.98832   16.91988  24.231  < 2e-16 ***
moisFeb      467.73990   16.94244  27.608  < 2e-16 ***
moisJan      477.19895   17.39473  27.434  < 2e-16 ***
moisJul      188.10440   20.70025   9.087  < 2e-16 ***
moisJun       96.02768   18.86935   5.089 4.06e-07 ***
moisMar      265.38774   15.75717  16.842  < 2e-16 ***
moisMay      -74.90871   15.63080  -4.792 1.81e-06 ***
moisNov      328.61473   15.55618  21.124  < 2e-16 ***
moisOct       60.46514   15.39093   3.929 8.94e-05 ***
jourSat     -102.25202   11.33801  -9.019  < 2e-16 ***
jourSun     -115.69760   11.32785 -10.214  < 2e-16 ***
jourThu       26.12732   11.36539   2.299 0.021652 *  
jourTue       34.23883   11.32916   3.022 0.002553 ** 
jourWed       38.68393   11.35653   3.406 0.000676 ***
tmoy2         -7.69947    3.74573  -2.056 0.040003 *  
tmoy7         -7.55547    2.30012  -3.285 0.001044 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 117.7 on 1482 degrees of freedom
Multiple R-squared:  0.9646,	Adjusted R-squared:  0.9639 
F-statistic:  1552 on 26 and 1482 DF,  p-value: < 2.2e-16


En enlevant les variables non significatives
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.230e+03  1.221e+02  10.077  < 2e-16 ***
Date         4.616e-02  7.078e-03   6.522 9.51e-11 ***
meteo       -5.304e+01  1.495e+00 -35.474  < 2e-16 ***
moisAug      6.229e+01  1.978e+01   3.150 0.001667 ** 
moisDec      4.153e+02  1.694e+01  24.521  < 2e-16 ***
moisFeb      4.736e+02  1.695e+01  27.947  < 2e-16 ***
moisJan      4.851e+02  1.735e+01  27.956  < 2e-16 ***
moisJul      1.806e+02  2.069e+01   8.729  < 2e-16 ***
moisJun      9.014e+01  1.889e+01   4.773 1.99e-06 ***
moisMar      2.705e+02  1.577e+01  17.159  < 2e-16 ***
moisMay     -7.551e+01  1.569e+01  -4.812 1.64e-06 ***
moisNov      3.315e+02  1.560e+01  21.251  < 2e-16 ***
moisOct      5.943e+01  1.545e+01   3.847 0.000125 ***
jourSat     -1.022e+02  1.136e+01  -8.996  < 2e-16 ***
jourSun     -1.152e+02  1.136e+01 -10.138  < 2e-16 ***
jourThu      2.564e+01  1.139e+01   2.252 0.024494 *  
jourTue      3.380e+01  1.136e+01   2.975 0.002977 ** 
jourWed      3.802e+01  1.139e+01   3.337 0.000867 ***
tmoy2       -9.858e+00  1.526e+00  -6.459 1.42e-10 ***
tmoy7       -1.080e+01  1.153e+00  -9.364  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 118.2 on 1487 degrees of freedom
Multiple R-squared:  0.9642,	Adjusted R-squared:  0.9637 
F-statistic:  1905 on 21 and 1487 DF,  p-value: < 2.2e-16


```{r}

# FRANCE
reglin_FR<-lm(conso~.,data=base_FR)
reglin_FR.sum<-summary(reglin_FR)
reglin_FR.sum
plot(reglin_FR)

# modèle avec les variables significatives
reglin_FR1<-lm(conso~Date+meteo+mois+jour+tmoy2+tmoy7, data=base_FR)
reglin_FR1.sum<-summary(reglin_FR1)
reglin_FR1.sum
plot(reglin_FR1)

```

MODELE LINEAIRE SUR LES PAYS BAS

Avec toutes les variables
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -4.474e+07  1.393e+07  -3.211 0.001358 ** 
Date         1.108e+04  8.167e+02  13.571  < 2e-16 ***
meteo       -3.457e+06  1.693e+05 -20.417  < 2e-16 ***
moisAug      1.055e+07  1.754e+06   6.013 2.45e-09 ***
moisDec      2.896e+07  1.389e+06  20.850  < 2e-16 ***
moisFeb      3.009e+07  1.429e+06  21.052  < 2e-16 ***
moisJan      3.263e+07  1.409e+06  23.156  < 2e-16 ***
moisJul      1.432e+07  1.788e+06   8.011 2.81e-15 ***
moisJun      5.895e+06  1.658e+06   3.556 0.000392 ***
moisMar      1.462e+07  1.360e+06  10.747  < 2e-16 ***
moisNov      2.247e+07  1.374e+06  16.357  < 2e-16 ***
moisOct      1.168e+07  1.387e+06   8.420  < 2e-16 ***
moisSep      8.705e+06  1.604e+06   5.427 7.00e-08 ***
jourMon     -2.340e+06  1.001e+06  -2.337 0.019615 *  
jourSat     -1.254e+07  1.004e+06 -12.490  < 2e-16 ***
tmoy1       -9.005e+05  2.393e+05  -3.763 0.000177 ***
tmoy7       -3.263e+05  1.663e+05  -1.963 0.049925 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 9089000 on 1126 degrees of freedom
Multiple R-squared:  0.9462,	Adjusted R-squared:  0.9449 
F-statistic: 761.1 on 26 and 1126 DF,  p-value: < 2.2e-16


En enlevant les variables non significatives
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -4.473e+07  1.399e+07  -3.197 0.001428 ** 
Date         1.108e+04  8.204e+02  13.501  < 2e-16 ***
meteo       -3.912e+06  1.206e+05 -32.428  < 2e-16 ***
moisAug      1.049e+07  1.754e+06   5.985 2.91e-09 ***
moisDec      2.900e+07  1.394e+06  20.803  < 2e-16 ***
moisFeb      3.010e+07  1.432e+06  21.025  < 2e-16 ***
moisJan      3.265e+07  1.408e+06  23.184  < 2e-16 ***
moisJul      1.425e+07  1.787e+06   7.976 3.68e-15 ***
moisJun      5.832e+06  1.658e+06   3.517 0.000454 ***
moisMar      1.470e+07  1.363e+06  10.781  < 2e-16 ***
moisNov      2.245e+07  1.380e+06  16.274  < 2e-16 ***
moisOct      1.170e+07  1.393e+06   8.396  < 2e-16 ***
moisSep      8.647e+06  1.607e+06   5.381 9.02e-08 ***
jourMon     -2.256e+06  1.004e+06  -2.247 0.024857 *  
jourSat     -1.244e+07  1.005e+06 -12.375  < 2e-16 ***
jourSun     -1.734e+07  1.006e+06 -17.242  < 2e-16 ***
tmoy2       -5.772e+05  1.222e+05  -4.722 2.62e-06 ***
tmoy7       -4.211e+05  9.391e+04  -4.485 8.04e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 9130000 on 1131 degrees of freedom
Multiple R-squared:  0.9454,	Adjusted R-squared:  0.9444 
F-statistic:   933 on 21 and 1131 DF,  p-value: < 2.2e-16



```{r}

# NL PAYS BAS
reglin_NL<-lm(conso~.,data=base_NL)
reglin_NL.sum<-summary(reglin_NL)
reglin_NL.sum
plot(reglin_NL)

# modèle avec les variables significatives
reglin_NL1<-lm(conso~Date+meteo+mois+jour+tmoy2+tmoy7, data=base_NL)
reglin_NL1.sum<-summary(reglin_NL1)
reglin_NL1.sum
plot(reglin_NL1)


```

MODELE LINEAIRE SUR LE ROYAUME UNI

AVEC TOUTES LES VARIABLES
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 60.9250189 16.9188764   3.601 0.000331 ***
Date         0.0096150  0.0009922   9.691  < 2e-16 ***
meteo       -6.8978365  0.2186886 -31.542  < 2e-16 ***
moisDec     41.5510525  1.6821041  24.702  < 2e-16 ***
moisFeb     48.6948747  1.7273093  28.191  < 2e-16 ***
moisJan     52.3859927  1.7046536  30.731  < 2e-16 ***
moisJul      6.4602457  2.2425405   2.881 0.004042 ** 
moisMar     27.9285614  1.6674242  16.750  < 2e-16 ***
moisMay     -5.9140261  1.7378134  -3.403 0.000689 ***
moisNov     33.8329914  1.6723595  20.231  < 2e-16 ***
moisOct      9.2148745  1.7485089   5.270 1.63e-07 ***
moisSep     -4.0833156  1.9744293  -2.068 0.038858 *  
jourMon      3.1513082  1.2441862   2.533 0.011449 *  
jourSat     -7.7228136  1.2456305  -6.200 7.90e-10 ***
jourSun     -9.6240351  1.2312928  -7.816 1.24e-14 ***
jourThu      3.7834269  1.2488067   3.030 0.002504 ** 
jourWed      3.1246969  1.2319863   2.536 0.011336 *  
tmoy1       -1.4418691  0.2828710  -5.097 4.04e-07 ***
tmoy2       -0.9463196  0.2843406  -3.328 0.000902 ***
tmoy7       -0.5138258  0.2157424  -2.382 0.017399 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 11.07 on 1131 degrees of freedom
Multiple R-squared:  0.9735,	Adjusted R-squared:  0.9729 
F-statistic:  1600 on 26 and 1131 DF,  p-value: < 2.2e-16

EN ENLEVANT LES VARIABLES NON SIGNIFICATIVES
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 60.1043628 16.9356958   3.549 0.000403 ***
Date         0.0096195  0.0009934   9.683  < 2e-16 ***
meteo       -6.9155560  0.2180843 -31.710  < 2e-16 ***
moisDec     41.6761938  1.6828049  24.766  < 2e-16 ***
moisFeb     49.0435011  1.7210967  28.495  < 2e-16 ***
moisJan     52.8198065  1.6953703  31.155  < 2e-16 ***
moisJul      5.8479105  2.2253689   2.628 0.008709 ** 
moisMar     28.2632305  1.6630420  16.995  < 2e-16 ***
moisMay     -6.0142384  1.7384133  -3.460 0.000561 ***
moisNov     33.9009239  1.6741497  20.250  < 2e-16 ***
moisOct      9.0341510  1.7479378   5.168 2.79e-07 ***
moisSep     -4.5194620  1.9656600  -2.299 0.021674 *  
jourMon      3.1512761  1.2414883   2.538 0.011272 *  
jourSat     -7.7561187  1.2323939  -6.294 4.42e-10 ***
jourSun     -9.7963011  1.2233001  -8.008 2.87e-15 ***
jourThu      3.9528274  1.2292057   3.216 0.001338 ** 
jourWed      3.1211973  1.2282812   2.541 0.011182 *  
tmoy1       -1.4286567  0.2802155  -5.098 4.01e-07 ***
tmoy2       -1.0067491  0.2185875  -4.606 4.57e-06 ***
tmoy7       -0.8581189  0.1407572  -6.096 1.48e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 11.09 on 1135 degrees of freedom
Multiple R-squared:  0.9734,	Adjusted R-squared:  0.9729 
F-statistic:  1886 on 22 and 1135 DF,  p-value: < 2.2e-16




```{r}

# UK ROYAUME UNI
reglin_UK<-lm(conso~.,data=base_UK)
reglin_UK.sum<-summary(reglin_UK)
reglin_UK.sum
plot(reglin_UK)

# modèle avec les variables significatives
reglin_UK1<-lm(conso~Date+meteo+mois+jour+tmoy1+tmoy2+tmoy7, data=base_UK)
reglin_UK1.sum<-summary(reglin_UK1)
reglin_UK1.sum
plot(reglin_UK1)


```

REGRESSION POLYNOMIALE ENTRE Y=CONSO ET X=METEO

Avec la validation croisée train/test, on trouve que le degré du polynome qui présente la plus petite MSE est 5.
La valeur de R² ajustée n'est cependant pas très élevée
Adjusted R-squared:  0.08201 
F-statistic: 124.3
le graphe des résidus n'est pas satisfaisant


Avec la validation croisée K-fold, l'erreur la plus petite est pour le polynome de degré 6
Multiple R-squared:  0.08271,	Adjusted R-squared:  0.08192 
F-statistic: 103.6 on 6 and 6892 DF,  p-value: < 2.2e-16

```{r}
# regression polynomiale entre Y=conso et X=meteo
Y=don$Y
X=don$meteo
donYX=data.frame(cbind(Y,X))
head(donYX)

# CROSS VALIDATION HOLD OUT TRAIN/TEST
set.seed(1)
d<-nrow(donYX)
index<-sample(d,2*d/3)
train=donYX[index,]
test=donYX[-index,]

d=10 # degré max de polynome à tester
mse.poly=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=train)
  mse.poly[i] <- mean((test$Y-predict(model,test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set, ici c'est pour le degré 5
plot(sqrt(mse.poly),ylab="MSE", main='Root MSE selon le degré de polynome',pch=19,type='b')

model.poly5 <- lm(formula=Y~poly(X,5, raw=T), data=don)
sum.poly5<- summary(model.poly5)
sum.poly5
plot(model.poly5)


# CROSS VALIDATION K.fold
# creation des variables Y cible et X explicative
Y=don$Y
X=don$meteo
donYX=data.frame(cbind(Y,X))
head(donYX)

k=10
d=15
set.seed(1)
cv.error=as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX)
cv.error[i]<-cv.glm(donYX,glm.fit,K=10)$delta[1]
}

plot(cv.error, type="l")
# ici c'est avec le degré 6 que l'erreur est la plus faible

model.poly6 <- lm(formula=Y~poly(X,6, raw=T), data=don)
sum.poly6<- summary(model.poly6)
sum.poly6
plot(model.poly6)


# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
Y=don$Y
X=don$meteo
donYX=data.frame(cbind(Y,X))
head(donYX)

library(boot)
d=10 # degré de polynome 
cv.error=rep(0,d)
for (i in 1:d) { 
  glm.fit=glm(Y~poly(X,i),data = donYX) 
  cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(cv.error, type="l")

```


REGRESSION PENALISEE RIDGE
```{r}

library(glmnet)
# library(caTools)
# library(randomForest)
library(ggplot2)

# definition variables Y et X
library(questionr)
don <- rename.variable(don, "conso", "Y")
Y=don$Y


# par defaut, glmnet standardise les variables pour les mettre sur la même échelle.
# si on ne veut pas, standardise=FALSE
X=model.matrix(Y~.,don)[,-1]
dim(X) # en colonne toutes les variables yc dummy variables


# grille de lambda de 10^10 à 10^-2
# pour mémoire, si lambda=0, c'est le MCO
grid=10^seq(10,-2,length=100)


# REGRESSION PENALISEE RIDGE sur une grille de lambda
# Ridge pour alpha=0 et Lasso pour alpha=1
ridge.mod=glmnet(X,Y,alpha=0,lambda=grid) 

# a chaque valeur de lambda est associé un vecteur de coefficients de regression stockés dans une matrice coef()
# nombre de lignes = nombre de variables + l'intercept
# plus lambda est grand et plus les coefficients sont petits
dim(coef(ridge.mod))


# PREDICT AVEC TRAIN ET TEST
set.seed(1)
train=sample(1:nrow(X),2*nrow(X)/3)
test=(-train)
Y.test=Y[test]

ridge.mod=glmnet(X[train,],Y[train],alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,newx=X[test,]) 
# ridge.pred=predict(ridge.mod,s=4, newx=X[test,]) 
# s est la valeur du lambda pour la prédiction. Par défaut, c'est la séquence de lambda qui a été utilisée pour creer le modèle
MSE=mean((ridge.pred-Y.test)^2)
MSE


# CROSS VALIDATION HOLD OUT POUR LE CHOIX DU LAMBDA DANS RIDGE
# recherche de lambda qui minimise MSE
grid=10^seq(10,-2,length=100) 
mse.lambda=rep(NA,length(grid))
for(i in 1:length(grid)) {
ridge.mod=glmnet(X[train,],Y[train],alpha=0,lambda=grid[i])
ridge.pred=predict(ridge.mod,s=grid[i], newx=X[test,]) 
mse.lambda[i] <- mean((Y.test-ridge.pred)^2)
  }
plot(mse.lambda) # visuellement à partir de la 20ème valeur

diff.lambda=rep(NA,(length(mse.lambda)-1)) # calcul de la variation de MSE d'une valeur lambda à l'autre
for (i in 1:length(mse.lambda)) { 
diff.lambda[i]=mse.lambda[i+1]-mse.lambda[i]
}
plot(diff.lambda) # la variation de mse.lambda baisse jusqu'à un certain point puis réaugmente jusqu'à la fin

diff.min<-which.min(diff.lambda) # recherche de la plus petite variation 
diff.min # c'est la 12ème variation qui est la plus petite.A partir de cette valeur, la variation réaugmente
lambda.min=grid[diff.min]
lambda.min

# MODELISATION AVEC LAMBDA.MIN TROUVEE PAR CROSS VALIDATION

# train and test avec sample
set.seed(1)
train=sample(1:nrow(X),2*nrow(X)/3)
test=(-train)
Y.test=Y[test]
# X=model.matrix(Y~.,don)[,-1]


ridge.mod.best=glmnet(X[train,],Y[train],alpha=0,lambda=lambda.min)
ridge.pred=predict(ridge.mod.best,s=lambda.min, newx=X[test,]) 
# s est la valeur du lambda pour la prédiction. Par défaut, c'est la séquence de lambda qui a été utilisée pour creer le modèle
MSE.lambda.min=mean((ridge.pred-Y.test)^2)
MSE.lambda.min



# plot des valeurs prédites vs valeurs réelles # pas pertinent car les prédictions sont écrasées par Ridge
date=data.frame(X)$Date

ggplot() +
  geom_line(aes(x = date[test], y = Y[test]),
             colour = 'red') +
  geom_line(aes(x = date[test], y = ridge.pred),
            colour = 'blue') +
  ggtitle('Regression Ridge, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```



RANDOM FOREST BASE TOTALE
```{r}
library(caTools)
library(randomForest)
library(ggplot2)


# train and test base TOTALE
# prendre base.nona pour éviter les valeurs manquantes
set.seed(123)
split=sample.split(base.nona$conso, SplitRatio=2/3)
training_set=subset(base.nona,split==TRUE)
test_set=subset(base.nona,split==FALSE)

# modelisation sur train, par défaut ntree=500
rf_total<-randomForest(conso~., data=training_set)
print(rf_total)

# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 30 environ
plot(rf_total$mse)

# prediction sur test
rf_total_pred<-predict(rf_total,test_set)
rf_total_pred_sum<-summary(rf_total_pred)
rf_total_pred_sum

library(ggplot2)

# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$conso),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_total_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression tous pays, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```



RANDOM FOREST BELGIQUE

                     Number of trees: 500
No. of variables tried at each split: 3

           Mean of squared residuals: 7.685223e+14
                    % Var explained: 97.01

```{r}
library(caTools)
library(randomForest)
library(ggplot2)


# train and test
set.seed(123)
split=sample.split(base_BE$Y, SplitRatio=2/3)
training_set=subset(base_BE,split==TRUE)
test_set=subset(base_BE,split==FALSE)

# modelisation random forest sur train
rf_BE<-randomForest(Y~., data=training_set)
print(rf_BE)

# prediction sur test
rf_BE_pred<-predict(rf_BE,test_set)
rf_BE_pred_sum<-summary(rf_BE_pred)
rf_BE_pred_sum

names(rf_BE)
# names(rf_BE_pred)


# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 50 environ
plot(rf_BE$mse)


# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$Y),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_BE_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression Belgique, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

# comment vérifier la performance du modele random forest, car la courbe ROC ne fonctionne que pour classification binaire

# faire cross validation

# a faire compare the Out of Bag Sample Errors and Error on Test set
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error","Test Error"),pch=19, col=c("red","blue"))

# DYGRAPH
install.packages("dygraphs")
library(dygraphs)

data_BE=cbind()
dygraph()

```



RANDOM FOREST ALLEMAGNE

                     Number of trees: 500
No. of variables tried at each split: 3

          Mean of squared residuals: 59618.8
                    % Var explained: 92.93

```{r}

library(caTools)
library(randomForest)
library(ggplot2)


# train and test
set.seed(123)
split=sample.split(base_DE$conso, SplitRatio=2/3)
training_set=subset(base_DE,split==TRUE)
test_set=subset(base_DE,split==FALSE)

# modelisation random forest sur train
rf_DE<-randomForest(conso~., data=training_set)
print(rf_DE)

# prediction sur test
rf_DE_pred<-predict(rf_DE,test_set)
rf_DE_pred_sum<-summary(rf_DE_pred)
rf_DE_pred_sum

# plot MSE selon le nombre d'arbre
plot(rf_DE$mse)


# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$conso),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_DE_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression Allemagne, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```

RANDOM FOREST ESPAGNE

                     Number of trees: 500
No. of variables tried at each split: 3

Mean of squared residuals: 2302.52
% Var explained: 93.34

```{r}

library(caTools)
library(randomForest)
library(ggplot2)


# train and test
set.seed(123)
split=sample.split(base_ES$conso, SplitRatio=2/3)
training_set=subset(base_ES,split==TRUE)
test_set=subset(base_ES,split==FALSE)

# modelisation random forest sur train
rf_ES<-randomForest(conso~., data=training_set)
print(rf_ES)

# prediction sur test
rf_ES_pred<-predict(rf_ES,test_set)
rf_ES_pred_sum<-summary(rf_ES_pred)
rf_ES_pred_sum

plot(rf_ES$mse)


# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$conso),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_ES_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression Espagne, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```

RANDOM FOREST FRANCE

                     Number of trees: 500
No. of variables tried at each split: 3
Mean of squared residuals: 7446.801
% Var explained: 98


```{r}
library(caTools)
library(randomForest)
library(ggplot2)


# train and test
set.seed(123)
split=sample.split(base_FR$conso, SplitRatio=2/3)
training_set=subset(base_FR,split==TRUE)
test_set=subset(base_FR,split==FALSE)

# modelisation random forest sur train
rf_FR<-randomForest(conso~., data=training_set)
print(rf_FR)

# prediction sur test
rf_FR_pred<-predict(rf_FR,test_set)
rf_FR_pred_sum<-summary(rf_FR_pred)
rf_FR_pred_sum

plot(rf_FR$mse)


# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$conso),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_FR_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression Espagne, en bleu prédiction') +
  xlab('date') +
  ylab('conso')


```



RANDOM FOREST PAYS BAS

                     Number of trees: 500
No. of variables tried at each split: 3
 Mean of squared residuals: 6.725851e+13
 % Var explained: 95.58

```{r}
library(caTools)
library(randomForest)
library(ggplot2)


# train and test
set.seed(123)
split=sample.split(base_NL$conso, SplitRatio=2/3)
training_set=subset(base_NL,split==TRUE)
test_set=subset(base_NL,split==FALSE)

# modelisation random forest sur train
rf_NL<-randomForest(conso~., data=training_set)
print(rf_NL)

# prediction sur test
rf_NL_pred<-predict(rf_NL,test_set)
rf_NL_pred_sum<-summary(rf_NL_pred)
rf_NL_pred_sum

plot(rf_NL$mse)


# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$conso),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_NL_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression PAYS BAS, en bleu prédiction') +
  xlab('date') +
  ylab('conso')




```


RANDOM FOREST ROYAUME UNI

                     Number of trees: 500
No. of variables tried at each split: 3
Mean of squared residuals: 119.8962
% Var explained: 97.35

```{r}
library(caTools)
library(randomForest)
library(ggplot2)


# train and test
set.seed(123)
split=sample.split(base_UK$conso, SplitRatio=2/3)
training_set=subset(base_UK,split==TRUE)
test_set=subset(base_UK,split==FALSE)

# modelisation random forest sur train
rf_UK<-randomForest(conso~., data=training_set)
print(rf_UK)

# prediction sur test
rf_UK_pred<-predict(rf_UK,test_set)
rf_UK_pred_sum<-summary(rf_UK_pred)
rf_UK_pred_sum

plot(rf_UK$mse)


# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_line(aes(x = test_set$Date, y = test_set$conso),
             colour = 'red') +
  geom_line(aes(x = test_set$Date, y = rf_UK_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression PAYS BAS, en bleu prédiction') +
  xlab('date') +
  ylab('conso')




```



