---
title: "Modeles BE Belgique"
author: "Nhu-Nguyen Ngo"
date: "27 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

remplacer nom fichier
remplacer title
remplacer base: base_BE_F
remplacer suffixe: _BE
remplacer nom:  Belgique

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# PACKAGES BASE ET VARIABLES

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


```{r}


# DONNEES VISUALISATION
library(stargazer)
library(ggplot2)
library(questionr)
library(dplyr)
library(lubridate) # pour les dates
library(dummies) # création de variables dummies (pour bestglm)


# TREE
library(rpart)				  # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)			# Enhanced tree plots
library(RColorBrewer)		# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree


# selection de variable
library(bestglm)
library(leaps) # regsubset


# cross validation
library(stats) # fonction glm


# CLUSTERING
library(stats) # fonction glm
library(cluster)
library(fastcluster)


# MODELES
library(caret)		
library(ISLR)
library(glmnet) # Poly, GAM
library(boot) # boostraping
library(splines)
library(caTools)
library(randomForest)
library(e1071) # SVR


# paralellisation
library(doParallel)
library(foreach)


```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# ARBRE DE DECISION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## base et variables pour Arbre décision NON CENTREE REDUITE, sans les autres variables météo
```{r}

# sur base totale avec tous les pays, non centrée réduite
don<-base_BE_F
# head(don)
# str(don)

# definition variables Y
library(questionr)
don <- rename.variable(don, "Conso", "Y")
Y=don$Y

# head(don)
str(don)


```


## ARBRE DECISION K_fold avec k=10 (par défaut)
```{r}

tree_BE_total<-rpart(Y~.,data=don)
# tree_BE_total
# prp(tree_BE_total)               # A fast plot													
fancyRpartPlot(tree_BE_total, main="arbre de décision Belgique")		# A fancy plot from rattle

# rpart choisit l'arbre par validation croisée k-fold. Par défaut k=10. On peut spécifier k avec xval=k
# si xval=nrow(don), c'est un LOOCV leave one out
# on peut spécifier le nombre minimum de données dans un noeud avec minsplit=


```




## ARBRE DECISION plot
```{r}
plotcp(tree_BE_total) 
# graphe qui permet de choisir le nombre de feuilles qui minimise l'erreur. 
# on prend le cp correspondant pour construire l'arbre final

```

## ARBRE DECISION FINAL avec k=10
```{r}
tree_BE_totalf<-rpart(Y~.,data=don, cp=0.01)
fancyRpartPlot(tree_BE_totalf, main="arbre de décision Belgique")

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# BASE POUR SELECTION DE VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


BASE CENTREE REDUITE, sans les autres variables météo
```{r}

# base totale centrée réduite, sans les variables météo
don<-base_BE_F_cr
head(don)
dim(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))


# Creation de l'echantillon train individus et test 
set.seed(1)
dim<-nrow(don.train)
partage=2/3

train=sample(dim,partage*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage

test=model.matrix(Y~.,data=don[-train,])# base de test

Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]

don.train=don[train,]
don.test=don[-train,]

donYX.train=donYX[train,]
donYX.test=donYX[-train,]


p=ncol(don) # nombre de variables explicatives
p

names(don)

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# SELECTION DE VARIABLES REGSUBSETS
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## SELECTION DE VARIABLES AVEC REGSUBSET exhaustif à éviter
```{r}

# # SELECTION EXHAUSTIVE: A EVITER car P GRAND !! (ici 27 variables trop grand)
# # Exhaustive search will be S L O W, must specify really.big=T
# # On va obtenir 2^p modeles comprenant entre une et p variables
# # par défaut, le nombre de variable est 8. Préciser le nombre de variables avec nvmax
# 
# best_full_tot=regsubsets(Y~.,data=don[train,],nvmax=p,method='exhaustive')
# 
# # choisir les meilleures variables: evaluer chacun des modeles sur le test set et calculer la MSE
# MSE_full_tot=rep(NA,p)
# for(i in 1:p){
#   coefi=coef(best_full_tot,id=i)
#   pred=test[,names(coefi)]%*%coefi
#   MSE_full_tot[i]=mean((Y.test-pred)^2)
# }
# 
# # plot les MSE des modeles sur le training 
# # On choisit le modele qui a la MSE la plus petite sur le test set
# plot(MSE_full_tot,ylab=' MSE des p modeles',pch=19,type='b')
# which.min(MSE_full_tot) # ici, c'est le modèle à 12 variables (toutes les variables)
# 
# # Pour acceder aux coefficient du modele avec la MSE la plus petite, on appelle la fonction coeff
# # Pour acceder aux RSS des modeles, on lance la fonction summary
# coef(best_full,12)
# summary(best_full)$rss

```


## SELECTION DE VARIABLES AVEC REGSUBSET forward
```{r}

# FORWARD SELECTION: NB pas assuré d'avoir le modèle optimal, mais possible si n<p

best_FW_BE=regsubsets(Y~.,data=don.train,nvmax=p,method='forward')
FW_BE_sum<-summary(best_FW_BE)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_FW_BE=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_FW_BE,id=i)
  pred=test[,names(coefi)]%*%coefi   # matrix modele et pas don.test
  MSE_FW_BE[i]=mean((Y.test-pred)^2)
}

# on plot les MSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(sqrt(MSE_FW_BE),ylab='MSE des p modeles FW', main="Regsubset forward sur base Belgique",pch=19,type='b')
 


```


## SELECTION DE VARIABLES AVEC REGSUBSET forward résultats MSE
```{r}
which.min(MSE_FW_BE)


```


## SELECTION DE VARIABLES AVEC REGSUBSET forward coef MSE
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables )
coef(best_FW_BE,which.min(MSE_FW_BE))

# variables sélectionnées par regsubset forward MSE: Temp + cosinus + sinus + day_length + teff + t2 + t5 + t6  + month + year + day + leadholidays + season

```


## SELECTION DE VARIABLES AVEC REGSUBSET forward détails
```{r}
# FW_BE_sum

```


## SELECTION DE VARIABLES AVEC REGSUBSET forward rss
```{r}
# # Pour acceder aux RSS des modèles, on lance la fonction summary
# FW_BE_sum$rss


```


## SELECTION DE VARIABLES AVEC REGSUBSET FW plot BIC
```{r}

# choix des variables selon critères BIC, R² ajusté, Cp
# graphe BIC autre: “Cp”, “adjr2”, “r2". classification des valeurs de BIC selon les modèles, en haut la plus petite valeur de BIC et en noir les variables inclusent dans le modèle
# Le $R^2$ ajusté permet de déterminer à quel point le modèle ajuste vos données lorsque vous souhaitez l'ajuster en fonction du nombre de prédicteurs inclus. La valeur du $R^2$ ajusté intègre le nombre de prédicteurs dans le modèle elle donc plus adaptée pour nous aider à choisir le modèle.

# graphe BIC
plot(best_FW_BE, scale="bic", main=" BIC pour Regsubset FW Belgique") 



```


## SELECTION DE VARIABLES AVEC REGSUBSET FW plot R²
```{r}
# graphe R² ajusté
plot(best_FW_BE, scale="adjr2", main=" R² Ajuste pour Regsubset FW Belgique")

 
```


## SELECTION DE VARIABLES AVEC REGSUBSET FW plot Cp
```{r}


# graphe Cp
plot(best_FW_BE, scale="Cp", main=" Cp pour Regsubset FW Belgique")


```


## SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_FW_BE)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)
# names(which(reg.summary$which[min.rss,]==TRUE))
# names(which(reg.summary$which[max.adjr2,]==TRUE))
# names(which(reg.summary$which[min.cp,]==TRUE))
# names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset FW Belgique")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


## SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

## SELECTION DE VARIABLES AVEC REGSUBSET FW Bic coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_FW_BE,min.bic) 

# variables sélectionnées par regsubset FW BIC: 
# cosinus + sinus + day_length + teff + t2 + t6 + month + year + quarter + season


```



## SELECTION DE VARIABLES AVEC REGSUBSET backward
```{r}
# selection variables BACKWARD: NB pas assuré d'avoir le modèle optimal,pas possible si n<p

best_BW_BE=regsubsets(Y~.,data=don.train,nvmax=p,method='backward')
sum_BW_BE<-summary(best_BW_BE)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_BW_BE=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_BW_BE,id=i)
  pred=test[,names(coefi)]%*%coefi  # matrix modele et pas don.test
  MSE_BW_BE[i]=mean((Y.test-pred)^2)
}

# on plot les MSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(sqrt(MSE_BW_BE),ylab='MSE des p modeles',main="Regsubset backward sur base Belgique",pch=19,type='b') 



```


## SELECTION DE VARIABLES AVEC REGSUBSET backward résultats
```{r}
which.min(MSE_BW_BE) 


```


## SELECTION DE VARIABLES AVEC REGSUBSET backward coef
```{r}

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_BE,which.min(MSE_BW_BE)) 

# variables sélectionnées par regsubset backward MSE: 
# Temp + cosinus + sinus + day_length + teff + t2 + t6 + month + year + day + homidays + quarter + season 

```




## SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_BW_BE)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)

# names(which(reg.summary$which[min.rss,]==TRUE))
# names(which(reg.summary$which[max.adjr2,]==TRUE))
# names(which(reg.summary$which[min.cp,]==TRUE))
# names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset BW Belgique")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


## SELECTION DE VARIABLES AVEC REGSUBSET BW comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

## SELECTION DE VARIABLES AVEC REGSUBSET BW Bic coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_BE,min.bic) 

# variables sélectionnées par regsubset BW BIC: cosinus + sinus + day_length + teff + t2 + t6 + month + year + day + holidays + quarter + season


```






## SELECTION DE VARIABLES AVEC REGSUBSET graphe MSE FW et BW
```{r}
# plot des MSE pour les modèles FW et BW

x=c(1:p)
y1=MSE_FW_BE
y2=MSE_BW_BE
plot(x, y1, type = "l", ylim = range(c(y1, y2)), xlab = "nb de variables", ylab = "MSE", main="MSE Belgique FW (blue) et BW (red)")
lines(x, y1, col = "blue")
lines(x, y2, col = "red")


```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# LASSO POUR SELECTION DE VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## REGRESSION PENALISEE LASSO avec cross validation cv.glmnet
```{r}

# par defaut, glmnet standardise les variables pour les mettre sur la même échelle.
# si on ne veut pas, standardise=FALSE
X=model.matrix(Y~.,don)[,-1]

# train & test
set.seed(1)
train=sample(1:nrow(X),2*nrow(X)/3)
test=-(train)
Y.test=Y[test]

# REGRESSION PENALISEE sur une grille de lambda
# Ridge pour alpha=0 et Lasso pour alpha=1
grid=10^seq(10,-2,length=100)
lasso.mod=glmnet(X,Y,alpha=1,lambda=grid) 
plot(lasso.mod)



```

## CV pour lambda 
```{r}
# cross validation pour trouver lambda min
set.seed(1)
cv.out=cv.glmnet(X[train,],Y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam

```

## MSE
```{r}
# MSE avec bestlam
lasso.pred=predict(lasso.mod,s=bestlam, newx=X[test,])
MSE.bestlam=mean((lasso.pred-Y.test)^2)
MSE.bestlam

# modelisation sur toutes les données, avec bestlam
out=glmnet(X,Y, alpha=0)
predict(out,type="coefficients", s=bestlam)

```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES OLS SANS INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


# BASE DONNEES OLS SANS les variables liées à Temp: TEFF T00 SEUIL
```{r}


# sur la base centrée réduite, sans les autres variables méteo
don<-base_BE_F_cr
head(don)

# suppression des variales liées à la température teff, seuil, T00
don<-don[,-which(colnames(don)== "teff")] 
don<-don[,-which(colnames(don)== "seuil")] 
don<-don[,-which(colnames(don)== "T00")] 
head(don)

# creation des variables Y (variable cible) et X
don<- rename.variable(don, "Conso", "Y")
head(don)

# variables pour modèles polynomial et splines
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))

# Creation de l'echantillon train 2/3 individus et test 1/3
set.seed(1)
dim<-nrow(don)
split=2/3
train=sample(dim,split*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage

test=model.matrix(Y~.,data=don[-train,])# model matrice sur base de test

Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]
don.train=don[train,]
don.test=don[-train,]
donYX.train=donYX[train,]
donYX.test=donYX[-train,]

names(don)




```



## RL SANS INTERACTION total avec toutes les variables résultats
```{r}

# OLS sans interaction sur base centrée réduite
# modèle linéaire simple sur Y, avec toutes les variables

RL_BE_tot<-lm(Y~.,data=don.train)
RL_BE_tot_sum<-summary(RL_BE_tot)
# RL_BE_tot_sum


# extraction des coefficients significatifs
coef<-RL_BE_tot_sum$coefficients[,4]
RL_BE_tot_var <- names(which(coef<0.05))
dim_coef <- length (RL_BE_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RL_BE_tot_var[i] , "+ ") }
formule

```


## RL SANS INTERACTION en ne gardant que les variables significatives
```{r}


# selection des variables significatives 
RL_BE_fin<-lm(Y~  Temp +  cosinus +  day_length +  t6 +  t7 +  month +  day +  leadholidays, data=don.train)
RL_BE_fin_sum<-summary(RL_BE_fin)
# RL_BE_fin_sum

# extraction des coefficients significatifs
coef<-RL_BE_fin_sum$coefficients[,4]
RL_BE_fin_var <- names(which(coef<0.05))
dim_coef <- length (RL_BE_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RL_BE_fin_var[i] , "+ ") }
formule

```



## RL SANS INTERACTION selection des variables par step
```{r}
RL_BE_step=step(RL_BE_tot, test="F", trace=FALSE)

RL_BE_step


```



## RL SANS INTERACTION modèle issu de step
```{r}
RL_BE_step <- lm(Y ~ Temp + cosinus + sinus + day_length + t1 + t2 + t6 + t7 + month + year + day + holidays + lagholidays + leadholidays, data = don.train)


```



## RL sans INTERACTION synthèse
```{r}
# comparaison avec modèle linéaire issu de step
# R² ajusté step légèrement meilleur que le modèle en ne gardant directement que les  variables significative mais égal à celui du modèle total
# F stat step moins élevé que fin mais supérieur au modèle total
# residual std error step moins élevé que fin mais égal modèle total.
stargazer(RL_BE_tot,RL_BE_fin,RL_BE_step,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("tot", "fin","step"))


```


## comparaison MSE RL tot, fin,  step et modèle retenu
```{r}
# modele lineaire total
MSE_RL_BE_tot= mean((Y.test-predict(RL_BE_tot,don.test))^2)

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RL_BE_fin= mean((Y.test-predict(RL_BE_fin,don.test))^2)

# modele lineaire en ne gardant que les variables significatives par step
MSE_RL_BE_step= mean((Y.test-predict(RL_BE_step,don.test))^2)

# comparaison des MSE entre les modèles RL sans interaction
MSE_RL_BE_sa=c(MSE_RL_BE_tot, MSE_RL_BE_fin, MSE_RL_BE_step)
which.min(MSE_RL_BE_sa) # c'est le modèle step qui présente la plus petite MSE

# graphe des MSE
graph<-barplot(MSE_RL_BE_sa, xlab="modèles", ylab="MSE", main="MSE des modèles",las=0)
axis(1, labels=c("tot", "final" ,"step"), at = graph)

# c'est le modèle tot qui a la plus petite MSE
RL_BE <- RL_BE_tot

```

RL_BE plot residus
```{r}
# graphe résidus vs fitted avec une structure incurvée
plot(RL_BE)

```


```{r}
checkresiduals(RL_BE)
# la distribution des résidus n'est pas bien centrée

```


## ANOVA RL tot, fin et step
```{r}

# anova: the returned information for the F-test is the difference in the sum of squares between the models, the F-statistic for this difference, and the p-value for the F-statistic.
anova(RL_BE_tot,RL_BE_fin) # la différence semble significative entre tot et fin
anova(RL_BE_fin,RL_BE_step) # la différence semble significative entre step et fin


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES AVEC INTERACTION avec la variable Temp
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## RLI modèle total avec toutes les variables
```{r}
# OLS AVEC INTERACTION entre la température et les autres variables

RLI_BE_tot<-lm(Y~(Date + cosinus + sinus + day_length + month + year + day + weekend + quarter + season + holidays + jc + lagholidays + leadholidays)*Temp ,data=don.train) 
RLI_BE_tot_sum<-summary(RLI_BE_tot)
# RLI_BE_tot_sum 

# extraction des coefficients significatifs
coef<-RLI_BE_tot_sum$coefficients[,4]
RLI_BE_tot_var <- names(which(coef<0.05))
dim_coef <- length (RLI_BE_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_BE_tot_var[i] , "+ ") }
formule

```



## RLI en ne gardant que les variables signficatives par itération jusqu'à stabilisation de formule
```{r}

RLI_BE_fin<-lm( Y~ month +  day + cosinus:Temp +  sinus:Temp +  month:Temp + lagholidays:Temp, data=don.train) 
RLI_BE_fin_sum<-summary(RLI_BE_fin)
# RLI_BE_fin_sum 

# extraction des coefficients significatifs
coef<-RLI_BE_fin_sum$coefficients[,4]
RLI_BE_fin_var <- names(which(coef<0.05))
dim_coef <- length (RLI_BE_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_BE_fin_var[i] , "+ ") }
formule

```


## RLI selection des variables par step
```{r}
RLI_BE_step <- step(RLI_BE_tot, test="F",trace=FALSE)
RLI_BE_step



```

# RLI modèle issu de step
```{r}
RLI_BE_step <-lm(formula = Y ~ Date + cosinus + sinus + day_length + month + year + day + jc + lagholidays + leadholidays + Temp + cosinus:Temp + sinus:Temp + day_length:Temp + month:Temp + year:Temp + jc:Temp + lagholidays:Temp, data = don.train)

```



## comparaison MSE RLI tot, RLI fin, RLI step
```{r}

# modele lineaire total
MSE_RLI_BE_tot= mean((Y.test-predict(RLI_BE_tot,don.test))^2)

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RLI_BE_fin= mean((Y.test-predict(RLI_BE_fin,don.test))^2)

# modele lineaire en ne gardant que les variables significatives par step
MSE_RLI_BE_step= mean((Y.test-predict(RLI_BE_step,don.test))^2)

# comparaison des MSE entre les modèles RL sans interaction
MSE_RLI_BE_sa=c(MSE_RLI_BE_tot, MSE_RLI_BE_fin, MSE_RLI_BE_step)
which.min(MSE_RLI_BE_sa) # c'est le modèle step qui présente la plus petite MSE


# c'est le modèle step qui a la plus petite MSE


```


## RLI modèle retenu, résidus
```{r}

# modèle retenu : step
RLI_BE <-RLI_BE_step 
# le graphe des résidus a moins de structure
plot(RLI_BE)


```

```{r}
checkresiduals(RLI_BE)
# la distribution est mieux centrée

```



# MODELES  AVEC INTERACTIONs multiples en séparant les variables liées à la température des autres variables

## RLI multi total avec toutes les variables
```{r}

RLI_BE_multi_tot<-lm(Y~(Date + cosinus + sinus + day_length + month + year + day + weekend + quarter + season + holidays + jc + lagholidays + leadholidays)* (Temp + t1 + t2 + t3 + t4 + t5 + t6 + t7), data=don.train) 
RLI_BE_multi_tot_sum<-summary(RLI_BE_multi_tot)
# RLI_BE_multi_tot_sum

# extraction des coefficients significatifs
coef<-RLI_BE_multi_tot_sum$coefficients[,4]
RLI_BE_multi_tot_var <- names(which(coef<0.05))
dim_coef <- length (RLI_BE_multi_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_BE_multi_tot_var[i] , "+ ") }
formule

```


## RLI multi en ne gardant que les variables significatives par itération jusqu'à stabilisation de formule
```{r}


RLI_BE_multi_fin <- lm(Y~ month +  month:t1 +  month:t3 + month:t6 +  month:t7, data=don.train) 
RLI_BE_multi_fin_sum<-summary(RLI_BE_multi_fin)
# RLI_BE_multi_fin_sum
# MSE_RLI_BE_multi= mean((Y.test-predict(RLI_BE_multi,don.test))^2)

# extraction des coefficients significatifs
coef<-RLI_BE_multi_fin_sum$coefficients[,4]
RLI_BE_multi_fin_var <- names(which(coef<0.05))
dim_coef <- length (RLI_BE_multi_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_BE_multi_fin_var[i] , "+ ") }
formule

```



## RLI multi modele issues de step ( long 7mn)
```{r}

RLI_BE_multi_step=step(RLI_BE_multi_tot, test="F", trace= FALSE)
RLI_BE_multi_step

```



## OLS RLI multi modèle issu de step
```{r}
RLI_BE_multi_step <- lm ( Y ~ Date + cosinus + sinus + day_length + month + year + day + holidays + jc + lagholidays + leadholidays + Temp + t1 + t2 + t3 + t4 + t5 + t6 + t7 + Date:Temp + Date:t1 + Date:t2 + Date:t4 + Date:t7 + cosinus:Temp + cosinus:t1 +     cosinus:t2 + cosinus:t4 + cosinus:t5 + cosinus:t7 + sinus:Temp + sinus:t1 + sinus:t2 + sinus:t4 + sinus:t5 + sinus:t6 + sinus:t7 + day_length:Temp + day_length:t1 + day_length:t2 + day_length:t3 + day_length:t5 + day_length:t7 + month:t1 + month:t3 + month:t4 + month:t6 + month:t7 + year:Temp + year:t2 + year:t4 + year:t5 + holidays:t2 + holidays:t4 + jc:t1 + lagholidays:t3 + lagholidays:t4 + lagholidays:t7 + leadholidays:t3 + leadholidays:t6, data = don.train)


```


## OLS RLI multi modele issues de step avec parallelisation (très long aussi)
```{r}
# step avec parallelisation
# mod=RLI_BE_multi_tot
# indice=1:1
# grappe <- makeCluster(ncores - 1)
# registerDoParallel(grappe)
# clusterExport(cl = grappe, varlist = "don.train")
# res_step <- foreach(indice) %dopar% step(mod, test="F")
# stopCluster(grappe)
# 
# RLI_BE_multi_step_par<-res_step # résultat

```


## OLS comparaison MSE RLI_multi tot, fin, step
```{r}
# modele lineaire total
MSE_RLI_BE_multi_tot= mean((Y.test-predict(RLI_BE_multi_tot,don.test))^2)

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RLI_BE_multi_fin= mean((Y.test-predict(RLI_BE_multi_fin,don.test))^2)

# modele lineaire en ne gardant que les variables significatives par step
MSE_RLI_BE_multi_step= mean((Y.test-predict(RLI_BE_multi_step,don.test))^2)

# comparaison des MSE entre les modèles RL sans interaction
MSE_RLI_BE_multi=c(MSE_RLI_BE_multi_tot, MSE_RLI_BE_multi_fin, MSE_RLI_BE_multi_step)
which.min(MSE_RLI_BE_multi) 

# c'est le modèle step qui est retenu

```


## OLS RLI multi, modèle retenu, graphe résidus
```{r}

# modèle retenu : 
RLI_BE_multi <- RLI_BE_multi_step

# le graphe des résidus n'a plus de structure
plot(RLI_BE_multi)


```

## OLS RLI multi autre plot résidus
```{r}
checkresiduals(RLI_BE_multi)
# la distribution est mieux centrée

```


## OLS comparaison RL, RLI, RLI multi STATS
```{r}
# comparaison modèles linéaire sans et avec interaction:
# R² ajusté plus élevé pour RLI multi
# residual std error plus faible pour RLI multi
# F-stat plus élevé pour pour RLI 
stargazer(RL_BE, RLI_BE, RLI_BE_multi ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","RLI", "multi"))



```


# MODELES AVEC INTERACTION SUR TEMP (poly 2)

## OLS AVEC INTERACTION entre Temp (poly degré 2) modèle total
```{r}

RLI_BE_P2_tot<-lm(Y~ (Date + cosinus + sinus + day_length + month + year + day + weekend + quarter + season + holidays + jc + lagholidays + leadholidays)*I(poly(Temp, 2)), data=don.train)
RLI_BE_P2_tot_sum<-summary(RLI_BE_P2_tot)
# RLI_BE_P2_tot_sum

# extraction des coefficients significatifs
coef<-RLI_BE_P2_tot_sum$coefficients[,4]
RLI_BE_P2_tot_var <- names(which(coef<0.05))
dim_coef <- length (RLI_BE_P2_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_BE_P2_tot_var[i] , "+ ") }
formule

```


## OLS AVEC INTERACTION  entre Temp (poly degré 2) en ne gardant que les variables significatives par itération jusqu'à stabilisation de formule 
```{r}


RLI_BE_P2_fin <- lm( Y~ cosinus + month +  day +  lagholidays +  cosinus:I(poly(Temp, 2)) +  sinus:I(poly(Temp, 2)) +  day_length:I(poly(Temp, 2)) +  month:I(poly(Temp, 2)), data=don.train) 
RLI_BE_P2_fin_sum<-summary(RLI_BE_P2_fin)


# extraction des coefficients significatifs
coef<-RLI_BE_P2_fin_sum$coefficients[,4]
RLI_BE_P2_fin_var <- names(which(coef<0.05))
dim_coef <- length (RLI_BE_P2_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_BE_P2_fin_var[i] , "+ ") }
formule

```



OLS AVEC INTERACTION entre Temp (poly degré 2) selection de variables par step
```{r}
RLI_BE_P2_step <- step(RLI_BE_P2_tot, test="F", trace = FALSE)
RLI_BE_P2_step


```

## OLS AVEC INTERACTION entre Temp (poly degré 2) modèle issu de step 
```{r}
RLI_BE_P2_step<-lm(formula = Y ~ Date + cosinus + sinus + day_length + month + year + day + jc + lagholidays + leadholidays + I(poly(Temp, 2)) + cosinus:I(poly(Temp, 2)) + sinus:I(poly(Temp, 2)) + day_length:I(poly(Temp, 2)) + month:I(poly(Temp, 2)) + jc:I(poly(Temp, 2)) + lagholidays:I(poly(Temp, 2)), data = don.train)


```


## comparaison RLI_P2 tot, fin et step
```{r}

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RLI_BE_P2_tot= mean((Y.test-predict(RLI_BE_P2_tot,don.test))^2)

# modele lineaire avec interaction 
MSE_RLI_BE_P2_fin= mean((Y.test-predict(RLI_BE_P2_fin,don.test))^2)

# modele lineaire avec interaction multiple en ne gardant que les variables significatives à la main
MSE_RLI_BE_P2_step= mean((Y.test-predict(RLI_BE_P2_step,don.test))^2)


# comparaison des MSE entre les modèles RL, RLI, RLI multi
MSE_RLI_BE_P2=c(MSE_RLI_BE_P2_tot, MSE_RLI_BE_P2_fin, MSE_RLI_BE_P2_step)


which.min(MSE_RLI_BE_P2) 
# c'est le modèle step qui est retenu

# graphe des MSE
graph<-barplot(MSE_RLI_BE_P2, xlab="modèles", ylab="MSE", main="MSE des modèles RLI",las=0)
axis(1, labels=c("tot","fin","step"), at = graph)

```

## modèle RLI_P2 final retenu par MSE et graphe résidus
```{r}

RLI_BE_P2 <- RLI_BE_P2_step

# le graphe des résidus n'a plus de structure incurvée
plot(RLI_BE_P2)

```


```{r}
checkresiduals(RLI_BE_P2)
# distribution pas centrée, queue à gauche

```



## OLS comparaison modèles linéaire avec interaction simples et multiples avec les stats
```{r}
# R² ajusté plus élevé pour RLI_multi
# Residual std error le plus faible pour RLI_multi
# F stat pllus élevé pour RLI
stargazer(RL_BE, RLI_BE, RLI_BE_multi, RLI_BE_P2 ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL", "RLI","multi", "P2"))


```

## comparaison RL et RLI avec les MSE
```{r}
# modele lineaire 
MSE_RL_BE= mean((Y.test-predict(RL_BE,don.test))^2)

# modele lineaire avec interaction 
MSE_RLI_BE= mean((Y.test-predict(RLI_BE,don.test))^2)

# modele lineaire avec interaction multiple
MSE_RLI_BE_multi= mean((Y.test-predict(RLI_BE_multi,don.test))^2)

# modele lineaire avec interaction multiple en ne gardant que les variables significatives à la main
MSE_RLI_BE_P2= mean((Y.test-predict(RLI_BE_P2,don.test))^2)


# comparaison des MSE entre les modèles RL, RLI, RLI multi
MSE_BE_RL=c(MSE_RL_BE, MSE_RLI_BE,MSE_RLI_BE_multi ,MSE_RLI_BE_P2)


# graphe des MSE
graph<-barplot(MSE_BE_RL, xlab="modèles", ylab="MSE", main="MSE des modèles RLI",las=0)
axis(1, labels=c("RL","RLI","RLI_multi", "RLI_P2"), at = graph)



```

## comparaison MSE RL et RLI avec MSE résultat
```{r}
which.min(MSE_BE_RL)
# c'est RLI multi

```


```{r}
checkresiduals(RL_BE)
```

```{r}
checkresiduals(RLI_BE)
```


```{r}
checkresiduals(RLI_BE_multi)
```


```{r}
checkresiduals(RLI_BE_P2)

```


## Graphes modèles RL et RLI
```{r}
pred_RL_BE=predict(RL_BE, newdata=don.test, se=T)
pred_RLI_BE=predict(RLI_BE, newdata=don.test, se=T)
pred_RLI_BE_P2=predict(RLI_BE_P2, newdata=don.test, se=T)
pred_RLI_BE_multi=predict(RLI_BE_multi, newdata=don.test, se=T)

# graphe des valeurs prédites selon les modèles
# plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RL et RLI Belgique" )
# lines(don.test$Date,pred_RL_BE$fit, col="blue")
# lines(don.test$Date,pred_RLI_BE$fit, col="red")
# lines(don.test$Date,pred_RLI_BE_P2$fit, col="green")

plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RL sur Belgique" )  # les valeurs extrèmes sont sous-estimées
lines(don.test$Date,pred_RL_BE$fit, col="blue")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI simple sur Belgique" )  # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_BE$fit, col="red")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RLI poly2 sur Belgique" )  # les valeurs extrèmes sont surestimées
lines(don.test$Date,pred_RLI_BE_P2$fit, col="green")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI multiple sur Belgique" )   # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_BE_multi$fit, col="yellow")

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES POLYNOMIAL
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

POLYNOME base et variables sur la base centrée réduite

Modèles avec cible=Conso en fonction d'un polynome sur Temp

## POLYNOME détermination du degré par cross validation hold out train / test
```{r}

d=20 # degré max de polynome à tester
err_poly_BE_HO=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX.train)
  err_poly_BE_HO[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(sqrt(err_poly_BE_HO),ylab="MSE", main=' MSE Belgique selon le degré de polynome',pch=19,type='b')


```

## POLYNOME détermination du degré par cross validation hold out resultats
```{r}
which.min(err_poly_BE_HO) 
# 5

```


## POLYNOME détermination du degré par cross validation hold out modèle retenu et résidus
```{r}

#modèle retenu par hold out
poly_BE_HO<- lm(formula=Y~poly(X,which.min(err_poly_BE_HO), raw=T), data=donYX.train)
poly_BE_HO_sum<- summary(poly_BE_HO)
MSE_poly_BE_HO= mean((Y.test-predict(poly_BE_HO,donYX.test))^2)

# le graphe des résidus vs fitted n'a plus de structure incurvée
plot(poly_BE_HO)

```


## POLYNOME détermination du degré par cross validation K-fold 
```{r}

# # CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
err_poly_BE_KF =as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX.train)
err_poly_BE_KF[i]<-cv.glm(donYX.test,glm.fit,K=10)$delta[1]
}

plot(err_poly_BE_KF, pch=19,type='b')

```

## POLYNOME détermination du degré par cross validation K-fold résulats
```{r}
which.min(err_poly_BE_KF) 

```



## POLYNOME détermination du degré par cross validation K-fold modèle retenu et résidus
```{r}

#modèle retenu par K_fold
poly_BE_KF<- lm(formula=Y~poly(X,which.min(err_poly_BE_KF), raw=T), data=donYX.train)
MSE_poly_BE_KF= mean((Y.test-predict(poly_BE_KF,donYX.test))^2)

# le graphe des résidus vs fitted a une structure incurvée
plot(poly_BE_KF)

```


## POLYNOME détermination du degré par cross validation LOOCV à éviter, trop long
```{r}
# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
# library(boot)
# d=10 # degré de polynome 
# cv.error=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~poly(X,i),data = donYX) 
#   cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }
# plot(cv.error, type="l") 

```


## comparaison poly hold out et K-Fold
```{r}

# COMPARAISON DES MODELES
#modèle retenu par hold out
poly_BE_HO<- lm(formula=Y~poly(X,which.min(err_poly_BE_HO), raw=T), data=donYX.train)
MSE_poly_BE_HO= mean((Y.test-predict(poly_BE_HO,donYX.test))^2)

#modèle retenu par K_fold
poly_BE_KF<- lm(formula=Y~poly(X,which.min(err_poly_BE_KF), raw=T), data=donYX.train)
MSE_poly_BE_KF= mean((Y.test-predict(poly_BE_KF,donYX.test))^2)

#comparaison des modèles linéaire total avec poly
# R² ajusté plus faible pour poly par rapport au modèle linéair
# résidual sdt error plus élevé pour poly que dans RL 
# F stat plus élevé pour les poly que pour modèle linéaire
stargazer(RL_BE,poly_BE_HO, poly_BE_KF, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","polyHO", "polyKF"))




```

## choix du degré par MSE
```{r}
# en comparant les MSE, 
diff_POLY_BE=MSE_poly_BE_HO - MSE_poly_BE_KF
diff_POLY_BE # MSE_poly_BE_HO < MSE_poly_BE_KF
# 
# nous retiendrons poly_BE_HO sur le critère du MSE
POLY_BE<- poly_BE_HO
POLY_BE_sum<- summary(POLY_BE)
MSE_POLY_BE_tot= mean((Y.test-predict(POLY_BE,donYX.test))^2)


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES SPLINES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

SPLINE Conso en fonction de la température


## SPLINES choix du degré de liberté/noeuds par CV hold out pour natural splines
```{r}

# CHOIX DU DEGRE DE LIBERTE df (et donc du nombre de noeuds) par cross validation HOLD OUT TRAIN/TEST 
# l'option df produit des splines avec des noeuds placés sur les quantiles
# on n'obtient pas les mêmes noeuds en bs et ns, pour un même degré de liberté
# attr() pour avoir les noeuds issus de df

# # noeuds avec basic splines
# attr(bs(X,df=3),"knots") # pas de noeud
# attr(bs(X,df=4),"knots") # un seul noeud à 50% = 2 intervalles + 2 frontières min et max
# attr(bs(X,df=5),"knots") # 2 noeuds à 1/3 et 2/3 = 3 intervalles + 2 frontières min et max
# attr(bs(X,df=6),"knots") # 3 noeuds à 25%, 50% et 75% = 4 intervalles + 2 frontières min et max
# 
# # noeuds avec natural splines
# attr(ns(X,df=1),"knots") #  pas de noeud
# attr(ns(X,df=2),"knots") #  un seul noeud à 50%
# attr(ns(X,df=3),"knots") #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
# attr(ns(X,df=4),"knots") #  3 noeuds à 25% (5.8), 50% (10.2),75% (15.5)
# attr(ns(X,df=5),"knots") #  4 noeuds à 20% (4.9), 40% (8.5),60% (12.2), 80% (16.5)


# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
MSE_SP_BE_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(X,df=i), data=donYX.train)
  MSE_SP_BE_ns[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(sqrt(MSE_SP_BE_ns),ylab="MSE", main=' MSE Belgique selon le degré de liberté du spline',pch=19,type='b')


```


## SPLINES choix du degré de liberté/noeuds résultats
```{r}

which.min(MSE_SP_BE_ns)
# 3

```

## SPLINES choix du degré de liberté: nombre de noeuds
```{r}
attr(ns(X,df=which.min(MSE_SP_BE_ns)),"knots")
# 2 noeuds

```


## SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}


# pour basic spline, recherche degré df qui minimise le MSE 

DF=15 # df max à tester
MSE_SP_BE_bs=rep(0,DF)
for(i in 4:DF) {
  model <- lm(Y~bs(X,df=i), data=donYX.train)
  MSE_SP_BE_bs[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(sqrt(MSE_SP_BE_bs),ylab="MSE", main=' MSE selon le degré de liberté du spline',pch=19,type='b')

```

## SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines résultat
```{r}
which.min(MSE_SP_BE_bs)+3 # le test démarre à df=4

```

## SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}
attr(bs(X,df=which.min(MSE_SP_BE_bs)+3),"knots")
# 1 noeud

```


## SPLINES choix entre natural splines et basic splines par CV hold out 
```{r}

# CHOIX ENTRE BASIC SPLINES ET NATURAL SPLINES, celui qui minimise le MSE

#natural splines ns
# ns() ne marche que si les variables sont numériques. Les variables qualitatives seront transformées en dummy variables
attr(ns(X,df=which.min(MSE_SP_BE_ns)),"knots")  # 2 noeuds 
fit_ns_BE_tot=lm(Y~ns(X,df=which.min(MSE_SP_BE_ns)), data=donYX.train)
plot(fit_ns_BE_tot)
MSE_SP_BE_ns <- mean((Y.test-predict(fit_ns_BE_tot,donYX.test))^2)

#basic splines bs: on prend le df qui donne les mêmes noeuds que natural spline 
attr(bs(X,df=which.min(MSE_SP_BE_bs)+3),"knots") # 1 noeud
fit_bs_BE_tot=lm(Y~bs(X,df=which.min(MSE_SP_BE_bs)+3), data=donYX.train)
plot(fit_bs_BE_tot)
MSE_SP_BE_bs <- mean((Y.test-predict(fit_bs_BE_tot,donYX.test))^2)


diff_BE_bs_ns=MSE_SP_BE_bs-MSE_SP_BE_ns
diff_BE_bs_ns # MSE_SP_BE_bs < MSE_bs_BE_ns 
# => avec les mse, on choisirait bs


```


## SPLINES choix entre natural splines et basic splines par CV hold out comparaison
```{r}


#comparaison des stats des résultats entre basic et natural splines
stargazer(fit_bs_BE_tot, fit_ns_BE_tot, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("bs", "ns"))
# => avec les stat des modèles, choix de ns car F-stat plus grand qu bs. Le R² ajusté et residual std error sont égaux entre ns et bs

```


## SPLINES choix entre natural splines et basic splines par CV hold out résultats et résidus
```{r}

# en minimisant MSE, on retient spline bs avec df=4 trouvé par cross validation hold out
SP_BE=lm(Y~bs(X,df=which.min(MSE_SP_BE_bs)+3), data=donYX.train) #  1 noeud 
pred_SP_BE=predict(SP_BE, newdata=donYX.test, se=T)
MSE_SP_BE= mean((Y.test-predict(SP_BE,donYX.test))^2)
plot(SP_BE) # graphe des résidus vs fitted n'a plus de structure incurvée


```

```{r}
checkresiduals(SP_BE)
# résidus corrects, distribution gaussienne centrée
```


## SPLINES graphes et smooting splines
```{r}

# graphes de conso vs température
plot(X.test,Y.test, xlab = "Temp", ylab="Conso")
points (X.test,pred_SP_BE$fit, col="blue") 

# graphe de conso vs date
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="Spline Belgique, fit (bleu)" )
lines(don.test$Date,pred_SP_BE$fit, col="blue") 


# SMOOTHING SPLINE
SM_BE=smooth.spline(Y.test,X.test,df=3) # on spécifie df=6 et le lambda est déterminé de sorte à obtenir df=6
SM_BE_cv=smooth.spline(Y.test,X.test,cv=TRUE) # lambda est choisi par cross validation

plot(SM_BE, main="smooth spline") 
plot(SM_BE_cv, main="cv") 


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES GAM
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

 GAM base centrée réduite et variables

## GAM détermination du polynome par CV K-fold avec toutes les variables : 
message erreur prediction from a rank-deficient fit may be misleading

```{r}
# library(boot)

d=15 # degré de poly à tester
GAM_cv.error_BE=rep(0,d)
for (i in 1:d) { 
  glm.fit= glm(Y~ poly(Temp,i) + Date + cosinus + sinus + day_length  + month + year + day + weekend + quarter + season + holidays + jc + lagholidays + leadholidays + t1 + t2 + t3 + t4 + t5 + t6 + t7, data = don) 
  GAM_cv.error_BE[i]=cv.glm(don, glm.fit, K=10 )$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(GAM_cv.error_BE, main="GAM Belgique cv.error selon degré polynome",pch=19,type='b') 


```

## GAM détermination du polynome par CV K-fold résultats
```{r}
GAM_BE_deg = which.min(GAM_cv.error_BE) 
GAM_BE_deg
# 6

```

## GAM détermination du polynome par CV K-fold modèle retenu 
```{r}

# modèle GAM avec polynôme sur la température 

GAM_BE_tot=glm(Y~ poly(Temp,GAM_BE_deg) + Date + cosinus + sinus + day_length + month + year + day + weekend + quarter + season + holidays + jc + lagholidays + leadholidays + t1 + t2 + t3 + t4 + t5 + t6 + t7, data = don.train) 

GAM_BE_tot_sum <-summary(GAM_BE_tot)

# extraction des coefficients significatifs
coef<-GAM_BE_tot_sum$coefficients[,4]
GAM_BE_tot_var <- names(which(coef<0.05))
dim_coef <- length (GAM_BE_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, GAM_BE_tot_var[i] , "+ ") }
formule

```

## GAM avec variables significatives à la main
```{r}


# modèle avec les variables significatives
GAM_BE_fin=glm(Y~  poly(Temp, GAM_BE_deg) +  cosinus +  sinus +  day_length + day + lagholidays +  t3 +  t7, data = don.train) 
GAM_BE_fin_sum <- summary (GAM_BE_fin)
# pred_GAM_BE=predict(GAM_BE, newdata=don.test, se=T)
# summary(GAM_BE)

# extraction des coefficients significatifs
coef<-GAM_BE_fin_sum$coefficients[,4]
GAM_BE_fin_var <- names(which(coef<0.05))
dim_coef <- length (GAM_BE_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, GAM_BE_fin_var[i] , "+ ") }
formule

```


## GAM avec variables issues de step
```{r}
GAM_BE_step<-step(GAM_BE_tot, test="F", trace=FALSE)
GAM_BE_step



```

# GAM modèle step
```{r}
GAM_BE_step = glm(Y ~ poly(Temp, GAM_BE_deg) + cosinus + sinus + day_length + month + year + day + holidays + lagholidays +     leadholidays + t3 + t5 + t6 + t7, data = don.train)


```


## comparaison MSE GAM tot, fin, step
```{r}
# modele lineaire total
MSE_GAM_BE_tot= mean((Y.test-predict(GAM_BE_tot,don.test))^2)

# modele lineaire en ne gardant que les variables significatives à la main
MSE_GAM_BE_fin= mean((Y.test-predict(GAM_BE_fin,don.test))^2)

# modele lineaire en ne gardant que les variables significatives par step
MSE_GAM_BE_step= mean((Y.test-predict(GAM_BE_step,don.test))^2)

# comparaison des MSE entre les modèles RL sans interaction
MSE_GAM_BE=c(MSE_GAM_BE_tot, MSE_GAM_BE_fin, MSE_GAM_BE_step)
which.min(MSE_GAM_BE) 

# c'est le modèle total qui est retenu

```


## GAM modèle retenu, résidus
```{r}

# modèle retenu : 
GAM_BE <- GAM_BE_tot

# le graphe des résidus est encore légèrement incurvé
plot(GAM_BE)


```

```{r}
checkresiduals(GAM_BE)
# résidus corrects, distribution centrée gaussienne

```



## GAM valeurs prédites
```{r}
pred_GAM_BE=predict(GAM_BE, newdata=don.test, se=T)
# graphe des valeurs prédites par GAM sur la Belgique
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="GAM" )
lines(don.test$Date,pred_GAM_BE$fit, col="yellow")


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES RANDOM FOREST
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## RANDOM FOREST base et variables
```{r}

# on peut régler deux éléments : 
# ntree: le nombre d’arbres construits par l’algorithme 
# mtry: le nombre de variables testées à chaque division. 
# la valeur par défaut de mtry correspond à la racine carrée du nombre de variables pour classification et le tiers pour les régressions


don<-base_BE_F_cr
head(don)
dim(don)
sqrt(ncol(don)) # = 5


```

## RANDOM FOREST modelisation
```{r}


# modelisation sur train, par défaut ntree=500
RF_BE_tot<-randomForest(Y~., data=don.train)
# summary(RF_BE_tot)
print(RF_BE_tot)
# names(RF_BE_tot) 
# "call"            "type"            "predicted"       "mse"             "rsq"            
# "oob.times"       "importance"      "importanceSD"    "localImportance" "proximity"      
# "ntree"           "mtry"            "forest"          "coefs"           "y"              
# "test"            "inbag"           "terms" 

```

## RANDOM FOREST MSE plot
```{r}

# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 100 environ
plot(RF_BE_tot$mse, xlab = "nombre d'arbres", ylab = "MSE")

```

## RANDOM FOREST choix de mtry par CV hold out
```{r}
# boucle de test long
set.seed(1)
m=15 # mtry max à tester. 
MSE_RF_BE_mtry=rep(0,m)
for(i in 1:m) {
  set.seed(1)
  model <- randomForest(Y~., data=don.train, mtry = i)
  MSE_RF_BE_mtry[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# graphe de MSE
plot(MSE_RF_BE_mtry, xlab="mtry", ylab="MSE", main="MSE selon mtry", type="b")

```

## RANDOM FOREST choix de mtry par CV résultats
```{r}

RF_BE_mtry= which.min(MSE_RF_BE_mtry) 
# 8

```



## RANDOM FOREST choix de ntree par CV: résultats pas stables
```{r}


Ntree=seq(100,1000,by=100)  # ntree à tester
d=length(Ntree)
nb=1 # nombre de tests de cross validation
MSE_RF_BE_tree=rep(NA,d*nb)
res_ntree=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE

for (j in 1:nb) {

  for(i in 1:d) {
    set.seed(1)
    model <- randomForest(Y~., data=don.train, mtry = RF_BE_mtry, ntree=Ntree[i])
    MSE_RF_BE_tree[i+j-1] <- mean((don.test$Y-predict(model,don.test))^2)
  }

  res_ntree[j]=Ntree[which.min(MSE_RF_BE_tree)]

}

res_ntree

# plot(MSE_RF_BE_tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")
# premier test Ntree=seq(100,500,by=100) : MSE décroissant avec ntree, minimul pour 500
# deuxième test avec Ntree=seq(100,1000,by=100): MSE croissant avec ntree, minimal pour 500

# graphe des MSE du choix de ntree
RF_BE_ntree = Ntree[which.min(MSE_RF_BE_tree)]
RF_BE_ntree # 200

barplot(MSE_RF_BE_tree, xlab="ntree", ylab="MSE", ylim = range(MSE_RF_BE_tree), main="MSE selon ntree")




```

## RANDOM FOREST choix de nodesize par CV 
```{r}

# CHOIX DE NODESIZE PAR CV HOLD OUT
n_list=seq(from=1,to=10,by=1)  # nodesize à tester
d=length(n_list)
nb=1 # nombre de tests de cross validation
MSE_RF_BE_node=rep(NA,d*nb)
res_node=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE

for (j in 1:nb) {
  
  for(i in 1:d) {
    set.seed(1)
    model <- randomForest(Y~., data=don.train,mtry = which.min(MSE_RF_BE_mtry), ntree=RF_BE_ntree, nodesize = n_list[i])
    MSE_RF_BE_node[i+j-1] <- mean((Y.test-predict(model,don.test))^2)
    names(MSE_RF_BE_node)[i] <- paste(as.character(n_list[i]),"node",sep="_")
  }

  res_node[j]=n_list[which.min(MSE_RF_BE_node)]

}

res_node


```



## RANDOM FOREST choix de nodesize résultats
```{r}

# graphe des MSE du choix de nodesize
RF_BE_node = which.min(MSE_RF_BE_node) # 1

# plot(MSE_RF_BE.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")


barplot(MSE_RF_BE_node, xlab="ntree", ylab="MSE", ylim = range(MSE_RF_BE_node) , names = names(MSE_RF_BE_node) ,main="MSE selon nodesize",las=0) 


```

## RANDOM FOREST modèle final
```{r}
RF_BE<-randomForest(Y~., mtry = RF_BE_mtry, ntree=RF_BE_ntree, nodesize = RF_BE_node ,data=don.train)

```


## RANDOM FOREST plot variables par importance
```{r}

varImpPlot(RF_BE)

```


## RANDOM FOREST liste variable par importance
```{r}

RF_BE$importance

```

## RANDOM FOREST liste variable par importance ordonnée
```{r}
RF_BE$importance[order(RF_BE$importance[, 1], decreasing = TRUE), ]


```


## RANDOM FOREST prediction
```{r}

# prediction
RF_BE_pred<-predict(RF_BE,don.test)
RF_BE_pred_sum<-summary(RF_BE_pred)
# RF_BE_pred_sum

MSE_RF_BE= mean((Y.test-predict(RF_BE,don.test))^2)

# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_point(aes(x = don.test$Date, y = Y.test),
             colour = 'red') +
  geom_line(aes(x = don.test$Date, y = RF_BE_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```

```{r}
# names(RF_BE)
# str(RF_BE)

res_RF_BE=don.test$Y-RF_BE$predicted
checkresiduals(res_RF_BE)
# la saisonnalité n'a pas été bien captée: le graphe des résidus est sinusoidal

```


```{r}
plot(RF_BE$mse)
```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES SVR
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



##SVR modelisation train/test
```{r}

# # train and test
# # éviter les valeurs manquantes
# set.seed(1)
# split=sample.split(don$Y, SplitRatio=2/3)
# don.train=subset(don,split==TRUE)
# don.test=subset(don,split==FALSE)
# Y.test=subset(don,split==FALSE)

#Regression with SVM
SVR_BE_tot = svm(Y~.,don.train)
MSE_SVR_BE_tot= mean((Y.test-predict(SVR_BE_tot,don.test))^2)

#Predict using SVM regression
pred_SVR_BE = predict(SVR_BE_tot, don.test)

#Overlay SVM Predictions on Scatter Plot
plot(don.test$Date, Y.test)
lines(don.test$Date, pred_SVR_BE, col="purple")



```


## SVR names
```{r}
# names(SVR_BE_tot)


```


##SVR residuals
```{r}

plot(SVR_BE_tot$residuals)


```

```{r}
res_SVR_BE=don.test$Y-pred_SVR_BE
checkresiduals(res_SVR_BE)
# plusieurs autocorrélation, distribution centrée, gaussienne

```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# RESEAUX NEURONES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## modelisation CV
```{r}

# avec caret
controlList <- trainControl(method = "cv", number = 5)
tuneMatrix <- expand.grid(size = c(1, 2, 3, 4, 5, 6), decay = seq(from = 0, to = 0.5, by=0.1))

set.seed(1)
NN_BE_tot <- train(x = don.train[ , colnames(don.train) != "Y"],
                   y = don.train[ , colnames(don.train) == "Y"],
                   method = "nnet",
                   linout = TRUE,
                   trace = FALSE,
                   maxit = 100,
                   tuneGrid = tuneMatrix,
                   trControl = controlList)

  
```


## plot
```{r}

plot(NN_BE_tot)


```

## modèle final
```{r}

# print(NN_BE_tot$finalModel)

set.seed(1)
NN_BE <- NN_BE_tot$finalModel
pred_NN_BE <- predict(NN_BE, newdata = don.test)
MSE_NN_BE <- mean((pred_NN_BE - don.test$Y)^2)

```

## names
```{r}
# names(NN_BE_tot$finalModel)

```

## tune value
```{r}
tv=NN_BE_tot$finalModel$tuneValue
str(tv)

```



```{r}
res_NN_BE=Y.test-pred_NN_BE
# str(res_NN_BE) # liste avec 2 
# head(res_NN_BE)

checkresiduals(res_NN_BE[,1])
# la distribution n'est pas vraiment gaussienne


```



