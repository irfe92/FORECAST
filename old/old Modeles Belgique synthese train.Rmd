---
title: "Synthese Belgique"
author: "NNN"
date: "16 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# COMPARAISON DES MODELES BE

#Load Library
# install.packages("stargaze")
library(stargazer)
library(splines) 
library(randomForest)
library(e1071)
library(ISLR)
library(leaps)
library(questionr)

# sur la base centrée réduite, sans les autres variables méteo
don<-base_BE_F_cr
head(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))

# Creation de l'echantillon train 2/3 individus et test 1/3
set.seed(1)
dim<-nrow(don)
train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
test=model.matrix(Y~.,data=don[-train,])# base de test
Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]
don.train=don[train,]
don.test=don[-train,]
donYX.train=donYX[train,]
donYX.test=donYX[-train,]

```

MODELES SUR BE
```{r}


# modèle linéaire simple avec que les variables significatives RL_BE2
RL_BE<-lm(Y ~ Temp+ cosinus + sinus + day_length + T00 + t1 + t5 + t6 + t7 + month + day + lagholidays + leadholidays, data=don[train,])
pred_RL_BE=predict(RL_BE, newdata=don.test, se=T)
mse_RL_BE= mean((Y.test-predict(RL_BE,don.test))^2)

# modèle linéaire simple avec que les variables significatives sélectionnée par step
RL_BE_step<-lm(formula = Y ~ Temp + cosinus + sinus + day_length + T00 + t1 + t4 + t5 + t6 + t7 + month + year + day + holidays + lagholidays + leadholidays, data = don[train,])
mse_RL_BE_step= mean((Y.test-predict(RL_BE_step,don.test))^2) 


# modèle linéaire avec interaction en ne gardant que les variables significatives
RLI_BE<-lm(Y~ cosinus + day_length + month + year + day + leadholidays + Temp + (month+year)*Temp,data=don[train,]) 
pred_RLI_BE=predict(RLI_BE, newdata=don.test, se=T)
mse_RLI_BE= mean((Y.test-predict(RLI_BE,don.test))^2)


# poly5 pour BE sur le critère du MSE,issu de la validation hold out train/test et k_folds
poly_BE<- lm(formula=Y~poly(X,5, raw=T), data=donYX.train)
pred_poly_BE=predict(poly_BE, newdata=donYX.test, se=T) # length 383
mse_poly_BE= mean((Y.test-predict(poly_BE,donYX.test))^2)
length(pred_poly_BE$fit)

# modèle spline sur toute la base BE, #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
SP_BE=lm(Y~ns(X,df=3), data=donYX.train) 
pred_SP_BE=predict(SP_BE, newdata=donYX.test, se=T)
mse_SP_BE= mean((Y.test-predict(SP_BE,donYX.test))^2)


# modèle GAM sur toute la base_BE
gam_BE=lm(Y~poly(Temp,8) + day_length + teff + month + day + holidays + lagholidays + leadholidays,data = don[train,]) 
pred_gam_BE=predict(gam_BE, newdata=don.test, se=T)
mse_gam_BE= mean((Y.test-predict(gam_BE,don.test))^2)


# Random Forest sur toute de la base, avec mtry choisi par CV hold out, ntree=500 par défaut
RF_BE<-randomForest(Y~., mtry = 7, data=don[train,])
pred_RF_BE = predict(RF_BE, don.test)
mse_RF_BE= mean((Y.test-predict(RF_BE,don.test))^2)


# SVR sur toute la base BE
svr_BE = svm(Y~.,don[train,])
pred_svr_BE = predict(svr_BE, don.test)
mse_SVR_BE= mean((Y.test-predict(svr_BE,don.test))^2)



```


SYNTHESE DES MODELES objet RF et SVR pas reconnu par stargazer
```{r}

stargazer(RL_BE,RLI_BE,poly_BE,SP_BE, gam_BE, type='text', flip=TRUE, title="Results", align=TRUE, keep=c("Date"), column.labels = c("RL", "RLI","poly","Spline" ,"GAM"), model.names = TRUE, single.row = TRUE)

# le R² ajusté est le plus élevé pour GAM (0.978) et le plus faible pour Poly et Spline à 0.903
# le residual error est le plus faible pour GAM (0.154) et le plus élevé pour poly et Spline (0.319)
# F-stat est le plus élevé pour Spline (2400) et le plus faible pour RL (732)

```



```{r}
# comparaison des MSE entre les modèles RL, RLI, Poly, Spline, GAM, SVR
mse_BE=c(mse_RL_BE, mse_RLI_BE, mse_poly_BE, mse_SP_BE,mse_gam_BE,mse_RF_BE,mse_svr_BE)

# graphe des MSE
graph<-barplot(mse_BE, xlab="modèles", ylab="MSE", main="MSE des modèles sur la Belgique",las=0)
axis(1, labels=c("Reg.Lin", "RL Inter", "Poly" ,"SPLINE","GAM", "RF", "SVR"), at = graph)

```

```{r}

# comparaison des MSE entre les modèles RL, RLI, GAM, SVR
mse_BE_r=c(mse_RL_BE, mse_RLI_BE, mse_gam_BE,mse_RF_BE,mse_svr_BE)

# graphe des MSE
graph<-barplot(mse_BE_r, xlab="modèles", ylab="MSE", main="MSE des modèles sur la Belgique sur test",las=0)
axis(1, labels=c("Reg.Lin", "RL Inter", "GAM", "RF", "SVR"), at = graph)

```


MSE minimal
```{r}
which.min(mse_BE) # c'est le modèle 7 ie SVR qui présente la plus petite MSE
```


graphe des valeurs prédites selon les modèles
```{r}

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles sur la Belgique" )
lines(don.test$Date,pred_RL_BE$fit, col="purple") # length 387
lines(don.test$Date,pred_RLI_BE$fit, col="cyan") # length 387
lines(don.test$Date,pred_gam_BE$fit, col="yellow") # length 387
lines(don.test$Date, pred_svr_BE, col="blue") # length 387
lines(don.test$Date, pred_RF_BE, col="red") # length 387
lines(don.test$Date,pred_poly_BE$fit, col="pink") # length 387
lines(don.test$Date,pred_SP_BE$fit, col="green") # length 387

```

```{r}
# graphes avec les 3 meilleurs modèles RF, SVR, GAM
plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèles sur la Belgique, GAM(yellow), SVR(blue), RF(red)" )
lines(don.test$Date,pred_gam_BE$fit, col="yellow")
lines(don.test$Date, pred_svr_BE, col="blue")
lines(don.test$Date, pred_RF_BE, col="red")

```





