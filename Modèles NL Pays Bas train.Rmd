---
title: "Modeles NL Pays Bas"
author: "Nhu-Nguyen Ngo"
date: "27 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

remplacer base_F_6P par base_NL_F
remplacer _6P par _NL
remplacer 6 pays par Pays Bas

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 PACKAGES BASE ET VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

PACKAGES
```{r}

library(rpart)				  # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)			# Enhanced tree plots
library(RColorBrewer)		# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree
library(caret)		
library(ISLR)
library(leaps)

library(glmnet) # Poly, GAM
library(boot) # Poly, GAM

library(splines)

library(caTools)
library(randomForest)

library(e1071) # SVR

library(stargazer)
library(ggplot2)
library(questionr)


```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ARBRE DE DECISION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

base et variables pour Arbre décision NON CENTREE REDUITE, sans les autres variables météo
```{r}

# sur base totale avec tous les pays, non centrée réduite
don<-base_NL_F
# head(don)
# str(don)

# definition variables Y
library(questionr)
don <- rename.variable(don, "Conso", "Y")
Y=don$Y

head(don)
str(don)


```


ARBRE DECISION K_fold avec k=10 (par défaut)
```{r}

tree_NL_total<-rpart(Y~.,data=don)
tree_NL_total
# prp(tree_NL_total)               # A fast plot													
fancyRpartPlot(tree_NL_total, main="arbre de décision Pays Bas")		# A fancy plot from rattle

# rpart choisit l'arbre par validation croisée k-fold. Par défaut k=10. On peut spécifier k avec xval=k
# si xval=nrow(don), c'est un LOOCV leave one out
# on peut spécifier le nombre minimum de données dans un noeud avec minsplit=


```




ARBRE DECISION plot
```{r}
plotcp(tree_NL_total) 
# graphe qui permet de choisir le nombre de feuilles qui minimise l'erreur. 
# on prend le cp correspondant pour construire l'arbre final

```

ARBRE DECISION FINAL avec k=10
```{r}
tree_NL_totalf<-rpart(Y~.,data=don, cp=0.013)
fancyRpartPlot(tree_NL_totalf, main="arbre de décision Pays Bas")

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 BASE POUR LES AUTRES MODELES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


BASE CENTREE REDUITE, sans les autres variables météo
```{r}

# base totale centrée réduite, sans les variables météo
don<-base_NL_F_cr
head(don)
dim(don)

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
head(don)
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))


# Creation de l'echantillon train individus et test 
set.seed(1)
dim<-nrow(don.train)
partage=2/3

train=sample(dim,partage*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage

test=model.matrix(Y~.,data=don[-train,])# base de test

Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]

don.train=don[train,]
don.test=don[-train,]

donYX.train=donYX[train,]
donYX.test=donYX[-train,]


p=ncol(don) # nombre de variables explicatives
p

names(don)

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 MODELES SELECTION DE VARIABLES REGSUBSETS
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


SELECTION DE VARIABLES AVEC REGSUBSET exhaustif à éviter
```{r}

# # SELECTION EXHAUSTIVE: A EVITER car P GRAND !! (ici 27 variables trop grand)
# # Exhaustive search will be S L O W, must specify really.big=T
# # On va obtenir 2^p modeles comprenant entre une et p variables
# # par défaut, le nombre de variable est 8. Préciser le nombre de variables avec nvmax
# 
# best_full_tot=regsubsets(Y~.,data=don[train,],nvmax=p,method='exhaustive')
# 
# # choisir les meilleures variables: evaluer chacun des modeles sur le test set et calculer la MSE
# MSE_full_tot=rep(NA,p)
# for(i in 1:p){
#   coefi=coef(best_full_tot,id=i)
#   pred=test[,names(coefi)]%*%coefi
#   MSE_full_tot[i]=mean((Y.test-pred)^2)
# }
# 
# # plot les RMSE des modeles sur le training 
# # On choisit le modele qui a la RMSE la plus petite sur le test set
# plot(sqrt(MSE_full_tot),ylab='Root MSE des p modeles',pch=19,type='b')
# which.min(MSE_full_tot) # ici, c'est le modèle à 12 variables (toutes les variables)
# 
# # Pour acceder aux coefficient du modele avec la RMSE la plus petite, on appelle la fonction coeff
# # Pour acceder aux RSS des modeles, on lance la fonction summary
# coef(best_full,12)
# summary(best_full)$rss

```


SELECTION DE VARIABLES AVEC REGSUBSET forward
```{r}

# FORWARD SELECTION: NB pas assuré d'avoir le modèle optimal, mais possible si n<p

best_FW_NL=regsubsets(Y~.,data=don.train,nvmax=p,method='forward')
FW_NL_sum<-summary(best_FW_NL)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_FW_NL=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_FW_NL,id=i)
  pred=test[,names(coefi)]%*%coefi   # matrix modele et pas don.test
  MSE_FW_NL[i]=mean((Y.test-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_FW_NL),ylab='Root MSE des p modeles FW', main="Regsubset forward sur base Pays Bas",pch=19,type='b')
 


```


SELECTION DE VARIABLES AVEC REGSUBSET forward résultats MSE
```{r}
which.min(MSE_FW_NL)
# d'après le graphe, MSE quasi stable à partir de 20

```


SELECTION DE VARIABLES AVEC REGSUBSET forward coef MSE
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables )
coef(best_FW_NL,27)

# variables sélectionnées par regsubset forward MSE: Date + Temp + cosinus + sinus + day_length + teff + t1 + t3 + t4 + t5 + t7 + month + year + day + seuil + wday + quarter + season

```


SELECTION DE VARIABLES AVEC REGSUBSET forward détails
```{r}
# FW_NL_sum

```


SELECTION DE VARIABLES AVEC REGSUBSET forward rss
```{r}
# # Pour acceder aux RSS des modèles, on lance la fonction summary
# FW_NL_sum$rss


```


SELECTION DE VARIABLES AVEC REGSUBSET backward
```{r}
# selection variables BACKWARD: NB pas assuré d'avoir le modèle optimal,pas possible si n<p

best_BW_NL=regsubsets(Y~.,data=don.train,nvmax=p,method='backward')
sum_BW_NL<-summary(best_BW_NL)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_BW_NL=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_BW_NL,id=i)
  pred=test[,names(coefi)]%*%coefi  # matrix modele et pas don.test
  MSE_BW_NL[i]=mean((Y.test-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_BW_NL),ylab='Root MSE des p modeles',main="Regsubset backward sur base Pays Bas",pch=19,type='b') 



```


SELECTION DE VARIABLES AVEC REGSUBSET backward résultats
```{r}
which.min(MSE_FW_NL) 
# d'après le graphe, MSE quasi-stable à partir de 15

```


SELECTION DE VARIABLES AVEC REGSUBSET backward coef
```{r}

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_NL,27) 

# variables sélectionnées par regsubset backward MSE: Date + Temp + cosinus + sinus + day_length + teff + t1 + t4 + t5 + t7 + month + year + day + quarter + season 

```


SELECTION DE VARIABLES AVEC REGSUBSET MSE
```{r}
# plot des RMSE pour les modèles FW et BW

x=c(1:p)
y1=sqrt(MSE_FW_NL)
y2=sqrt(MSE_BW_NL)
plot(x, y1, type = "l", ylim = range(c(y1, y2)), xlab = "nb de variables", ylab = "root mse", main="MSE Pays Bas FW (blue) et BW (red)")
lines(x, y1, col = "blue")
lines(x, y2, col = "red")


```


SELECTION DE VARIABLES AVEC REGSUBSET RSS
```{r}

# Pour acceder aux RSS des modeles, on lance la fonction summary
# summary(best_FW_NL)$rss
# summary(best_BW_NL)$rss


```


SELECTION DE VARIABLES AVEC REGSUBSET plot BIC
```{r}

# choix des variables selon critères BIC, R² ajusté, Cp
# graphe BIC autre: “Cp”, “adjr2”, “r2". classification des valeurs de BIC selon les modèles, en haut la plus petite valeur de BIC et en noir les variables inclusent dans le modèle
# Le $R^2$ ajusté permet de déterminer à quel point le modèle ajuste vos données lorsque vous souhaitez l'ajuster en fonction du nombre de prédicteurs inclus. La valeur du $R^2$ ajusté intègre le nombre de prédicteurs dans le modèle elle donc plus adaptée pour nous aider à choisir le modèle.

# graphe BIC
plot(best_FW_NL, scale="bic", main=" BIC pour Regsubset FW Pays Bas") 



```


SELECTION DE VARIABLES AVEC REGSUBSET FW plot R²
```{r}
# graphe R² ajusté
plot(best_FW_NL, scale="adjr2", main=" R² Ajuste pour Regsubset FW Pays Bas")

 
```


SELECTION DE VARIABLES AVEC REGSUBSET FW plot Cp
```{r}


# graphe Cp
plot(best_FW_NL, scale="Cp", main=" Cp pour Regsubset FW Pays Bas")


```


SELECTION DE VARIABLES AVEC REGSUBSET forward comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_FW_NL)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)
# names(which(reg.summary$which[min.rss,]==TRUE))
# names(which(reg.summary$which[max.adjr2,]==TRUE))
# names(which(reg.summary$which[min.cp,]==TRUE))
# names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset FW Pays Bas")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

SELECTION DE VARIABLES AVEC REGSUBSET FW Bic coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_FW_NL,16) 

# variables sélectionnées par regsubset FW BIC: Date + cosinus + sinus + day_length + teff + t1 + t5 + month + day + wday +  quarter + season


```




SELECTION DE VARIABLES AVEC REGSUBSET FW comparaison BIC R² et Cp graphes
```{r}


# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_BW_NL)

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)

# names(which(reg.summary$which[min.rss,]==TRUE))
# names(which(reg.summary$which[max.adjr2,]==TRUE))
# names(which(reg.summary$which[min.cp,]==TRUE))
# names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset BW Pays Bas")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```


SELECTION DE VARIABLES AVEC REGSUBSET BW comparaison BIC R² et Cp résultats
```{r}

# C'est avec le critère BIC qu'on a le plus petit modèle
min.bic 
min.rss 
max.adjr2 
min.cp 


```

SELECTION DE VARIABLES AVEC REGSUBSET BW Bic coef
```{r}
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_NL,16) 

# variables sélectionnées par regsubset BW BIC: Date + cosinus + sinus + day_length + teff + t1 + t5 + month + day + quarter + season


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES LASSO POUR SELECTION DE VARIABLES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES OLS SANS INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


On cherche à prédire la consommation (Y) en fonction des autres variables


OLS SANS INTERACTION avec toutes les variables résultats
```{r}

# OLS sans interaction sur base centrée réduite
# modèle linéaire simple sur Y, avec toutes les variables
# R² ajust 0.8642 F Stat 1002 Residual standard error: 0.3685

RL_NL_tot<-lm(Y~.,data=don.train)
RL_NL_tot_sum<-summary(RL_NL_tot)
RL_NL_tot_sum


```

OLS SANS INTERACTION avec toutes les variables résidus
```{r}
# le graphe des résidus présente une structure incurvée
plot(RL_NL_tot) 

```


OLS SANS INTERACTION en ne gardant que les variables significatives
```{r}

# selection des variables significatives à la main, en en gardant que les pvalue significatives
RL_NL_tot1<-lm(Y~ cosinus + sinus + day_length + teff + T00 + t4 + month + day + lagholidays, data=don.train)
RL_NL_tot1.sum<-summary(RL_NL_tot1)
RL_NL_tot1.sum


```


OLS SANS INTERACTION en ne gardant que les variables significatives: résidus
```{r}
# graphe résidus vs fitted a encore une structure incurvée
plot(RL_NL_tot1) 


```

OLS SANS INTERACTION step
```{r}
# selection des variables significatives avec step
# step picks the best model from the one-term-dropped models and repeats the process until no further improvement in the model can be made by dropping a term. 
# The test parameter is optional, the default criteria is "AIC". It can also take the values "F" and "LRT".
step(RL_NL_tot, test="F")

```


OLS SANS INTERACTION modèle issu de step et plot résidus
```{r}

RL_NL_step<-lm(Y ~ Temp + cosinus + sinus + day_length + teff + T00 + t3 + t4 + t6 + month + year + day + jc + lagholidays + leadholidays, data = don.train)

# graphe des résidus avec une structure encore incurvée
plot(RL_NL_step)

```



OLS SANS INTERACTION synthèse
```{r}
# comparaison avec modèle linéaire issu de step
# R² ajusté step légèrement meilleur que le modèle en ne gardant directement que les  variables significative mais égal à celui du modèle total
# F stat step moins élevé que tot1 mais supérieur au modèle total
# residual std error step moins élevé que RL_NL_tot1 mais égal modèle total. Mais il est globalement faible pour les 3 modèles
stargazer(RL_NL_tot,RL_NL_tot1,RL_NL_step,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("tot", "tot1","step"))


```


ANOVA
```{r}

# anova: the returned information for the F-test is the difference in the sum of squares between the models, the F-statistic for this difference, and the p-value for the F-statistic.
anova(RL_NL_tot,RL_NL_tot1) # la différence semble significative entre tot et tot1
anova(RL_NL_tot1,RL_NL_step) # la différence semble significative entre step et tot1


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES OLS AVEC INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

"Date"         "Y"            "Temp"         "cosinus"      "sinus"        "day_length"   "teff"         "seuil"       
 [9] "T00"          "t1"           "t2"           "t3"           "t4"           "t5"           "t6"           "t7"          
[17] "month"        "year"         "day"          "weekend"      "wday"         "quarter"      "season"      
[25] "holidays"     "jc"           "lagholidays"  "leadholidays"

OLS AVEC INTERACTION SIMPLE résultats
```{r}
# OLS AVEC INTERACTION entre la température et les autres variables

RLI_NL_temp<-lm(Y~(Date + cosinus + sinus + day_length + teff + seuil + T00 + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)*Temp ,data=don.train) 
RLI_NL_temp_sum<-summary(RLI_NL_temp)
RLI_NL_temp_sum

# les variables significatives sont teff + month + day + lagholidays + (sinus + month) *Temp

```


OLS AVEC INTERACTION SIMPLE residus
```{r}
# le graphe des résidus s'améliore et n'est plus incurvée
plot(RLI_NL_temp)

```

OLS AVEC INTERACTION SIMPLE avec TEMP, en ne gardant que les variables signficatives
```{r}
# modèle OLS avec interaction avec seulement les variables significatives
RLI_NL_temp1<-lm(Y~ teff + month + day + lagholidays + (sinus + month) *Temp, data=don.train) 
RLI_NL_temp1_sum<-summary(RLI_NL_temp1)
RLI_NL_temp1_sum

```


OLS AVEC INTERACTION SIMPLE vec TEMP, en ne gardant que les variables signficatives résidus
```{r}
# le graphe des résidus n'est plus incurvé
plot(RLI_NL_temp1)


```


OLS AVEC INTERACTION multiples en séparant les variables liées à la température des autres variables
```{r}

RLI_NL_temp_multi<-lm(Y~(Date + cosinus + sinus + day_length + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)* (Temp + + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7),data=don.train) 
RLI_NL_temp_multi_sum<-summary(RLI_NL_temp_multi)
RLI_NL_temp_multi_sum


```


OLS AVEC INTERACTION multiples en séparant les variables liées à la température des autres variables
```{r}
# en ne gardant que les variables significatives: Date + month + year + day + holidays + leadholidays + teff + T00 + t1 + t2 + t6 + Date*(teff + T00 + t1 + t2 + t6) + cosinus*(T00 + t3 + t5) + sinus*(T00) + day_length *(T00 + t3 + t5) + month*(Temp + teff + T00 + t1 + t2 + t5)
RLI_NL_temp_multi1<-lm(Y ~ Date + month + year + day + holidays + leadholidays + teff + T00 + t1 + t2 + t6 + Date*(teff + T00 + t1 + t2 + t6) + cosinus*(T00 + t3 + t5) + sinus*(T00) + day_length *(T00 + t3 + t5) + month*(Temp + teff + T00 + t1 + t2 + t5), data=don.train) 

RLI_NL_temp_multi1_sum<-summary(RLI_NL_temp_multi1)

RLI_NL_temp_multi1_sum

```


OLS AVEC INTERACTION multiples en séparant les variables liées à la température des autres variables
```{r}

# en ne gardant que les variables significatives: Date + month + year + day + holidays + leadholidays + cosinus*(T00 + t5) + sinus*(T00) + day_length *(T00 + t5) + month*(t1 + t2 + t5)
RLI_NL_temp_multi2 <-lm(Y ~ Date + month + year + day + holidays + leadholidays + cosinus*(T00 + t5) + sinus*(T00) + day_length *(T00 + t5) + month*(t1 + t2 + t5), data=don.train) 

RLI_NL_temp_multi2_sum<-summary(RLI_NL_temp_multi2)

RLI_NL_temp_multi2_sum

```


```{r}
# en ne gardant que les variables significatives: 
RLI_NL_temp_multi3 <-lm(Y ~ month + day + holidays + cosinus*(t5) + sinus*(T00) + day_length *(t5) + month*(t1 + t2), data=don.train) 

RLI_NL_temp_multi3_sum<-summary(RLI_NL_temp_multi3)

RLI_NL_temp_multi3_sum
```


```{r}
# en ne gardant que les variables significatives: 
RLI_NL_temp_multi <-lm(Y ~ month + day + holidays + cosinus*(t5) + month*(t1 + t2), data=don.train) 

RLI_NL_temp_multi_sum<-summary(RLI_NL_temp_multi)

RLI_NL_temp_multi_sum
```


OLS comparaison régression linéaire sans et avec interaction
```{r}
# comparaison modèles linéaire sans et avec interaction: les stats sont meilleures pour le modèle avec interaction
# R² ajusté plus élevé pour RLI avec interaction que pour les RL sans interaction
# residual std error équivalent
# F-stat plus élevé pour pour RLI
stargazer(RL_NL_tot, RL_NL_tot1, RL_NL_step, RLI_NL_temp1, RLI_NL_temp_multi, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("tot","tot2","step","RLI", "RLI2"))

# ainsi, pour la base avec Pays Bas, la RL avec interaction améliore légèrement les stats

```


OLS AVEC INTERACTION entre Temp (poly degré 2) et les autres variables
```{r}

RLI_NL_P2_tot<-lm(Y~ (Date + cosinus + sinus + day_length + teff + seuil + T00 + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays)*I(poly(Temp, 2)), data=don.train)
RLI_NL_P2_tot_sum<-summary(RLI_NL_P2_tot)
RLI_NL_P2_tot_sum



```

OLS AVEC INTERACTION entre Temp (poly degré 2) et les autres variables step (très long)
```{r}
# selection des variables significatives avec step
# step picks the best model from the one-term-dropped models and repeats the process until no further improvement in the model can be made by dropping a term. 
# The test parameter is optional, the default criteria is "AIC". It can also take the values "F" and "LRT".

step(RLI_NL_P2_tot, test="F")

```


OLS AVEC INTERACTION entre Temp (poly degré 2) et les autres variables step modèle retenu
```{r}
# les variables significatives sont cosinus + day_length + teff + seuil + Pays + month + year + lagholidays + leadholidays + (seuil + T00 +  Pays + month)*I(poly(Temp,2))

RLI_NL_P2_step<-lm(Y ~ Date + cosinus + sinus + day_length + teff + month + year + day + jc + lagholidays + leadholidays + I(poly(Temp, 2)) + cosinus:I(poly(Temp, 2)) + sinus:I(poly(Temp, 2)) + day_length:I(poly(Temp, 2)) + teff:I(poly(Temp, 2)) + month:I(poly(Temp, 2)) + jc:I(poly(Temp, 2)), data = don.train) 
RLI_NL_P2_step_sum<-summary(RLI_NL_P2_step)
RLI_NL_P2_step_sum

```


comparaison modèles linéaire avec interaction simple sur toutes les variables, avec seulement les variables significatives
```{r}
# faible hausse du R² ajusté de 0.966 à 0.98
# faible  baisse du Residual std error de 0.045 à 0.035
# hausse de F stat entre RLI_NL_temp1 et RLI P2, mais inférieur au F-Stat de RLI
stargazer(RLI_NL_temp1,RLI_NL_temp_multi, RLI_NL_P2_step ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RLI","RLI multi", "RLI P2"))


```

Graphes modèles RL et RLI
```{r}
pred_RL_NL_tot1=predict(RL_NL_tot1, newdata=don.test, se=T)
pred_RLI_NL_temp1=predict(RLI_NL_temp1, newdata=don.test, se=T)
pred_RLI_NL_P2_step=predict(RLI_NL_P2_step, newdata=don.test, se=T)
pred_RLI_NL_temp_multi=predict(RLI_NL_temp_multi, newdata=don.test, se=T)

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RL et RLI Pays Bas" )
lines(don.test$Date,pred_RL_NL_tot1$fit, col="blue")
lines(don.test$Date,pred_RLI_NL_temp1$fit, col="red")
lines(don.test$Date,pred_RLI_NL_P2_step$fit, col="green")

plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RL sur Pays Bas" )  # les valeurs extrèmes ne sont pas bien prédites
lines(don.test$Date,pred_RL_NL_tot1$fit, col="blue")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI simple sur Pays Bas" )
lines(don.test$Date,pred_RLI_NL_temp1$fit, col="red")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RLI poly2 sur Pays Bas" )  # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_NL_P2_step$fit, col="green")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI multiple sur Pays Bas" )   
lines(don.test$Date,pred_RLI_NL_temp_multi$fit, col="yellow")

```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES POLYNOMIAL
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

POLYNOME base et variables sur la base centrée réduite

Modèles avec cible=Conso en fonction d'un polynome sur Temp

POLYNOME détermination du degré par cross validation hold out train / test
```{r}

# # CROSS VALIDATION HOLD OUT TRAIN/TEST
# set.seed(1)
# dim<-nrow(donYX)
# train<-sample(dim,2*dim/3)
# donYX.train=donYX[train,]
# donYX.test=donYX[-train,]
# Y.test=Y[-train]

d=20 # degré max de polynome à tester
MSE_poly_NL=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(X,i, raw=T), data=donYX.train)
  MSE_poly_NL[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_poly_NL),ylab="MSE", main='Root MSE Pays Bas selon le degré de polynome',pch=19,type='b')


```

POLYNOME détermination du degré par cross validation hold out resultats
```{r}
which.min(MSE_poly_NL) 

```


POLYNOME détermination du degré par cross validation hold out modèle retenu et résidus
```{r}

#modèle retenu par hold out
poly_NL_HO<- lm(formula=Y~poly(X,5, raw=T), data=donYX.train)
poly_NL_HO_sum<- summary(poly_NL_HO)
MSE_poly_NL_HO= mean((Y.test-predict(poly_NL_HO,donYX.test))^2)

# le graphe des résidus vs fitted n'a plus de structure incurvée
plot(poly_NL_HO)

```


POLYNOME détermination du degré par cross validation K-fold
```{r}


# CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
POLY_cv.error_NL=as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(X,i),data = donYX.train)
POLY_cv.error_NL[i]<-cv.glm(donYX.test,glm.fit,K=10)$delta[1]
}

plot(POLY_cv.error_NL, pch=19,type='b')

```

POLYNOME détermination du degré par cross validation K-fold résulats
```{r}
which.min(POLY_cv.error_NL) 

```



POLYNOME détermination du degré par cross validation K-fold modèle retenu et résidus
```{r}

#modèle retenu par K_fold
poly_NL_KF<- lm(formula=Y~poly(X,1, raw=T), data=donYX.train)
MSE_poly_NL_KF= mean((Y.test-predict(poly_NL_KF,donYX.test))^2)

# le graphe des résidus vs fitted a une structure incurvée
plot(poly_NL_KF)

```


POLYNOME détermination du degré par cross validation LOOCV à éviter, trop long
```{r}
# CROSS VALIDATION LOOCV leave one out !!!! TRES LONG
# library(boot)
# d=10 # degré de polynome 
# cv.error=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~poly(X,i),data = donYX) 
#   cv.error[i]=cv.glm(donYX,glm.fit)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }
# plot(cv.error, type="l") 

```


POLYNOME comparaison RL et poly
```{r}

# COMPARAISON DES MODELES
#modèle retenu par hold out
poly_NL_HO<- lm(formula=Y~poly(X,5, raw=T), data=donYX.train)
MSE_poly_NL_HO= mean((Y.test-predict(poly_NL_HO,donYX.test))^2)

#modèle retenu par K_fold
poly_NL_KF<- lm(formula=Y~poly(X,1, raw=T), data=donYX.train)
MSE_poly_NL_KF= mean((Y.test-predict(poly_NL_KF,donYX.test))^2)

#comparaison des modèles linéaire total avec poly
# R² ajusté plus faible pour poly par rapport au modèle linéair
# résidual sdt error plus élevé pour poly que dans RL 
# F stat plus élevé pour les poly que pour modèle linéaire
stargazer(RL_NL_tot1,poly_NL_HO, poly_NL_KF, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","polyHO", "polyKF"))




```

```{r}
# en comparant les MSE, 
diff_POLY_NL=MSE_poly_NL_HO - MSE_poly_NL_KF
diff_POLY_NL # MSE_poly10_NL_tot < MSE_poly6_NL_tot
# 
# nous retiendrons polyHO sur le critère du MSE
POLY_NL<- lm(formula=Y~poly(X,5, raw=T), data=donYX.train)
POLY_NL_sum<- summary(POLY_NL)
MSE_POLY_NL_tot= mean((Y.test-predict(POLY_NL,donYX.test))^2)


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES SPLINES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

SPLINE Conso en fonction de la température

SPLINES sur base centrée réduite et variables

```{r}

# don<-base_NL_F_cr
# don <- rename.variable(don, "Conso", "Y")
# 
# #creation des variables Y et X
# Y=don$Y 
# X=don$Temp
# donYX=data.frame(cbind(Y,X))
# str(donYX)
# nrow(donYX)
# length(X)
# length(Y)
# 
# # Creation de l'echantillon train 2/3 individus et test 1/3
# set.seed(1)
# dim<-nrow(don)
# train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
# test=model.matrix(Y~.,data=don[-train,])# base de test
# Y.train=Y[train]
# X.train=X[train]
# Y.test=Y[-train]
# X.test=X[-train]
# don.train=don[train,]
# don.test=don[-train,]
# donYX.train=donYX[train,]
# donYX.test=donYX[-train,]

```


SPLINES choix du degré de liberté/noeuds par CV hold out pour natural splines
```{r}

# CHOIX DU DEGRE DE LIBERTE df (et donc du nombre de noeuds) par cross validation HOLD OUT TRAIN/TEST 
# l'option df produit des splines avec des noeuds placés sur les quantiles
# on n'obtient pas les mêmes noeuds en bs et ns, pour un même degré de liberté
# attr() pour avoir les noeuds issus de df

# # noeuds avec basic splines
# attr(bs(X,df=3),"knots") # pas de noeud
# attr(bs(X,df=4),"knots") # un seul noeud à 50% = 2 intervalles + 2 frontières min et max
# attr(bs(X,df=5),"knots") # 2 noeuds à 1/3 et 2/3 = 3 intervalles + 2 frontières min et max
# attr(bs(X,df=6),"knots") # 3 noeuds à 25%, 50% et 75% = 4 intervalles + 2 frontières min et max
# 
# # noeuds avec natural splines
# attr(ns(X,df=1),"knots") #  pas de noeud
# attr(ns(X,df=2),"knots") #  un seul noeud à 50%
# attr(ns(X,df=3),"knots") #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
# attr(ns(X,df=4),"knots") #  3 noeuds à 25% (5.8), 50% (10.2),75% (15.5)
# attr(ns(X,df=5),"knots") #  4 noeuds à 20% (4.9), 40% (8.5),60% (12.2), 80% (16.5)


# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
MSE_SP_NL_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(X,df=i), data=donYX.train)
  MSE_SP_NL_ns[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_SP_NL_ns),ylab="MSE", main='Root MSE Pays Bas selon le degré de liberté du spline',pch=19,type='b')


```


SPLINES choix du degré de liberté/noeuds résultats
```{r}

which.min(MSE_SP_NL_ns)

```

SPLINES choix du degré de liberté: nombre de noeuds
```{r}
attr(ns(X,df=3),"knots")

```


SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}


# pour basic spline, recherche degré df qui minimise le MSE 

DF=15 # df max à tester
MSE_SP_NL_bs=rep(0,DF)
for(i in 4:DF) {
  model <- lm(Y~bs(X,df=i), data=donYX.train)
  MSE_SP_NL_bs[i] <- mean((Y.test-predict(model,donYX.test))^2)
  }

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(MSE_SP_NL_bs),ylab="MSE", main='Root MSE selon le degré de liberté du spline',pch=19,type='b')

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines résultat
```{r}
which.min(MSE_SP_NL_bs)+3 # le test démarre à df=4

```

SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}
attr(ns(X,df=4),"knots")
 

```


SPLINES choix entre natural splines et basic splines par CV hold out 
```{r}

# CHOIX ENTRE BASIC SPLINES ET NATURAL SPLINES, celui qui minimise le MSE

#natural splines ns
# ns() ne marche que si les variables sont numériques. Les variables qualitatives seront transformées en dummy variables
attr(ns(X,df=3),"knots")  # 7 noeuds à12.5% 25% 37.5% 50% 62.5% 75% 87.5%
fit_ns_NL_tot=lm(Y~ns(X,df=3), data=donYX.train)
plot(fit_ns_NL_tot)
MSE_SP_NL_ns <- mean((Y.test-predict(fit_ns_NL_tot,donYX.test))^2)

#basic splines bs: on prend le df qui donne les mêmes noeuds que natural spline 
attr(bs(X,df=4),"knots") # 3 noeuds
fit_bs_NL_tot=lm(Y~bs(X,df=5), data=donYX.train)
plot(fit_bs_NL_tot)
MSE_SP_NL_bs <- mean((Y.test-predict(fit_bs_NL_tot,donYX.test))^2)


diff_NL_bs_ns=MSE_SP_NL_bs-MSE_SP_NL_ns
diff_NL_bs_ns # MSE_SP_NL_bs > MSE_bs_NL_ns 
# => avec les mse, on choisirait ns


```


SPLINES choix entre natural splines et basic splines par CV hold out comparaison
```{r}


#comparaison des stats des résultats entre basic et natural splines
stargazer(fit_bs_NL_tot, fit_ns_NL_tot, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("bs", "ns"))
# => avec les stat des modèles, choix de ns car F-stat plus grand qu bs. Le R² ajusté et residual std error sont égaux entre ns et bs

```


SPLINES choix entre natural splines et basic splines par CV hold out résultats et résidus
```{r}

# en minimisant MSE, on retient spline bs avec df=1 trouvé par cross validation hold out
SP_NL=lm(Y~ns(X,df=3), data=donYX.train) #  3 noeuds 
pred_SP_NL=predict(SP_NL, newdata=donYX.test, se=T)
MSE_SP_NL= mean((Y.test-predict(SP_NL,donYX.test))^2)
plot(SP_NL) # graphe des résidus vs fitted n'a plus de structure incurvée


```


SPLINES graphes et smooting splines
```{r}

# graphes de conso vs température
plot(X.test,Y.test, xlab = "Temp", ylab="Conso")
points (X.test,pred_SP_NL$fit, col="blue") 

# graphe de conso vs date
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="Spline Pays Bas, fit (bleu)" )
lines(don.test$Date,pred_SP_NL$fit, col="blue") 


# SMOOTHING SPLINE
SM_NL=smooth.spline(Y.test,X.test,df=3) # on spécifie df=6 et le lambda est déterminé de sorte à obtenir df=6
SM_NL_cv=smooth.spline(Y.test,X.test,cv=TRUE) # lambda est choisi par cross validation

plot(SM_NL, main="smooth spline") 
plot(SM_NL_cv, main="cv") 

# #comparaison des résultats entre Spline df3, smoothing spline df3 et smoothing spline avec lambda par cv
# stargazer(SP_NL, SM_NL, SM_NL_cv, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("SP", "SM", "SMcv"), model.names = TRUE)
```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES GAM
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



GAM base centrée réduite et variables
```{r}

# library(splines) 
# library(questionr)
# 
# don<-base_NL_F_cr
# don <- rename.variable(don, "Conso", "Y")
# 
# #creation des variables Y et X
# Y=don$Y 
# X=don$Temp
# donYX=data.frame(cbind(Y,X))
# str(donYX)
# nrow(donYX)
# length(X)
# length(Y)
# 
# # data set train et test
# set.seed(1)
# d<-nrow(donYX)
# train<-sample(d,2*d/3)
# # test=donYX[-train,]
# 
# # Creation de l'echantillon train 2/3 individus et test 1/3
# set.seed(1)
# dim<-nrow(don)
# train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
# test=model.matrix(Y~.,data=don[-train,])# base de test
# Y.train=Y[train]
# X.train=X[train]
# Y.test=Y[-train]
# X.test=X[-train]
# don.train=don[train,]
# don.test=don[-train,]
# donYX.train=donYX[train,]
# donYX.test=donYX[-train,]


```

GAM détermination du polynome par CV K-fold avec toutes les variables : 

message erreur prediction from a rank-deficient fit may be misleading

```{r}
# library(boot)
# en enlevant les variables liées à la température: + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7

d=15 # degré de poly à tester
GAM_cv.error_NL=rep(0,d)
for (i in 1:d) { 
  glm.fit= glm(Y~ poly(Temp,i) + Date + cosinus + sinus + day_length  + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7, data = don) 
  GAM_cv.error_NL[i]=cv.glm(don, glm.fit, K=10 )$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(GAM_cv.error_NL, main="GAM Pays Bas cv.error selon degré polynome",pch=19,type='b') 


```

GAM détermination du polynome par CV K-fold résultats
```{r}
which.min(GAM_cv.error_NL) 

```

GAM détermination du polynome par CV K-fold modèle retenu 
```{r}

# modèle GAM avec polynôme sur la température 

GAM_NL=glm(Y~ poly(Temp,7) + Date + cosinus + sinus + day_length + month + year + day + weekend + wday + quarter + season + holidays + jc + lagholidays + leadholidays + teff + seuil + T00 + t1 + t2 + t3 + t4 + t5 + t6 + t7, data = don) 

# pred_GAM_NL=predict(GAM_NL, newdata=don.test, se=T)

summary(GAM_NL)


```

GAM détermination du polynome par CV K-fold modèle retenu en ne gardant que les variables significatives par step
```{r}
step(GAM_NL, test="F")
```


GAM détermination du polynome par CV K-fold modèle retenu par step
```{r}

GAM_NL_step= glm(Y~ poly(Temp, 7) + Date + cosinus + sinus + day_length + month + year + day + jc + lagholidays + leadholidays + t2 + t3 + t4 + t6, data = don.train) 
MSE_GAM_NL_step= mean((Y.test-predict(GAM_NL_step,don.test))^2)
summary(GAM_NL_step)

```


GAM résidus
```{r}
# le graphe des résidus n'a quasiment plus de structure
plot(GAM_NL_step) 


```



GAM détermination du polynome par CV K-fold avec compilation des variables sélectionnées par regsubset
```{r}

# # détermination du degré du polynome par cross validation, 
# # il y a trop de variables,le modèle ne tourne pas, il faut réduire
# # en utilisant les variables sélectionnées par regsubset: Date + day_length + Pays + month + year + wday + quarter
# # sans les variales liées à la température: (seuil + t1 + t3 + t4 + t5 + t6 + t7)
# 
# library(boot)
# d=15 # degré de poly à tester
# GAM_cv.error_NL_reg=rep(0,d)
# for (i in 1:d) { 
#   glm.fit=glm(Y~ poly(Temp,i) + Date + day_length + Pays + month + year + wday + quarter + seuil + t1 + t3 + t4 + t5 + t6 + t7, data = don) 
#   GAM_cv.error_NL_reg[i]=cv.glm(don,glm.fit, K=10)$delta[1] # par défaut, K= nombre d'observations donc LOOCV
# }
# 
# plot(GAM_cv.error_NL_reg, main="GAM Pays Bas cv.error selon degré polynome",pch=19,type='b') 

```


GAM détermination du polynome par CV K-fold  avec compilation des variables sélectionnées par regsubset résultats
```{r}
# which.min(GAM_cv.error_NL_reg) 

```

GAM détermination du polynome par CV K-fold avec compilation des variables sélectionnées par regsubset modèle retenu 
```{r}
# 
# # modèle GAM avec polynôme degré 1 sur la température 
# 
# GAM_NL_reg=lm(Y~ poly(Temp,7) + Date + day_length + Pays + month + year + wday + quarter + seuil + t1 + t3 + t4 + t5 + t6 + t7, data = don.train) 
# 
# summary(GAM_NL_reg)


```

GAM détermination du polynome par CV K-fold avec compilation des variables sélectionnées par regsubset modèle retenu 
```{r}
# # en enlevant les variables non significatives
# GAM_NL_reg1=lm(Y~ poly(Temp,7) + day_length + Pays + month + wday + t1 + t3 + t4 + t5 + t6, data = don.train) 
# # pred_GAM_NL_reg=predict(GAM_NL_reg, newdata=don.test, se=T)
# summary(GAM_NL_reg1)
# 
# MSE_GAM_NL_reg1= mean((Y.test-predict(GAM_NL_reg1,don.test))^2)

```


GAM avec compilation des variables sélectionnées par regsubset  résidus
```{r}
# # le graphe des résidus présente toujours une structure en 3 groupes
# plot(GAM_NL_reg1) 


```



GAM comparaison des modèles 
```{r}

# GAM_NL_2= glm(Y~ poly(Temp,7) + cosinus + day_length + Pays + T00 + t1 + t3 + t5 + t6, data = don.train) 
# MSE_GAM_NL_2= mean((Y.test-predict(GAM_NL_2,don.test))^2)
# 
# GAM_NL_reg1=lm(Y~ poly(Temp,7) + day_length + Pays + month + wday + t1 + t3 + t4 + t5 + t6, data = don.train) 
# MSE_GAM_reg1= mean((Y.test-predict(GAM_NL_reg1,don.test))^2)
# 
# diff=MSE_GAM_NL_2-MSE_GAM_NL_reg1
# diff 
# 
# which.min(c(MSE_GAM_NL_2, MSE_GAM_NL_reg1)) 

```

GAM modèle retenu
```{r}
GAM_NL=lm(Y~ poly(Temp, 7) + Date + cosinus + sinus + day_length + month + year + day + jc + lagholidays + leadholidays + t2 + t3 + t4 + t6, data = don.train) 

```


GAM valeurs prédites
```{r}
pred_GAM_NL=predict(GAM_NL, newdata=don.test, se=T)
# graphe des valeurs prédites par GAM sur la Belgique
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="GAM" )
lines(don.test$Date,pred_GAM_NL$fit, col="yellow")


```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES RANDOM FOREST
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


RANDOM FOREST base et variables
```{r}

# on peut régler deux éléments : 
# ntree: le nombre d’arbres construits par l’algorithme 
# mtry: le nombre de variables testées à chaque division. 
# la valeur par défaut de mtry correspond à la racine carrée du nombre de variables

# library(caTools)
# library(randomForest)
# library(ggplot2)
# library(questionr)

don<-base_NL_F_cr
head(don)
dim(don)
sqrt(ncol(don)) # = valeur mtry par défaut soit 5
# 
# # création de variable Y
# don <- rename.variable(don, "Conso", "Y")
# head(don)
# 
# 
# # train & test datasets
# #éviter les valeurs manquantes
# set.seed(1)
# dim<-nrow(don)
# index<-sample(dim,2*dim/3)
# don.train=don[index,]
# don.test=don[-index,]
# Y.test=Y[-index]

```

RANDOM FOREST modelisation
```{r}

# modelisation sur train, par défaut ntree=500
RF_NL<-randomForest(Y~., data=don.train, ntree = 500, mtry = 5)
# summary(RF_NL_tot_train)
print(RF_NL)
# names(RF_NL_tot) 
# "call"            "type"            "predicted"       "mse"             "rsq"            
# "oob.times"       "importance"      "importanceSD"    "localImportance" "proximity"      
# "ntree"           "mtry"            "forest"          "coefs"           "y"              
# "test"            "inbag"           "terms" 
```

RANDOM FOREST MSE plot
```{r}

# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 100 environ
plot(RF_NL$mse, xlab = "nombre d'arbres", ylab = "MSE")

```

RANDOM FOREST choix de mtry par CV hold out
```{r}

# CHOIX DE MTRY PAR CV HOLD OUT

# train & test datasets
set.seed(1)
dim<-nrow(don)
index<-sample(dim,2*dim/3)
don.train=don[index,]
don.test=don[-index,]
Y.test=Y[-index]

# boucle de test.très long
m=15 # mtry max à tester. 
MSE_RF_NL=rep(0,m)
for(i in 1:m) {
  model <- randomForest(Y~., data=don.train, mtry = i)
  MSE_RF_NL[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# graphe de MSE
plot(MSE_RF_NL, xlab="mtry", ylab="MSE", main="MSE selon mtry", type="b")

```

RANDOM FOREST choix de mtry par CV résultats
```{r}

which.min(MSE_RF_NL) 


```


RANDOM FOREST choix de ntree par CV: résultats pas stables
```{r}


# # CHOIX DE NTREE PAR CV HOLD OUT
# set.seed(1)
# dim<-nrow(don)
# index<-sample(dim,2*dim/3)
# train=don[index,]
# test=don[-index,]
# 
# 
# # résultats très instables
# # tests sur c(50,100,150,200,250,300,350,400,450,500) min MSE pour 100 250 450 300 250 400 300 350 200 250
# # tests sur c(100,200,300,400,500,600,700,800,900,1000) 
# # min MSE pas stable à ntree=200 700 300 100 900 200 200 800 300 700 300 200 500 900  700  600  600 1000
# # tests sur c(500,1000,1500,2000,2500,3000), min MSE pour 1000 2500 2000 1500  500 3000
# # test sur c(1000,2500,5000), min MSE pour 2500
# # test sur c(1000,2000,2500,3000,4000,5000) min MSE pour 2500 2000 1000 2500 1000 1000
# # test sur c(1000,2000,2500,3000,4000,5000,7000) min MSE pour 2000, 2000, 1000, 2000, 7000
# # test sur c(1000,2000,3000,4000,5000,6000) min MSE pour 4000 3000 3000 2000 2000
# # test sur c(100,200,300,700,1000,2000,3000,4000) min MSE 3000 2000 4000  200 3000 4000 700 100 4000 100
# # test sur c(50,100,150,200,250,300,350,400,450,500,600,700,800,900,1000,2000,2500,3000,300,4000,5000,7000)
# # min MSE 800 200 50 250 200 2000 50 100 300 250 450 350 200 500 1000 100 250 900 2500 800 300 350 450 100 1000
# # 350 900 300 250 100 900 350 350 100 300 600 350 350 900 150 150 350 700  50 200
# # 300  450  400  300  200  100  100  450  300  300 2000  350  250  350  600  450  350 50 2500 300
# # test sur c(50,100,150,200,250,300,350,400,450,500)  min MSE pour 350 150 400 100 200 350 400 150 200 400 450 150 450 400 100 400 300 200 450 150 300 100 300 300 300 100 200 100 350 100
# 
# # seq(100,500,by=20) 400 500 380 160 440 220 260 440 480 400 260 260 260  NA 260 260  NA 480 260 260  NA  NA  NA 260  NA 260  NA  NA 260  NA
# 
# Ntree=seq(100,500,by=20)  # ntree à tester
# d=length(Ntree)
# nb=30 # nombre de tests de cross validation
# MSE_RF_NL.tree=rep(NA,d*nb)
# res_ntree=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE
# 
# for (j in 1:nb) {
#   
#   for(i in 1:d) {
#     model <- randomForest(Y~., data=train, mtry = 7, ntree=Ntree[i])
#     MSE_RF_NL.tree[i+j-1] <- mean((test$Y-predict(model,test))^2)
#   }  
#   
#   res_ntree[j]=Ntree[which.min(MSE_RF_NL.tree)]
#  
# }
# 
# res_ntree
# # plot(MSE_RF_NL.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")
# 
# # graphe des MSE du choix de ntree
# Ntree[which.min(MSE_RF_NL.tree)]
# plot(MSE_RF_NL.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")




```

RANDOM FOREST prediction
```{r}
RF_NL_tot<-randomForest(Y~., mtry = 10, data=don.train)

# prediction
RF_NL_tot_pred<-predict(RF_NL_tot,don.test)
RF_NL_tot_pred_sum<-summary(RF_NL_tot_pred)
# RF_NL_tot_pred_sum

MSE_RF_NL_tot= mean((Y.test-predict(RF_NL_tot,don.test))^2)

# plot des valeurs prédites vs valeurs réelles
ggplot() +
  geom_point(aes(x = don.test$Date, y = Y.test),
             colour = 'red') +
  geom_line(aes(x = don.test$Date, y = RF_NL_tot_pred),
            colour = 'blue') +
  ggtitle('Random Forest Regression, en bleu prédiction') +
  xlab('date') +
  ylab('conso')

```

vérifier la performance du modele random forest
```{r}

# faire cross validation

# a faire compare the Out of Bag Sample Errors and Error on Test set
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error","Test Error"),pch=19, col=c("red","blue"))

# DYGRAPH
install.packages("dygraphs")
library(dygraphs)



```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
MODELES SVR
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



SVR base et variables

```{r}

# # install.packages("e1071")
# # Load Library
# library(caTools)
# library(e1071)
# library(questionr)
# 
# don<-base_tot_F_cr
# head(don)
# dim(don)
# 
# 
# don <- rename.variable(don, "Conso", "Y")
# head(don)

```


SVR modelisation train/test
```{r}

# train and test
# éviter les valeurs manquantes
set.seed(1)
split=sample.split(don$Y, SplitRatio=2/3)
don.train=subset(don,split==TRUE)
don.test=subset(don,split==FALSE)
Y.test=subset(don,split==FALSE)

#Regression with SVM
SVR_NL_tot = svm(Y~.,don.train)
MSE_SVR_NL_tot= mean((Y.test-predict(SVR_NL_tot,don.test))^2)

#Predict using SVM regression
pred_svr = predict(SVR_NL_tot, don.test)

#Overlay SVM Predictions on Scatter Plot
plot(don.test$Date, Y.test)
lines(don.test$Date, pred_svr, col="purple")



```


SVR names
```{r}
names(SVR_NL_tot)


```


SVR residuals
```{r}

plot(SVR_NL_tot$residuals)


```






