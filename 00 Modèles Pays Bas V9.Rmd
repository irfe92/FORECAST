---
title: "Modeles NL Pays Bas"
author: "Nhu-Nguyen Ngo"
date: "27 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# PACKAGES BASE ET VARIABLES

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## load PACKAGES
```{r}

# DONNEES VISUALISATION
library(stargazer)
library(ggplot2)
library(questionr)
library(dplyr)
library(lubridate)      # pour les dates
library(dummies)        # création de variables dummies (pour bestglm)
library(forecast)       # plot sympa des résidus
library(corrplot)       # plot de la matrice de corrélation
library(PerformanceAnalytics)
library(stringr)
library(lattice)
library(ROCR)
library(pROC)

# TREE
library(rpart)				  # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)			# Enhanced tree plots
library(RColorBrewer)		# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree


# selection de variable
library(bestglm)
library(leaps)          # regsubset


# cross validation
library(stats)          # fonction glm, kmeans
library(caret)          # CV, matrice de confusion
library(boot)           # fonction cv.glm pour cross validation

# CLUSTERING, classification
library(cluster)
library(fastcluster)
library(FactoMineR) # ACP
library(MASS) # LDA
library(ade4)
library(klaR) # LDA, stepclass: stepwise variable selection for classification, direction="both", "forward", "backward". Method = "lda"

# MODELES
library(ISLR)
library(glmnet)         # Poly, GAM
library(boot)           # boostraping
library(splines)
library(caTools)
library(randomForest)
library(e1071)          # SVR
library(nnet)           # reseau neurones
library(neuralnet)
library(mlbench)
library(gbm)
library(xgboost) # boosting regression lineraire, logistique
library(C50)


# paralellisation
library(doParallel)
library(foreach)    # baggigng, parallisation

```



# fonctions performance
```{r}
# Y variable cible
# model = fit du model
# don.test : base de test

fun_mse <- function (Y.test, model, don.test) {
  mse <- mean((Y.test-predict(model,don.test))^2)
  return(mse)
}



fun_mape = function (Y,model, don.test) {
  error <- Y-predict(model,don.test)
  mape <- mean(abs(error/Y))*100
  return(mape)
}
# mape pas adapté quand Y proche de zéro, ce qui peut être souvent le cas avec des données centrées réduites


fun_mase = function (model) {
  acc <- accuracy(model)
  MASE <- acc [[6]]
  return(MASE)
}
# accuracy ne fonctionne pas pour RF, SVR, NN, XGB

```


# ARBRE DE DECISION
```{r}
# sur base  non centrée réduite avec toutes les variables
don<-base_NL_F
# definition variables Y
don <- rename.variable(don, "Conso", "Y")
Y=don$Y
str(don)

# arbre
tree_NL_total<-rpart(Y~.,data=don)
tree_NL_total
# prp(tree_NL_total)               # A fast plot													
fancyRpartPlot(tree_NL_total, main="arbre de décision Pays Bas")		# A fancy plot from rattle

# les variables discriminantes sont :
# t1>11
# les mois d'été mai, juin, juillet, aout, septembre vs mois d'hiver octobre, novembre, décembre, janvier, février, mars, avril
# teff >3.8
# t3>6.6 
# Temp>0.7

```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# SELECTION DE VARIABLES REGSUBSETS
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## BASE pour selection de variable
```{r}

# base totale centrée réduite, sans les variables météo
don<-base_NL_F_cr

# creation des variables Y et X
don<- rename.variable(don, "Conso", "Y")
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))


# Creation de l'echantillon train individus et test 
set.seed(1)
dim<-nrow(don)
split=0.8

train=sample(dim,split*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage

test=model.matrix(Y~.,data=don[-train,])# base de test

Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]

don.train=don[train,]
don.test=don[-train,]

donYX.train=donYX[train,]
donYX.test=donYX[-train,]


p=ncol(don) # nombre de variables explicatives
p

names(don)

```



## SELECTION EXHAUSTIVE: A EVITER car P GRAND !! (ici 27 variables trop grand)

## SELECTION AVEC REGSUBSET forward
```{r}

# FORWARD SELECTION: NB pas assuré d'avoir le modèle optimal, mais possible si n<p

best_FW_NL=regsubsets(Y~.,data=don.train,nvmax=p,method='forward')
FW_NL_sum<-summary(best_FW_NL)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_FW_NL=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_FW_NL,id=i)
  pred=test[,names(coefi)]%*%coefi   # matrix modele et pas don.test
  MSE_FW_NL[i]=mean((Y.test-pred)^2)
}

# on plot les MSE des p modeles 
plot(sqrt(MSE_FW_NL),ylab='MSE des p modeles FW', main="Regsubset forward sur base Pays Bas",pch=19,type='b')

# On choisit le modele qui a la MSE la plus petite sur le test set
FW_NL_nvar=which.min(MSE_FW_NL)
FW_NL_nvar
 
# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables )
coef(best_FW_NL,FW_NL_nvar)

# variables sélectionnées par regsubset forward MSE: 
FW_NL_formule_best <- Y ~Temp + cosinus + sinus + day_length + t2 + t4 + t6 + t7 + Date + month + year + day + jc + lagholidays +  quarter + season

```


## SELECTION FW comparaison BIC R² et Cp graphes
```{r}

# Afin de nous aider à choisir le modèle à sélectionner, identifier l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-summary(best_FW_NL)

FW_min.rss <- which.min(reg.summary$rss)
FW_max.adjr2 <- which.max(reg.summary$adjr2)
FW_min.cp <- which.min(reg.summary$cp)
FW_min.bic <- which.min(reg.summary$bic)



# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset FW Pays Bas")
points(FW_min.rss,reg.summary$rss[FW_min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(FW_max.adjr2,reg.summary$adjr2[FW_max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(FW_min.cp,reg.summary$cp[FW_min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(FW_min.bic,reg.summary$bic[FW_min.bic],col ="red",cex =2, pch =20)

# C'est avec le critère BIC qu'on a le plus petit modèle
FW_min.bic 
FW_min.rss 
FW_max.adjr2 
FW_min.cp 

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_FW_NL,FW_min.bic) 

# variables sélectionnées par regsubset FW BIC: 
FW_NL_formule_BIC = Y ~ Temp + cosinus + sinus + day_length + t4 + t6 + Date + month + day + lagholidays + quarter + season

```



## SELECTION AVEC REGSUBSET backward
```{r}
# selection variables BACKWARD: NB pas assuré d'avoir le modèle optimal,pas possible si n<p

best_BW_NL=regsubsets(Y~.,data=don.train,nvmax=p,method='backward')
sum_BW_NL<-summary(best_BW_NL)

# pour chacun des modeles sur le test set, calculer la MSE
MSE_BW_NL=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_BW_NL,id=i)
  pred=test[,names(coefi)]%*%coefi  # matrix modele et pas don.test
  MSE_BW_NL[i]=mean((Y.test-pred)^2)
}

# on plot les MSE des p modeles 
plot(sqrt(MSE_BW_NL),ylab='MSE des p modeles',main="Regsubset backward sur base Pays Bas",pch=19,type='b') 

# On choisit le modele qui a la MSE la plus petite sur le test set
BW_NL_nvar = which.min(MSE_BW_NL) 
BW_NL_nvar

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_NL,BW_NL_nvar) 

# variables sélectionnées par regsubset backward MSE: 
BW_NL_formule_best <- Y ~ Temp + cosinus + sinus + day_length + t2 + t4 + t6 + Date + month + year + day + quarter + season 

```



## SELECTION FW comparaison BIC R² et Cp graphes
```{r}

reg.summary<-summary(best_BW_NL)

BW_min.rss <- which.min(reg.summary$rss)
BW_max.adjr2 <- which.max(reg.summary$adjr2)
BW_min.cp <- which.min(reg.summary$cp)
BW_min.bic <- which.min(reg.summary$bic)

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.
par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l", main="regsubset BW Pays Bas")
points(BW_min.rss,reg.summary$rss[BW_min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(BW_max.adjr2,reg.summary$adjr2[BW_max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(BW_min.cp,reg.summary$cp[BW_min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(BW_min.bic,reg.summary$bic[BW_min.bic],col ="red",cex =2, pch =20)

# C'est avec le critère BIC qu'on a le plus petit modèle
BW_min.bic 
BW_min.rss 
BW_max.adjr2 
BW_min.cp 

# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables)
coef(best_BW_NL,BW_min.bic) 

# variables sélectionnées par regsubset BW BIC: 
FW_NL_formule_BIC = Y ~ Temp + cosinus + sinus + day_length + t4 + t6 + month + day + quarter + season


```



## SELECTION DE VARIABLES AVEC REGSUBSET graphe MSE FW et BW
```{r}
# plot des MSE pour les modèles FW et BW

x=c(1:p)
y1=MSE_FW_NL
y2=MSE_BW_NL
plot(x, y1, type = "l", ylim = range(c(y1, y2)), xlab = "nb de variables", ylab = "MSE", main="MSE Pays Bas FW (blue) et BW (red)")
lines(x, y1, col = "blue")
lines(x, y2, col = "red")


```



# ETUDE DES CORRELATIONS
```{r}
don <- base_NL_F_cr

ind.quant <- sapply(don, function(x) is.numeric(x) | is.integer(x))
# variables quantitative
don.quant <- don[, ind.quant]
str(don.quant) # 14 variables dont 7 retardées


# en enlevant la variable cible Conso et les variables de températures retardées, qui sont forcément corrélées  :
don.quant <- don.quant[, 2:6]
cor_NL <- cor(don.quant)
# cor_NL

library(PerformanceAnalytics)
chart.Correlation(don[,1:6], histogram=TRUE, pch=19)

# il existe une relation linéaire entre Y et Temp donc une régression linéaire a du sens
# Il y a de fortes corrélations entre les variables Temp, cosinus et day_length
# donc dans les régressions linéaires, nous conserverons seulement Temp comme variable numérique

```

```{r}
library(corrplot)
corrplot(cor(don.quant), type="upper", order="hclust", tl.col="black", tl.srt=45)

```



# BASE DONNEES MODELES 
SANS les variables liées à Temp: TEFF T00 SEUIL
```{r}


# sur la base centrée réduite, sans les autres variables méteo
don <- base_NL_F_cr
dim(don)
head(don)

# suppression des variales liees a la temperature teff, seuil, T00
var_delete <- c(which(colnames(don)== "teff"),which(colnames(don)== "seuil"),which(colnames(don)== "T00"))
don<-don[,-var_delete] 
head(don)



# creation des variables Y (variable cible) et X
don<- rename.variable(don, "Conso", "Y")
head(don)

# Creation de l'echantillon train et test
set.seed(1)
dim<-nrow(don)
split=0.8
train=sample(dim,split*dim,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage

don.train=don[train,]
don.test=don[-train,]

# variables pour modèles polynomial et splines
Y=don$Y 
X=don$Temp
donYX=data.frame(cbind(Y,X))
Y.train=Y[train]
X.train=X[train]
Y.test=Y[-train]
X.test=X[-train]
donYX.train=donYX[train,]
donYX.test=donYX[-train,]

# matrice avec uniquement les variables prédictives
donX=don[, which(colnames(don)!="Y")]
donX.train=donX[train,]
donX.test=donX[-train,]

# model matrice sur base de test
test=model.matrix(Y~.,data=don[-train,])




```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES OLS SANS INTERACTION
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## RL SANS INTERACTION
1- nous avons estimé un modèle linéaire simple sur Y, avec Temp et toutes les variables -> message prediction from a rank-deficient fit may be misleading
2- estimations des modèles avec les variables sélectionnées par regsubset: forward, FW_bic, BW, BW_bic ->  message prediction from a rank-deficient fit may be misleading
3- cela nous a amené à devoir supprimer les variables numériques fortement corrélées avec Temp (cosinus, day_length, teff) ainsi que les variables factor corrélées à month, year, day (Date, holidays, jc, weekend, quarter, season, lagholidays, leadholidays) pour ne garder que month, year, date. Sinus a aussi été enlevé car redondant avec day.

## modèles avec variables Regsubset
non fiables car de rang faibles
```{r}
# avec les variables sélectionnées par regsubset forward MSE: 
FW_NL_formule_best <- Y ~ Temp + cosinus + sinus + day_length + t2 + t4 + t6 + t7 + Date + month + year + day + jc + lagholidays +  quarter + season
RL_NL_FW <- lm(FW_NL_formule_best, data = don.train)
MSE_RL_NL_FW= mean((Y.test-predict(RL_NL_FW,don.test))^2) 

# avec les variables sélectionnées par regsubset FW BIC: 
FW_NL_formule_BIC = Y ~ Temp + cosinus + sinus + day_length + t4 + t6 + Date + month + day + lagholidays + quarter + season
RL_NL_FW_bic <- lm(FW_NL_formule_BIC, data = don.train)
MSE_RL_NL_FW_bic= mean((Y.test-predict(RL_NL_FW_bic,don.test))^2) 

# avec les variables sélectionnées par regsubset backward MSE: 
BW_NL_formule_best <- Y ~ Temp + cosinus + sinus + day_length + t2 + t4 + t6 + Date + month + year + day + quarter + season 
RL_NL_BW <- lm(BW_NL_formule_best, data = don.train)
MSE_RL_NL_BW= mean((Y.test-predict(RL_NL_BW,don.test))^2) 

# avec les variables sélectionnées par regsubset BW BIC: 
FW_NL_formule_BIC <- Y ~ Temp + cosinus + sinus + day_length + t4 + t6 + month + day + quarter + season
RL_NL_BW_bic <- lm(FW_NL_formule_BIC, data = don.train)
MSE_RL_NL_BW_bic= mean((Y.test-predict(RL_NL_BW_bic,don.test))^2) 

```


# modèle à partir des toutes les variables
```{r}
# à partir de toutes les variables
RL_NL_init <- lm(Y ~ .,data=don.train)
RL_NL_init_sum <-summary(lm(Y ~. , data = don.train))

# extraction des coefficients significatifs
coef<-RL_NL_init_sum$coefficients[,4]
RL_NL_init_var <- names(which(coef<0.05))
dim_coef <- length (RL_NL_init_var)
formule <- "Y ~ Temp"
for ( i in 2: dim_coef) { formule <- paste ( formule,"+",RL_NL_init_var[i] ) } # le premier terme est Temp
formule

# en ne gardant que les variables significatives
RL_NL_init_sign <- lm(Y ~ Temp + cosinus + sinus + day_length + t4 + t6 + month+ day +lagholidays + leadholidays, data=don.train)
summary(RL_NL_init_sign)

# analyse variances
anova(RL_NL_init_sign)
# le modelee est significatif pour Temp, cosinus, day_length, t6, month, day, lagholidays, leadholidays

# résidus
plot(RL_NL_init_sign) # plot residus vs fitted avec une structure incurvee
checkresiduals(RL_NL_init_sign) # distribution presque gaussienne, quelques autocorrelations

# prédictions
pred_RL_NL_init_sign=predict(RL_NL_init_sign, newdata=don.test, se=T)
MSE_RL_NL_init= mean((Y.test-predict(RL_NL_init_sign,don.test))^2)

```


# modèle avec nombre réduit de variables: Temp, month, year et day
```{r}
RL_NL_tot<-lm(Y ~ Temp + month + year + day, data=don.train)
RL_NL_tot_sum<-summary(RL_NL_tot)

# extraction des coefficients significatifs
coef<-RL_NL_tot_sum$coefficients[,4]
RL_NL_tot_var <- names(which(coef<0.05))
dim_coef <- length (RL_NL_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RL_NL_tot_var[i] , "+ ") }
formule

```


modele reduit en ne gardant que les variables significatives jusqu'à stabilisation de formule
```{r}

# selection des variables significatives 
RL_NL_fin<-lm(Y~  Temp + month + year + day, data=don.train) # identique à tot
RL_NL_fin_sum<-summary(RL_NL_fin)
# RL_NL_fin_sum

# extraction des coefficients significatifs
coef<-RL_NL_fin_sum$coefficients[,4]
RL_NL_fin_var <- names(which(coef<0.05))
dim_coef <- length (RL_NL_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RL_NL_fin_var[i] , "+ ") }
formule

```



modele reduit selection des variables par step
```{r}
RL_NL_step=step(RL_NL_tot, test="F", trace=FALSE)
RL_NL_step

```



modele reduit modèle issu de step
```{r}
RL_NL_step <- lm(Y ~ Temp + month + year + day, data = don.train) # identique à tot et fin

```


modèle reduit retenu
```{r}
# les 3 modèles sont identiques
RL_NL <- RL_NL_tot
anova(RL_NL) # toutes les variables sont significatives
MSE_RL_NL= mean((Y.test-predict(RL_NL,don.test))^2)

```


## comparaison des MSE RL 
```{r}

# comparaison MSE
MSE_RL_NL_comp=c(MSE_RL_NL_init, MSE_RL_NL, MSE_RL_NL_FW, MSE_RL_NL_FW_bic,MSE_RL_NL_BW,MSE_RL_NL_BW_bic)
graph<-barplot(MSE_RL_NL_comp, xlab="modèles RL", ylab="MSE", ylim = range(MSE_RL_NL_comp), main="MSE des modèles RL",las=0)
axis(1, labels=c("init","tot","FW","FW_bic", "BW", "BW_bic"), at = graph)
which.min(MSE_RL_NL_comp) # c'est le modèle FW
which.max(MSE_RL_NL_comp) # c'est le modèle tot

# les écarts de MSE sont assez significatifs
diff_min_max_RL_NL = (max(MSE_RL_NL_comp) - min(MSE_RL_NL_comp))/ min(MSE_RL_NL_comp)
diff_min_max_RL_NL #  21% d'écart

# toutefois, les modèles avec les variables sélectionnées par regsubset sont de rang faible et ne peuvent être retenus

# la MSE de init est plus faible que total, l'écart est de 11%
diff = (MSE_RL_NL - MSE_RL_NL_init)/ MSE_RL_NL_init
diff 

```

comparaison des stats entre RL_NL_init et RL_NL_tot
```{r}
stargazer(RL_NL_init_sign, RL_NL, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("init", "tot"), model.names = TRUE, single.row = TRUE)

# R² ajusté légèrement plus grand pour init (0.946) que pour tot (0.942) : mais le gain est très faible (+0.4%)
# residual std error plus faible pour init (0.23) vs 0.238 pour tot: réduction de 4%
# F stat plus faible pour init que pour tot

# conclusion, pour généraliser aux autres pays, dans un souci de simplification, on n'utilisera que les variables Temp + month + year + day

```




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES AVEC INTERACTION avec la variable Temp
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## RLI modèle reduit total
```{r}
# OLS AVEC INTERACTION entre la température et toutes les autres variables 
# -> message prediction from a rank-deficient fit may be misleading
# enlever les variables dates corrélées pour ne garder que month, year, day

RLI_NL_tot<-lm(Y~(month + year + day)*Temp ,data=don.train) 
RLI_NL_tot_sum<-summary(RLI_NL_tot)
# RLI_NL_tot_sum 


# # extraction des coefficients significatifs
coef<-RLI_NL_tot_sum$coefficients[,4]
RLI_NL_tot_var <- names(which(coef<0.05))
dim_coef <- length (RLI_NL_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_NL_tot_var[i] , "+ ") }
formule

```



## RLI en ne gardant que les variables signficatives par itération jusqu'à stabilisation de formule
```{r}

RLI_NL_fin<-lm( Y~ month + year + day + month:Temp + year:Temp + day:Temp, data=don.train) # c'est le modèle tot
RLI_NL_fin_sum<-summary(RLI_NL_fin)
# RLI_NL_fin_sum 

# extraction des coefficients significatifs
coef<-RLI_NL_fin_sum$coefficients[,4] 
RLI_NL_fin_var <- names(which(coef<0.05))
dim_coef <- length (RLI_NL_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_NL_fin_var[i] , "+ ") }
formule

```


## RLI selection des variables par step
```{r}
RLI_NL_step <- step(RLI_NL_tot, test="F",trace=FALSE)
RLI_NL_step


```

RLI modèle issu de step
```{r}
RLI_NL_step <-lm(formula = Y ~  month + year + day + Temp + month:Temp, data = don.train)

```



## comparaison MSE RLI tot, RLI fin, RLI step
```{r}

# modele lineaire total
MSE_RLI_NL_tot= mean((Y.test-predict(RLI_NL_tot,don.test))^2)

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RLI_NL_fin= mean((Y.test-predict(RLI_NL_fin,don.test))^2)

# modele lineaire en ne gardant que les variables significatives par step
MSE_RLI_NL_step= mean((Y.test-predict(RLI_NL_step,don.test))^2)

# comparaison des MSE entre les modèles RL sans interaction
MSE_RLI_NL=c(MSE_RLI_NL_tot, MSE_RLI_NL_fin, MSE_RLI_NL_step)
which.min(MSE_RLI_NL) # c'est le modèle fin qui présente la plus petite MSE



```

```{r}
# graphe des MSE
graph<-barplot(MSE_RLI_NL, xlab="modèles", ylab="MSE", ylim = range(MSE_RLI_NL), main="MSE des modèles RLI",las=0)
axis(1, labels=c("tot","fin","step"), at = graph)

# les MSE sont assez proches
diff_min_max_RLI_NL = (MSE_RLI_NL_step - MSE_RLI_NL_tot)/ MSE_RLI_NL_tot
diff_min_max_RLI_NL # 3.1% d'écart

```


## RLI modèle retenu, résidus
```{r}

# modèle retenu : fin=tot
RLI_NL <-RLI_NL_tot 
pred_RLI_NL=predict(RLI_NL, newdata=don.test, se=T)
MSE_RLI_NL= mean((Y.test-predict(RLI_NL,don.test))^2)
# le graphe des résidus presente moins de structure
plot(RLI_NL)


```

```{r}
checkresiduals(RLI_NL)
# la distribution pas centrée, avec une queue à gauche

```



# MODELES  AVEC INTERACTIONs multiples en séparant les variables liées à la température des autres variables

## RLI multi total avec toutes les variables
```{r}

RLI_NL_multi_tot<-lm(Y~(month + year + day)* (Temp + t1 + t2 + t3 + t4 + t5 + t6 + t7), data=don.train) 
RLI_NL_multi_tot_sum<-summary(RLI_NL_multi_tot)
# RLI_NL_multi_tot_sum


# extraction des coefficients significatifs
coef<-RLI_NL_multi_tot_sum$coefficients[,4]
RLI_NL_multi_tot_var <- names(which(coef<0.05))
dim_coef <- length (RLI_NL_multi_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_NL_multi_tot_var[i] , "+ ") }
formule

```


## RLI multi en ne gardant que les variables significatives par itération jusqu'à stabilisation de formule
```{r}


RLI_NL_multi_fin <- lm( Y~ month + year +  day +  Temp +  t1 +  t7 +  month:Temp +  month:t1 + month:t2 +  month:t3 + month:t4 +  month:t5 +  month:t7 +  year:t1 +  year:t2 +  year:t5 +  year:t6 +  year:t7, data=don.train) 
RLI_NL_multi_fin_sum<-summary(RLI_NL_multi_fin)
# RLI_NL_multi_fin_sum
# MSE_RLI_NL_multi= mean((Y.test-predict(RLI_NL_multi,don.test))^2)

# extraction des coefficients significatifs
coef<-RLI_NL_multi_fin_sum$coefficients[,4]
RLI_NL_multi_fin_var <- names(which(coef<0.05))
dim_coef <- length (RLI_NL_multi_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_NL_multi_fin_var[i] , "+ ") }
formule

```



## RLI multi modele issues de step
```{r}

RLI_NL_multi_step=step(RLI_NL_multi_tot, test="F", trace= FALSE)
RLI_NL_multi_step

```



OLS RLI multi modèle issu de step
```{r}
RLI_NL_multi_step <- lm ( Y ~  month + year + day + Temp + t1 + t2 + t3 + t4 + t5 + t6 + t7 + month:Temp + month:t1 + month:t2 + month:t3 + month:t4 + month:t5 + month:t7 + year:t1 + year:t2 + year:t3 + year:t5 + year:t6 + year:t7, data = don.train)


```


## OLS comparaison MSE RLI_multi tot, fin, step
```{r}
# modele lineaire total
MSE_RLI_NL_multi_tot= mean((Y.test-predict(RLI_NL_multi_tot,don.test))^2)

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RLI_NL_multi_fin= mean((Y.test-predict(RLI_NL_multi_fin,don.test))^2)

# modele lineaire en ne gardant que les variables significatives par step
MSE_RLI_NL_multi_step= mean((Y.test-predict(RLI_NL_multi_step,don.test))^2)

# comparaison des MSE entre les modèles RL sans interaction
MSE_RLI_NL_multi=c(MSE_RLI_NL_multi_tot, MSE_RLI_NL_multi_fin, MSE_RLI_NL_multi_step)
which.min(MSE_RLI_NL_multi) 

# c'est le modèle fin qui est retenu


```


```{r}
# graphe des MSE
graph<-barplot(MSE_RLI_NL_multi, xlab="modèles", ylab="MSE", ylim = range(MSE_RLI_NL_multi), main="MSE des modèles RLI multi",las=0)
axis(1, labels=c("tot","fin","step"), at = graph)

# les MSE sont assez proches
diff_min_max_RLI_NL_multi = (MSE_RLI_NL_multi_tot - MSE_RLI_NL_multi_fin)/ MSE_RLI_NL_multi_fin
diff_min_max_RLI_NL_multi # 6.3% d'écart

```



## OLS RLI multi, modèle retenu, graphe résidus
```{r}

# modèle retenu : 
RLI_NL_multi <- RLI_NL_multi_fin
pred_RLI_NL_multi=predict(RLI_NL_multi, newdata=don.test, se=T)
MSE_RLI_NL_multi= mean((Y.test-predict(RLI_NL_multi,don.test))^2)

# le graphe des résidus n'a plus de structure
plot(RLI_NL_multi)


```

## OLS RLI multi autre plot résidus
```{r}
checkresiduals(RLI_NL_multi)
# la distribution est mieux centrée, forme plus gaussienne

```


## OLS comparaison RL, RLI, RLI multi STATS
```{r}
# comparaison modèles linéaire sans et avec interaction: l'interaction permet d'améliorer les stat
# R² ajusté plus élevé pour RLI multi
# residual std error plus faible pour RLI multi
# F-stat plus élevé pour pour RLI 
stargazer(RL_NL, RLI_NL, RLI_NL_multi ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","RLI", "multi"))



```


# MODELES AVEC INTERACTION SUR TEMP (poly 2)

## OLS AVEC INTERACTION entre Temp (poly degré 2) modèle total
```{r}

RLI_NL_P2_tot<-lm(Y~ (month + year + day)*I(poly(Temp, 2)), data=don.train)
RLI_NL_P2_tot_sum<-summary(RLI_NL_P2_tot)
# RLI_NL_P2_tot_sum

# extraction des coefficients significatifs
coef<-RLI_NL_P2_tot_sum$coefficients[,4]
RLI_NL_P2_tot_var <- names(which(coef<0.05))
dim_coef <- length (RLI_NL_P2_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_NL_P2_tot_var[i] , "+ ") }
formule

```


## OLS AVEC INTERACTION  entre Temp (poly degré 2) en ne gardant que les variables significatives par itération jusqu'à stabilisation de formule 
```{r}


RLI_NL_P2_fin <- lm( Y~ month + year +  day +  I(poly(Temp, 2)) + month:I(poly(Temp, 2)) + day:I(poly(Temp, 2)), data=don.train) 
RLI_NL_P2_fin_sum<-summary(RLI_NL_P2_fin)


# extraction des coefficients significatifs
coef<-RLI_NL_P2_fin_sum$coefficients[,4]
RLI_NL_P2_fin_var <- names(which(coef<0.05))
dim_coef <- length (RLI_NL_P2_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, RLI_NL_P2_fin_var[i] , "+ ") }
formule

```



OLS AVEC INTERACTION entre Temp (poly degré 2) selection de variables par step
```{r}
RLI_NL_P2_step <- step(RLI_NL_P2_tot, test="F", trace = FALSE)
RLI_NL_P2_step


```

## OLS AVEC INTERACTION entre Temp (poly degré 2) modèle issu de step 
```{r}
RLI_NL_P2_step<-lm(formula = Y ~ month + year + day + I(poly(Temp, 2)) + month:I(poly(Temp, 2)) + year:I(poly(Temp, 2)), data = don.train)


```


## comparaison RLI_P2 tot, fin et step
```{r}

# modele lineaire en ne gardant que les variables significatives à la main
MSE_RLI_NL_P2_tot= mean((Y.test-predict(RLI_NL_P2_tot,don.test))^2)

# modele lineaire avec interaction 
MSE_RLI_NL_P2_fin= mean((Y.test-predict(RLI_NL_P2_fin,don.test))^2)

# modele lineaire avec interaction multiple en ne gardant que les variables significatives à la main
MSE_RLI_NL_P2_step= mean((Y.test-predict(RLI_NL_P2_step,don.test))^2)


# comparaison des MSE entre les modèles RL, RLI, RLI multi
MSE_RLI_NL_P2=c(MSE_RLI_NL_P2_tot, MSE_RLI_NL_P2_fin, MSE_RLI_NL_P2_step)


which.min(MSE_RLI_NL_P2) 
# c'est le modèle fin qui est retenu


```

```{r}

# graphe des MSE
graph<-barplot(MSE_RLI_NL_P2, xlab="modèles", ylab="MSE", ylim = range(MSE_RLI_NL_P2), main="MSE des modèles RLI",las=0)
axis(1, labels=c("tot","fin","step"), at = graph)

# les MSE sont très proches
diff_min_max_RLI_NL_P2 = (MSE_RLI_NL_P2_step - MSE_RLI_NL_P2_fin)/ MSE_RLI_NL_P2_fin
diff_min_max_RLI_NL_P2 # 1.3% d'écart

```


## modèle RLI_P2 final retenu par MSE et graphe résidus
```{r}

RLI_NL_P2 <- RLI_NL_P2_fin
pred_RLI_NL_P2=predict(RLI_NL_P2, newdata=don.test, se=T)
MSE_RLI_NL_P2= mean((Y.test-predict(RLI_NL_P2,don.test))^2)

# le graphe des résidus n'a plus de structure incurvée
plot(RLI_NL_P2)

```


```{r}
checkresiduals(RLI_NL_P2)
# la distribution  moins centrée avec pic au centre

```



## OLS comparaison modèles linéaire avec interaction simples et multiples avec les stats
```{r}
# les interactions améliorent les stat par rapport au modèle linéaire sans interaction
# R² ajusté plus élevé pour RLI_multi (0.979 vs 0.942)
# Residual std error le plus faible pour RLI_multi (0.45 vs 0.24)
# F stat plus élevé pour RLI
stargazer(RL_NL, RLI_NL, RLI_NL_multi, RLI_NL_P2 ,type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL", "RLI","multi", "P2"))


```

## comparaison RL et RLI avec les MSE
```{r}
# modele lineaire 
MSE_RL_NL= mean((Y.test-predict(RL_NL,don.test))^2)

# modele lineaire avec interaction 
MSE_RLI_NL= mean((Y.test-predict(RLI_NL,don.test))^2)

# modele lineaire avec interaction multiple
MSE_RLI_NL_multi= mean((Y.test-predict(RLI_NL_multi,don.test))^2)

# modele lineaire avec interaction multiple en ne gardant que les variables significatives à la main
MSE_RLI_NL_P2= mean((Y.test-predict(RLI_NL_P2,don.test))^2)


# comparaison des MSE entre les modèles RL, RLI, RLI multi
MSE_NL_RL=c(MSE_RL_NL, MSE_RLI_NL, MSE_RLI_NL_multi ,MSE_RLI_NL_P2)

which.min(MSE_NL_RL)
# c'est RLI_multi



```

## comparaison MSE RL et RLI avec MSE résultat

```{r}
# graphe des MSE
graph<-barplot(MSE_NL_RL, xlab="modèles", ylab="MSE", main="MSE des modèles RL",las=0)
axis(1, labels=c("RL","RLI","RLI_multi", "RLI_P2"), at = graph)

```


```{r}

# graphe des MSE échelle réduite
graph<-barplot(MSE_NL_RL, xlab="modèles", ylab="MSE", ylim = range(MSE_NL_RL) ,main="MSE des modèles RL",las=0)
axis(1, labels=c("RL","RLI","RLI_multi", "RLI_P2"), at = graph)

```


```{r}

# les écarts de MSE sont très grands : celui du max (RLI_P2) est 12.7x fois plus grand que celui du plus petit
diff_min_max_RL_NL_all = (MSE_RLI_NL_P2 - MSE_RLI_NL_multi)/ MSE_RLI_NL_multi
diff_min_max_RL_NL_all 
```


```{r}
checkresiduals(RL_NL)
```

```{r}
checkresiduals(RLI_NL)
```


```{r}
checkresiduals(RLI_NL_multi)
```


```{r}
checkresiduals(RLI_NL_P2)

```


## Graphes modèles RL et RLI
```{r}
pred_RL_NL=predict(RL_NL, newdata=don.test, se=T)
pred_RLI_NL=predict(RLI_NL, newdata=don.test, se=T)
pred_RLI_NL_P2=predict(RLI_NL_P2, newdata=don.test, se=T)
pred_RLI_NL_multi=predict(RLI_NL_multi, newdata=don.test, se=T)

# graphe des valeurs prédites selon les modèles
# plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RL et RLI Pays Bas" )
# lines(don.test$Date,pred_RL_NL$fit, col="blue")
# lines(don.test$Date,pred_RLI_NL$fit, col="red")
# lines(don.test$Date,pred_RLI_NL_P2$fit, col="green")

plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RL sur Pays Bas" )  # les valeurs extrèmes sont sous-estimées
lines(don.test$Date,pred_RL_NL$fit, col="blue")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI simple sur Pays Bas" )  # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_NL$fit, col="red")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèles RLI poly2 sur Pays Bas" )  # les valeurs extrèmes sont surestimées
lines(don.test$Date,pred_RLI_NL_P2$fit, col="green")

# graphe des valeurs prédites selon les modèles
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="modèle RLI multiple sur Pays Bas" )   # les valeurs extrèmes sont mieux prédites
lines(don.test$Date,pred_RLI_NL_multi$fit, col="yellow")

```

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# REGRESSION PENALISEE
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## REGRESSION PENALISEE RIDGE
```{r}
library(glmnet)
# library(caTools)
# library(randomForest)
library(ggplot2)


# par defaut, glmnet standardise les variables pour les mettre sur la même échelle.
# si on ne veut pas, standardise=FALSE
X=model.matrix(Y~.,don)[,-1]
dim(X) # en colonne toutes les variables yc dummy variables


# grille de lambda de 10^10 à 10^-2
# pour mémoire, si lambda=0, c'est le MCO
grid=10^seq(10,-2,length=100)


# REGRESSION PENALISEE RIDGE sur une grille de lambda
# Ridge pour alpha=0 et Lasso pour alpha=1
ridge.mod=glmnet(X,Y,alpha=0,lambda=grid) 

# a chaque valeur de lambda est associé un vecteur de coefficients de regression stockés dans une matrice coef()
# nombre de lignes = nombre de variables + l'intercept
# plus lambda est grand et plus les coefficients sont petits
dim(coef(ridge.mod))


# PREDICT AVEC TRAIN ET TEST
set.seed(1)
train=sample(1:nrow(X),0.8*nrow(X))
test=(-train)
Y.test=Y[test]

ridge.mod=glmnet(X[train,],Y[train],alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,newx=X[test,]) 
# ridge.pred=predict(ridge.mod,s=4, newx=X[test,]) 
# s est la valeur du lambda pour la prédiction. Par défaut, c'est la séquence de lambda qui a été utilisée pour creer le modèle
MSE_ridge=mean((ridge.pred-Y.test)^2)
MSE_ridge


# CROSS VALIDATION HOLD OUT POUR LE CHOIX DU LAMBDA DANS RIDGE
# recherche de lambda qui minimise MSE
grid=10^seq(10,-2,length=100) 
mse.lambda=rep(NA,length(grid))
for(i in 1:length(grid)) {
ridge.mod=glmnet(X[train,],Y[train],alpha=0,lambda=grid[i])
ridge.pred=predict(ridge.mod,s=grid[i], newx=X[test,]) 
mse.lambda[i] <- mean((Y.test-ridge.pred)^2)
  }
plot(mse.lambda) 

diff.lambda=rep(NA,(length(mse.lambda)-1)) # calcul de la variation de MSE d'une valeur lambda à l'autre
for (i in 1:length(mse.lambda)) { 
diff.lambda[i]=mse.lambda[i+1]-mse.lambda[i]
}
plot(diff.lambda) # la variation de mse.lambda baisse jusqu'à un certain point puis réaugmente jusqu'à la fin

diff.min<-which.min(diff.lambda) # recherche de la plus petite variation 
diff.min 
lambda.min=grid[diff.min]
lambda.min

# MODELISATION AVEC LAMBDA.MIN TROUVEE PAR CROSS VALIDATION
ridge.mod.best=glmnet(X[train,],Y[train],alpha=0,lambda=lambda.min)
ridge.pred=predict(ridge.mod.best,s=lambda.min, newx=X[test,]) 
# s est la valeur du lambda pour la prédiction. Par défaut, c'est la séquence de lambda qui a été utilisée pour creer le modèle
MSE_ridge_best=mean((ridge.pred-Y.test)^2)
MSE_ridge_best



# plot des valeurs prédites vs valeurs réelles # pas pertinent car les prédictions sont écrasées par Ridge
date=data.frame(X)$Date

ggplot() +
  geom_line(aes(x = date[test], y = Y[test]),
             colour = 'red') +
  geom_line(aes(x = date[test], y = ridge.pred),
            colour = 'blue') +
  ggtitle('Regression Ridge, en bleu prédiction') +
  xlab('date') +
  ylab('conso')



```



## REGRESSION PENALISEE LASSO
```{r}

# grille de lambda de 10^10 à 10^-2
# pour mémoire, si lambda=0, c'est le MCO
grid=10^seq(10,-2,length=100)


# REGRESSION PENALISEE RIDGE sur une grille de lambda
# Ridge pour alpha=0 et Lasso pour alpha=1
lasso.mod=glmnet(X,Y,alpha=1,lambda=grid) 

# a chaque valeur de lambda est associé un vecteur de coefficients de regression stockés dans une matrice coef()
# nombre de lignes = nombre de variables + l'intercept
# plus lambda est grand et plus les coefficients sont petits
# dim(coef(lasso.mod))


# PREDICT AVEC TRAIN ET TEST
set.seed(1)
train=sample(1:nrow(X),2*nrow(X)/3)
test=(-train)
Y.test=Y[test]

lasso.mod=glmnet(X[train,],Y[train],alpha=1,lambda=grid) # Ridge pour alpha=0 et Lasso pour alpha=1
lasso.pred=predict(lasso.mod,newx=X[test,]) 
# lasso.pred=predict(lasso.mod,s=4, newx=X[test,]) 
# s est la valeur du lambda pour la prédiction. Par défaut, c'est la séquence de lambda qui a été utilisée pour creer le modèle
MSE=mean((lasso.pred-Y.test)^2)
MSE


# CROSS VALIDATION HOLD OUT POUR LE CHOIX DU LAMBDA DANS lasso
# recherche de lambda qui minimise MSE
grid=10^seq(10,-2,length=100) 
mse.lambda=rep(NA,length(grid))
for(i in 1:length(grid)) {
lasso.mod=glmnet(X[train,],Y[train],alpha=1,lambda=grid[i])
lasso.pred=predict(lasso.mod,s=grid[i], newx=X[test,]) 
mse.lambda[i] <- mean((Y.test-lasso.pred)^2)
  }
plot(mse.lambda) 

diff.lambda=rep(NA,(length(mse.lambda)-1)) # calcul de la variation de MSE d'une valeur lambda à l'autre
for (i in 1:length(mse.lambda)) { 
diff.lambda[i]=mse.lambda[i+1]-mse.lambda[i]
}
plot(diff.lambda) # la variation de mse.lambda baisse jusqu'à un certain point puis réaugmente jusqu'à la fin

diff.min<-which.min(diff.lambda) # recherche de la plus petite variation 
diff.min
lambda.min=grid[diff.min]
lambda.min

# MODELISATION AVEC LAMBDA.MIN TROUVEE PAR CROSS VALIDATION
lasso.mod.best=glmnet(X[train,],Y[train],alpha=1,lambda=lambda.min)
lasso.pred=predict(lasso.mod.best,s=lambda.min, newx=X[test,]) 
MSE_lasso_best=mean((lasso.pred-Y.test)^2)
MSE_lasso_best



# plot des valeurs prédites vs valeurs réelles # pas pertinent car les prédictions sont écrasées par lasso
date=data.frame(X)$Date

ggplot() +
  geom_line(aes(x = date[test], y = Y[test]),
             colour = 'red') +
  geom_line(aes(x = date[test], y = lasso.pred),
            colour = 'blue') +
  ggtitle('Regression lasso, en bleu prédiction') +
  xlab('date') +
  ylab('conso')


```



Les MSE sont tres eleves, nous ne retiendrons pas les regressions penalisees pour la suite.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES POLYNOMIAL
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

POLYNOME base et variables sur la base centrée réduite

Modèles avec cible=Conso en fonction d'un polynome sur Temp

## POLYNOME détermination du degré par cross validation hold out train / test
```{r}

d=20 # degré max de polynome à tester
err_poly_NL_HO=rep(NA,d)
for(i in 1:d) {
  model <- lm(formula=Y~poly(Temp,i, raw=T), data=don.train)
  err_poly_NL_HO[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(sqrt(err_poly_NL_HO),ylab="MSE", main=' MSE Pays Bas selon le degré de polynome',pch=19,type='b')


```

POLYNOME détermination du degré par cross validation hold out resultats
```{r}
poly_NL_deg_HO=which.min(err_poly_NL_HO) 
poly_NL_deg_HO
# 5

```


POLYNOME détermination du degré par cross validation hold out modèle retenu et résidus
```{r}

#modèle retenu par hold out
poly_NL_HO<- lm(formula=Y~poly(Temp,which.min(err_poly_NL_HO), raw=T), data=don.train)
poly_NL_HO_sum<- summary(poly_NL_HO)
MSE_poly_NL_HO= mean((Y.test-predict(poly_NL_HO,don.test))^2)

```


## POLYNOME détermination du degré par cross validation K-fold 
```{r}

# # CROSS VALIDATION K.fold
library(boot)
k=10
d=15
set.seed(1)
err_poly_NL_KF =as.vector(rep(0,d))
for (i in 1:d){
glm.fit<-glm(Y~poly(Temp,i),data = don.train)
err_poly_NL_KF[i]<-cv.glm(don.test,glm.fit,K=10)$delta[1]
}

plot(err_poly_NL_KF, pch=19,type='b')

```


POLYNOME détermination du degré par cross validation K-fold résulats
```{r}
poly_NL_deg_KF=which.min(err_poly_NL_KF) 
poly_NL_deg_KF

```


POLYNOME détermination du degré par cross validation K-fold modèle retenu
```{r}

#modèle retenu par K_fold
poly_NL_KF<- lm(formula=Y~poly(Temp,which.min(err_poly_NL_KF), raw=T), data=don.train)
MSE_poly_NL_KF= mean((Y.test-predict(poly_NL_KF,don.test))^2)


```


## comparaison poly hold out et K-Fold
```{r}

# COMPARAISON DES MODELES
#modèle issu de CV hold out
poly_NL_HO<- lm(formula=Y~poly(Temp,which.min(err_poly_NL_HO), raw=T), data=don.train)
MSE_poly_NL_HO= mean((Y.test-predict(poly_NL_HO,don.test))^2)

#modèle issu de CV K_fold
poly_NL_KF<- lm(formula=Y~poly(Temp,which.min(err_poly_NL_KF), raw=T), data=don.train)
MSE_poly_NL_KF= mean((Y.test-predict(poly_NL_KF,don.test))^2)

#comparaison des modèles linéaire total avec poly
# R² ajusté plus faible pour poly par rapport au modèle linéair
# résidual sdt error plus élevé pour poly que dans RL 
# F stat plus élevé pour les poly que pour modèle linéaire
stargazer(RL_NL,poly_NL_HO, poly_NL_KF, type='text', flip=TRUE, title="Results", keep=c("Date"), column.labels = c("RL","polyHO", "polyKF"))



```

choix du degré par MSE
```{r}
# en comparant les MSE, 
POLY_NL_compar=c(MSE_poly_NL_HO, MSE_poly_NL_KF)
which.min(POLY_NL_compar)
# c'est celui par CV HO

```

## modèle poly retenu
```{r}
# nous retiendrons poly_NL_HO sur le critère du MSE
poly_NL_deg = poly_NL_deg_HO
POLY_NL<- poly_NL_HO
pred_POLY_NL=predict(POLY_NL, newdata=don.test, se=T) 
MSE_POLY_NL= mean((Y.test-predict(POLY_NL,don.test))^2)



```


modèle poly retenu résidus
```{r}
plot(POLY_NL)
# il n'y a plus de structure incurvée de Residuals vs fitted

```


```{r}
checkresiduals(POLY_NL)
# la distribution ne semble pas être gaussienne


```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES SPLINES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

SPLINE Conso en fonction de la température


## SPLINES choix du degré de liberté/noeuds par CV hold out pour natural splines
```{r}

# CHOIX DU DEGRE DE LIBERTE df (et donc du nombre de noeuds) par cross validation HOLD OUT TRAIN/TEST 
# l'option df produit des splines avec des noeuds placés sur les quantiles
# on n'obtient pas les mêmes noeuds en bs et ns, pour un même degré de liberté
# attr() pour avoir les noeuds issus de df

# # noeuds avec basic splines
# attr(bs(X,df=3),"knots") # pas de noeud
# attr(bs(X,df=4),"knots") # un seul noeud à 50% = 2 intervalles + 2 frontières min et max
# attr(bs(X,df=5),"knots") # 2 noeuds à 1/3 et 2/3 = 3 intervalles + 2 frontières min et max
# attr(bs(X,df=6),"knots") # 3 noeuds à 25%, 50% et 75% = 4 intervalles + 2 frontières min et max
# 
# # noeuds avec natural splines
# attr(ns(X,df=1),"knots") #  pas de noeud
# attr(ns(X,df=2),"knots") #  un seul noeud à 50%
# attr(ns(X,df=3),"knots") #  2 noeuds aux quantiles 33% (7.4) et 66% (13.7)
# attr(ns(X,df=4),"knots") #  3 noeuds à 25% (5.8), 50% (10.2),75% (15.5)
# attr(ns(X,df=5),"knots") #  4 noeuds à 20% (4.9), 40% (8.5),60% (12.2), 80% (16.5)


# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
MSE_SP_NL_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(Temp,df=i), data=don.train)
  MSE_SP_NL_ns[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(MSE_SP_NL_ns, ylab="MSE", main=' MSE Pays Bas selon le degré de liberté du spline',pch=19,type='b')

SP_NL_df_ns=which.min(MSE_SP_NL_ns)
SP_NL_df_ns
# 3

attr(ns(don$Temp,df=SP_NL_df_ns),"knots")
# 2 noeuds

```



## SPLINES choix du degré de liberté/noeuds par CV hold out pour basic splines
```{r}

# pour basic spline, recherche degré df qui minimise le MSE 

DF=15 # df max à tester
MSE_SP_NL_bs=rep(0,DF)
for(i in 4:DF) {
  model <- lm(Y~bs(Temp,df=i), data=don.train)
  MSE_SP_NL_bs[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(MSE_SP_NL_bs, ylab="MSE", main=' MSE selon le degré de liberté du spline', pch=19, type='b')

SP_NL_df_bs = which.min(MSE_SP_NL_bs)+3 # le test démarre à df=4
SP_NL_df_bs # 4

attr(bs(don$Temp,df=SP_NL_df_bs),"knots")
# 1 noeud

```


## SPLINES choix entre natural splines et basic splines par MSE 
```{r}

# CHOIX ENTRE BASIC SPLINES ET NATURAL SPLINES, celui qui minimise le MSE

#natural splines ns
# ns() ne marche que si les variables sont numériques. Les variables qualitatives seront transformées en dummy variables
attr(ns(don$Temp,df=SP_NL_df_ns),"knots")  # 2 noeuds 
fit_ns_NL_tot=lm(Y~ns(Temp,df=SP_NL_df_ns), data=don.train)
MSE_SP_NL_ns <- mean((Y.test-predict(fit_ns_NL_tot,don.test))^2)

#basic splines bs: on prend le df qui donne les mêmes noeuds que natural spline 
attr(bs(don$Temp,df=SP_NL_df_bs),"knots") # 1 noeud
fit_bs_NL_tot=lm(Y~bs(Temp,SP_NL_df_bs), data=don.train)
MSE_SP_NL_bs <- mean((Y.test-predict(fit_bs_NL_tot,don.test))^2)


SP_NL_compar=c(MSE_SP_NL_bs,MSE_SP_NL_ns)
which.min(SP_NL_compar)
# => avec les mse, on choisit ns


```


SPLINES choix entre natural splines et basic splines par stats des modèles
```{r}

#comparaison des stats des résultats entre basic et natural splines
# Le R² ajusté et residual std error sont égaux entre ns et bs
stargazer(fit_bs_NL_tot, fit_ns_NL_tot, type='text', flip=TRUE, title="Results", align=TRUE, column.labels = c("bs", "ns"))
# => avec les stat des modèles, choix de ns car F-stat plus grand qu bs. 

```


SPLINES modele retenu et résidus
```{r}

# en minimisant MSE, on retient spline ns avec df=3 trouvé par cross validation hold out
SP_NL_df= SP_NL_df_ns
SP_NL <- lm ( Y~ ns(Temp, df = SP_NL_df), data=don.train) #  2 noeud 
pred_SP_NL=predict ( SP_NL, newdata=don.test, se=T)
MSE_SP_NL= mean( (Y.test-predict(SP_NL,don.test))^2 )
plot(SP_NL) # graphe des résidus vs fitted n'a plus de structure incurvée


```

```{r}
checkresiduals(SP_NL)
# distribution pas vraiment gaussienne


```


SPLINES graphes et smooting splines
```{r}

# graphes de conso vs température
plot(X.test,Y.test, xlab = "Temp", ylab="Conso")
points (X.test,pred_SP_NL$fit, col="blue") 

# graphe de conso vs date
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="Spline Pays Bas, fit (bleu)" )
lines(don.test$Date,pred_SP_NL$fit, col="blue") 


# SMOOTHING SPLINE
SM_NL=smooth.spline(Y.test,X.test,df=3) # on spécifie df=6 et le lambda est déterminé de sorte à obtenir df=6
SM_NL_cv=smooth.spline(Y.test,X.test,cv=TRUE) # lambda est choisi par cross validation

plot(SM_NL, main="smooth spline") 
plot(SM_NL_cv, main="cv") 


```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES GAM
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


## GAM POLY
avec détermination du polynome par CV K-fold avec toutes les variables : 
intialement avec toutes les variables, mais message erreur prediction from a rank-deficient fit may be misleading: cela amène a supprimer les variables liées aux vacances et jours fériés, pour ne garder que month, year, day

```{r}
# library(boot)

d=15 # degré de poly à tester
GAM_NL_POLY_error=rep(0,d)
for (i in 1:d) { 
  glm.fit= glm(Y~ poly(Temp,i) + month + year + day, data = don.train) 
  GAM_NL_POLY_error[i]=cv.glm(don.train, glm.fit, K=10 )$delta[1] # par défaut, K= nombre d'observations donc LOOCV
}

plot(GAM_NL_POLY_error, main="GAM Pays Bas cv.error selon degré polynome",pch=19,type='b') 

GAM_NL_POLY_deg = which.min(GAM_NL_POLY_error) 
GAM_NL_POLY_deg


```

GAM POLY 
```{r}

# modèle GAM avec polynôme sur la température 
GAM_NL_POLY_tot=glm(Y~ poly(Temp,GAM_NL_POLY_deg) + month + year + day, data = don.train) 
GAM_NL_POLY_tot_sum <-summary(GAM_NL_POLY_tot)

# extraction des coefficients significatifs
coef<-GAM_NL_POLY_tot_sum$coefficients[,4]
GAM_NL_POLY_tot_var <- names(which(coef<0.05))
dim_coef <- length (GAM_NL_POLY_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, GAM_NL_POLY_tot_var[i] , "+ ") }
formule

```

GAM POLY avec variables significatives à la main, de façon itérative jusqu'à stabilisation de formule
```{r}

# modèle avec les variables significatives
GAM_NL_POLY_fin=glm(Y~  poly(Temp, GAM_NL_POLY_deg) +  month + year + day, data = don.train) # fin et tot identiques
GAM_NL_POLY_fin_sum <- summary (GAM_NL_POLY_fin)


# extraction des coefficients significatifs
coef<-GAM_NL_POLY_fin_sum$coefficients[,4]
GAM_NL_POLY_fin_var <- names(which(coef<0.05))
dim_coef <- length (GAM_NL_POLY_fin_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, GAM_NL_POLY_fin_var[i] , "+ ") }
formule

```


GAM POLY avec variables issues de step
```{r}
GAM_NL_POLY_step<-step(GAM_NL_POLY_tot, test="F", trace=FALSE) # step identique à tot et fin
GAM_NL_POLY_step

```


GAM POLY modèle retenu, résidus
```{r}

# modèle retenu : 
GAM_NL_POLY <- GAM_NL_POLY_tot
pred_GAM_NL_POLY=predict(GAM_NL_POLY, newdata=don.test, se=T)
MSE_GAM_NL_POLY= mean((Y.test-predict(GAM_NL_POLY,don.test))^2)

# le graphe des résidus est encore légèrement incurvé
plot(GAM_NL_POLY)

checkresiduals(GAM_NL_POLY)
# peu d'autocorrélation, distribution pas centrée , presque gaussienne

```



GAM POLY valeurs prédites
```{r}
pred_GAM_NL_POLY=predict(GAM_NL_POLY, newdata=don.test, se=T)
# graphe des valeurs prédites par GAM sur la Pays Bas
plot(don.test$Date, Y.test, xlab = "date", ylab="Conso", main="GAM" )
lines(don.test$Date,pred_GAM_NL_POLY$fit, col="yellow")


```



## GAM SPLINE
```{r}
# pour natural spline, recherche degré df qui minimise le MSE
DF=15 # df max à tester
MSE_GAM_SP_NL_ns=rep(0,DF)
for(i in 1:DF) {
  model <- lm(Y~ns(Temp,df=i) + month + year + day, data=don.train)
  MSE_GAM_SP_NL_ns[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# plot les MSE des modeles sur le training et sur le test set
# On choisit le modele qui a la MSE la plus petite sur le test set
plot(MSE_GAM_SP_NL_ns, ylab="MSE", main=' MSE Pays Bas selon le degré de liberté du spline',pch=19,type='b')

GAM_SP_NL_ns_df=which.min(MSE_GAM_SP_NL_ns)
GAM_SP_NL_ns_df
# 3

attr(ns(don$Temp,df=GAM_SP_NL_ns_df),"knots")
# 2 noeuds

```

```{r}
# modèle GAM avec spline sur la température 
GAM_NL_SP_tot=lm(Y~ns(Temp,df=GAM_SP_NL_ns_df) + month + year + day, data=don.train)
GAM_NL_SP_tot_sum <-summary(GAM_NL_SP_tot)

# extraction des coefficients significatifs
coef<-GAM_NL_SP_tot_sum$coefficients[,4]
GAM_NL_SP_tot_var <- names(which(coef<0.05))
dim_coef <- length (GAM_NL_SP_tot_var)
formule <- "Y ~ "
for ( i in 1: dim_coef) { formule <- paste ( formule, GAM_NL_SP_tot_var[i] , "+ ") }
formule # identique à tot

```

selection de variable par step
```{r}
GAM_NL_SP_step<-step(GAM_NL_SP_tot, test="F", trace=FALSE) # step identique à tot et fin
GAM_NL_SP_step

```

GAM POLY modèle retenu, résidus
```{r}

# modèle retenu : 
GAM_NL_SP <- GAM_NL_SP_tot
pred_GAM_NL_SP=predict(GAM_NL_SP, newdata=don.test, se=T)
MSE_GAM_NL_SP= mean((Y.test-predict(GAM_NL_SP,don.test))^2)

# le graphe des résidus est encore légèrement incurvé
plot(GAM_NL_SP)

checkresiduals(GAM_NL_SP)
# peu d'autocorrélation, distribution pas centrée , presque gaussienne

```

## comparaison GAM POLy et GAM SP
```{r}
# les MSE des 2 GAM ont l'air très proches:
which.min(c(MSE_GAM_NL_POLY,MSE_GAM_NL_SP)) #  c'est GAM SP qui a la plus petite MSE

100*(MSE_GAM_NL_POLY-MSE_GAM_NL_SP)/ MSE_GAM_NL_SP # l'écart est de 1.2%.

# conclusion: pour les autres pays, on pourrait se contenter de fair GAM SP

```


```{r}
stargazer(GAM_NL_POLY, GAM_NL_SP, type='text', flip=TRUE, title="comparaison GAM POLY et GAM SP", align=TRUE, column.labels = c("POLY", "SP"), keep = c("Date"), model.names = TRUE, single.row = TRUE)

# les R² ajusté et residual sd error sont équivalents


```



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES RANDOM FOREST
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 on peut régler deux éléments : 
ntree: le nombre d’arbres construits par l’algorithme 
mtry: le nombre de variables testées à chaque division. 


```{r}

sqrt(ncol(don)) # = valeur mtry par défaut pour une classification
ncol(don) / 3 # valeur par defaut pour une regression


```

## RANDOM FOREST modelisation par defaut
```{r}


# modelisation sur train, par défaut ntree=500
RF_NL<-randomForest(Y~., data=don.train)
# summary(RF_NL_tot_train)
print(RF_NL)
# names(RF_NL_tot) 
# "call"            "type"            "predicted"       "mse"             "rsq"            
# "oob.times"       "importance"      "importanceSD"    "localImportance" "proximity"      
# "ntree"           "mtry"            "forest"          "coefs"           "y"              
# "test"            "inbag"           "terms" 

```

RANDOM FOREST MSE plot
```{r}

# plot MSE selon le nombre d'arbres: la valeur de MSE baisse rapidement et stagne à partir de 100 environ
plot(RF_NL$mse, xlab = "nombre d'arbres", ylab = "MSE")

```

## RANDOM FOREST choix de mtry par CV hold out
```{r}

set.seed(1)
m=15 # mtry max à tester. 
MSE_RF_NL_mtry=rep(0,m)
for(i in 1:m) {
  set.seed(1)
  model <- randomForest(Y~., data=don.train, mtry = i)
  MSE_RF_NL_mtry[i] <- mean((Y.test-predict(model,don.test))^2)
  }

# graphe de MSE
plot(MSE_RF_NL_mtry, xlab="mtry", ylab="MSE", main="MSE selon mtry", type="b")


RF_NL_mtry= which.min(MSE_RF_NL_mtry) 
RF_NL_mtry

```



## RANDOM FOREST choix de ntree par CV
```{r}


Ntree=seq(100,1000,by=100)  # ntree à tester
d=length(Ntree)
nb=1 # nombre de tests de cross validation
MSE_RF_NL_tree=rep(NA,d*nb)
res_ntree=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE

for (j in 1:nb) {

  for(i in 1:d) {
    set.seed(1)
    model <- randomForest(Y~., data=don.train, mtry = RF_NL_mtry, ntree=Ntree[i])
    MSE_RF_NL_tree[i+j-1] <- mean((don.test$Y-predict(model,don.test))^2)
  }

  res_ntree[j]=Ntree[which.min(MSE_RF_NL_tree)]

}

res_ntree


# graphe des MSE du choix de ntree
RF_NL_ntree = Ntree[which.min(MSE_RF_NL_tree)] 
RF_NL_ntree
barplot(MSE_RF_NL_tree, xlab="ntree", ylab="MSE", ylim = range(MSE_RF_NL_tree), main="MSE selon ntree")




```

## RANDOM FOREST choix de nodesize par CV 
```{r}

# CHOIX DE NODESIZE PAR CV HOLD OUT
n_list=seq(from=1,to=10,by=1)  # nodesize à tester
d=length(n_list)
nb=1 # nombre de tests de cross validation
MSE_RF_NL_node=rep(NA,d*nb)
res_node=rep(NA,nb)   # résultat de la CV, ntree qui minimise la MSE

for (j in 1:nb) {
  
  for(i in 1:d) {
    set.seed(1)
    model <- randomForest(Y~., data=don.train,mtry = which.min(MSE_RF_NL_mtry), ntree=RF_NL_ntree, nodesize = n_list[i])
    MSE_RF_NL_node[i+j-1] <- mean((Y.test-predict(model,don.test))^2)
    names(MSE_RF_NL_node)[i] <- paste(as.character(n_list[i]),"node",sep="_")
  }

  res_node[j]=n_list[which.min(MSE_RF_NL_node)]

}

res_node

# graphe des MSE du choix de nodesize
RF_NL_node = which.min(MSE_RF_NL_node)

# plot(MSE_RF_NL.tree, xlab="ntree", ylab="MSE", main="MSE selon ntree")


barplot(MSE_RF_NL_node, xlab="ntree", ylab="MSE", ylim = range(MSE_RF_NL_node) , names = names(MSE_RF_NL_node) ,main="MSE selon nodesize",las=0) 

```


## RANDOM FOREST modèle final
```{r}
RF_NL_fin<-randomForest(Y~., mtry = RF_NL_mtry, ntree=RF_NL_ntree, nodesize = RF_NL_node,data=don.train)
res_RF_NL=don.test$Y-RF_NL_fin$predicted
checkresiduals(res_RF_NL)
# la saisonnalité n'a pas été bien captée: le graphe des résidus est sinusoidal
# beaucoup d'autocorrelations

# plot(RF_NL_fin$mse)

```




## RANDOM FOREST variables par importance
```{r}
varImpPlot(RF_NL_fin) # PLOT (t1, t3) , temp, (cosinus, month, t4, t6, t7)
RF_NL_fin$importance # liste des variables 
RF_NL_fin$importance[order(RF_NL_fin$importance[, 1], decreasing = TRUE), ]  # liste ordonnée

```


## RANDOM FOREST prediction
```{r}

# prediction
RF_NL_fin_pred<-predict(RF_NL_fin,don.test)
RF_NL_fin_pred_sum<-summary(RF_NL_fin_pred)
# RF_NL_fin_pred_sum

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="modèle RF Pays Bas" )
lines(don.test$Date, RF_NL_fin_pred, col="red") 


```

RF modèle avec Temp, month, year, day pour essayer
```{r}
RF_NL_TMYD<-randomForest(Y ~ Temp + month + year + day, mtry = RF_NL_mtry, ntree=RF_NL_ntree, nodesize = RF_NL_node,data=don.train)
res_RF_NL_TMYD=don.test$Y-RF_NL_TMYD$predicted
checkresiduals(res_RF_NL_TMYD)
# pas mieux

```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MODELES SVR
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



## SVR modelisation 
```{r}

# grid search pour les paramètres epsilon et cost (très long)
tuneResult <- tune(svm, Y ~ .,  data = don.train,
              ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:9))
)

print(tuneResult)

# Draw the tuning graph: plus c'est foncé, plus la MSE est élevée
plot(tuneResult)


#Regression with SVM
SVR_NL = tuneResult$best.model
MSE_SVR_NL= mean((Y.test-predict(SVR_NL,don.test))^2)

#Predict using SVM regression
pred_SVR_NL = predict(SVR_NL, don.test)

# SVM Prediction Plot
plot(don.test$Date, Y.test)
lines(don.test$Date, pred_SVR_NL, col="purple")



```


##SVR residuals
```{r}

plot(SVR_NL_tot$residuals)

res_SVR_NL=don.test$Y-pred_SVR_NL
checkresiduals(res_SVR_NL)
# beaucoup d'autocorrélation, distribution pas centrée

```


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# RESEAUX NEURONES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## choix des parametres par CV
```{r}

# avec caret
controlList <- trainControl(method = "cv", number = 5)
tuneMatrix <- expand.grid(size = c(1, 2, 3, 4, 5, 6), decay = seq(from = 0, to = 0.5, by=0.1))

set.seed(1)
NN_NL_tot <- train(x = don.train[ , colnames(don.train) != "Y"],
                   y = don.train[ , colnames(don.train) == "Y"],
                   method = "nnet",
                   linout = TRUE,
                   trace = FALSE,
                   maxit = 100,
                   tuneGrid = tuneMatrix,
                   trControl = controlList)

  
```


## modèle final
```{r}

print(NN_NL_tot$finalModel)

set.seed(1)
NN_NL <- NN_NL_tot$finalModel
pred_NN_NL <- predict(NN_NL, newdata = don.test)
MSE_NN_NL <- mean((pred_NN_NL - don.test$Y)^2)

plot(NN_NL_tot)

```

## tune value
```{r}
tv=NN_NL_tot$finalModel$tuneValue
str(tv)

```


## résidus
```{r}
res_NN_NL=Y.test-pred_NN_NL
str(res_NN_NL) # liste avec 2 
head(res_NN_NL)

checkresiduals(res_NN_NL[,1])
# la distribution n'est pas vraiment gaussienne


```


# XGBOOST

## base speciale XGB
```{r}

don <- base_NL_F_cr

# nom des variables facteurs à convertir en dummies variables
ohe_vars <- names(don)[which(sapply(don, is.factor))]

# conversion en en dummies variables
dummies <- dummyVars(~., data = don)
don_ohe <- as.data.frame(predict(dummies, newdata = don))

# remplacer les variables facteurs par les dummies
don <- cbind(don[, -c(which(colnames(don) %in% ohe_vars))], don_ohe)

# train/test 
Xtrain <- don[train, ]
Xtest <- don[-train, ]

```



## XGBOOST choix des nrounds
```{r}
nround_list = seq(from = 100, to = 1000 , by = 100)
nb_test= length(nround_list)
mse_test = rep(0, nb_test)
str(mse_test)

for (i in 1:nb_test) {
  
  don <- base_NL_F_cr

  # nom des variables facteurs à convertir en dummies variables
  ohe_vars <- names(don)[which(sapply(don, is.factor))]

  # conversion en en dummies variables
  dummies <- dummyVars(~., data = don)
  don_ohe <- as.data.frame(predict(dummies, newdata = don))

  # remplacer les variables facteurs par les dummies
  don <- cbind(don[, -c(which(colnames(don) %in% ohe_vars))], don_ohe)

  # train/test 
  Xtrain <- don[train, ]
  Xtest <- don[-train, ]

  # modelisation
  XGB_NL <- xgboost(data = data.matrix(Xtrain), label = Y.train,
  booster = "gbtree", objective = "reg:linear", eval_metric = "rmse",
  learning_rate = 0.05, 
  subsample = 0.5, seed = 1, # subsample default value=1. Setting to 0.5 means that XGBoost randomly       #collected half of the data instances to grow trees and this will prevent overfitting. 
  silent = 1, nrounds = nround_list[i], verbose = 0)

  # prédiction
  pred_XGB_NL= predict(XGB_NL, data.matrix(Xtest))
  mse_test[i] = fun_mse(Y.test, XGB_NL, data.matrix(Xtest))
 
}

names(mse_test) <- as.character(nround_list)

barplot(mse_test, xlab="nround", ylab="MSE", ylim = range(mse_test) , names = names(mse_test) , main="MSE selon nround",las=0) 



```

```{r}
mse_test


which.min(mse_test) 

```

## modèle retenu
```{r}
XGB_NL <- xgboost(data = data.matrix(Xtrain), label = Y.train,
  booster = "gbtree", objective = "reg:linear", eval_metric = "rmse",
  learning_rate = 0.05, 
  subsample = 0.5, seed = 1, # subsample default value=1. Setting to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting. 
  silent = 1, nrounds = 700, verbose = 0)

# prédiction
pred_XGB_NL= predict(XGB_NL, data.matrix(Xtest))
MSE_XGB_NL=mean((Y.test-pred_XGB_NL)^2)
MAPE_XGB_NL = fun_mape(Y.test, XGB_NL, data.matrix(Xtest))

plot(don.test$Date, don.test$Y, xlab = "date", ylab="Conso", main="XGB Pays Bas" )
lines(don.test$Date,pred_XGB_NL, col="purple") 

```


# BAGGING

## bagging RL

```{r}
fun_bag_RL<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-lm(Y ~ Temp + month + year + day ,data=training[train_pos,])
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_RL_pred <-fun_bag_RL(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_RL <- mean((Y.test-bagg_RL_pred)^2)


```



## bagging POLY avec degre issu de CV 

```{r}
fun_bag_POLY<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-lm(formula=Y~poly(Temp,poly_NL_deg, raw=T),data=training[train_pos,])
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_POLY_pred <-fun_bag_POLY(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_POLY <- mean((Y.test-bagg_POLY_pred)^2)


```



## bagging Splines: avec df issu CV

```{r}
fun_bag_SP<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-lm ( Y~ ns(Temp, df = SP_NL_df), data=training[train_pos,])
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_SP_pred <-fun_bag_SP(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_SP <- mean((Y.test-bagg_SP_pred)^2)


```



## bagging GAM Spline avec df issu de CV  
```{r}
fun_bag_GAM<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-lm(Y~ns(Temp,df=GAM_SP_NL_ns_df) + month + year + day, data=training[train_pos,])
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_GAM_pred <-fun_bag_GAM(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_GAM <- mean((Y.test-bagg_GAM_pred)^2)



```



## bagging RF avec parametres issus de CV
```{r}
fun_bag_RF<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-randomForest(Y~., mtry = RF_NL_mtry, ntree= RF_NL_ntree, nodesize = RF_NL_node, data=training[train_pos,])
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_RF_pred <-fun_bag_RF(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_RF <- mean((Y.test-bagg_RF_pred)^2)



```



## bagging SVR avec epsilon et cost du modele final après tuning
```{r}
fun_bag_SVR<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-svm(Y~., data=training[train_pos,], epsilon = 0, cost = 4)
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_SVR_pred <-fun_bag_SVR(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_SVR <- mean((Y.test-bagg_SVR_pred)^2)


```



## NN avec bagging: size et decay issu de tuning
```{r}

fun_bag_NN<-function(training,testing, length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
fit<-nnet(Y ~ . , data=training[train_pos,], size=5, decay=0.4, trace= F)
predict(fit,newdata=testing)
}
rowMeans(predictions) # moyenne des predictions
}

bagg_NN_pred <-fun_bag_NN(don.train, don.test, length_divisor=4,iterations=1000)
bagg_MSE_NN <- mean((Y.test-bagg_NN_pred)^2)


```



## bagging XGB trop long



# SYNTHESE DES MODELES 


## MSE sans bagging 
```{r}


# comparaison des MSE de tous les modèles 
MSE_NL_tot=c(MSE_RL_NL, MSE_RLI_NL, MSE_RLI_NL_multi, MSE_RLI_NL_P2, MSE_POLY_NL, MSE_SP_NL, MSE_GAM_NL_POLY,MSE_GAM_NL_SP ,MSE_RF_NL, MSE_SVR_NL, MSE_NN_NL, MSE_XGB_NL)
min_MSE <- which.min(MSE_NL_tot) # c'est le modèle XGB

# graphe des MSE
graph<-barplot(MSE_NL_tot, xlab="modèles", ylab="MSE", main="MSE des modèles Pays Bas",las=0, col=ifelse(MSE_NL_tot==MSE_NL_tot[min_MSE], "red", "blue"))
axis(1, labels=c("RL", "RLI","multi", "P2" ,"Poly" ,"SPLINE", "GAM_poly", "GAM_SP" ,"RF", "SVR", "NN", "XGB"), at = graph)

```


MSE meilleurs modèles 
```{r}

# comparaison des MSE entre les meilleurs modèles, sans P2, Poly simple, Spline simple, NN
MSE_NL_r=c(MSE_RL_NL, MSE_RLI_NL, MSE_RLI_NL_multi, MSE_GAM_NL_POLY, MSE_GAM_NL_SP, MSE_RF_NL, MSE_SVR_NL, MSE_XGB_NL)

# graphe des MSE
graph<-barplot(MSE_NL_r, xlab="modèles", ylab="MSE",ylim=c(MSE_SVR_NL, MSE_RL_NL) ,main="MSE des modèles", las=0, col=ifelse(MSE_NL_tot==MSE_NL_tot[min_MSE], "red", "blue"))
axis(1, labels=c("RL", "RLI","multi", "GAM_POLY","GAM_SP" ,"RF", "SVR", "XGB"), at = graph)


```



## MSE avec bagging
```{r}

bagg_MSE_tot=c(bagg_MSE_RL, bagg_MSE_POLY, bagg_MSE_SP, bagg_MSE_GAM, bagg_MSE_RF, bagg_MSE_SVR, bagg_MSE_NN, bagg_MSE_XGB)
min_bagg_MSE <- which.min(bagg_MSE_tot)

# graphe des MSE
graph<-barplot(bagg_MSE_tot, xlab="modeles", ylab="MSE", main="MSE des modeles avec bagging",las=0, col=ifelse(bagg_MSE_tot==bagg_MSE_tot[min_bagg_MSE], "red", "blue"))
axis(1, labels=c("RL", "Poly" ,"SP", "GAM" ,"RF", "SVR", "NN", "XGB"), at = graph)



```

MSE des meilleurs modeles 
```{r}

bagg_MSE_r= c(bagg_MSE_RL, bagg_MSE_POLY, bagg_MSE_SP, bagg_MSE_GAM, bagg_MSE_RF, bagg_MSE_SVR, bagg_MSE_XGB)
min_bagg_MSE <- which.min(bagg_MSE_r)

# graphe des MSE
graph<-barplot(bagg_MSE_r, xlab="modeles", ylab="MSE", main="MSE des modeles avec bagging",las=0, col=ifelse(bagg_MSE_r==bagg_MSE_r[min_bagg_MSE], "red", "blue"))
axis(1, labels=c("RL", "Poly" ,"SP", "GAM" ,"RF", "SVR", "XGB"), at = graph)

```


## comparaison des MSE sans bagging et avec bagging
```{r}
MSE_NL_comp=c(MSE_RL_NL, MSE_POLY_NL, MSE_SP_NL, MSE_GAM_NL_SP ,MSE_RF_NL, MSE_SVR_NL, MSE_NN_NL, MSE_XGB_NL)

modeles=c("RL", "Poly" ,"SP", "GAM" ,"RF", "SVR", "NN", "XGB")
sans_bagg=MSE_NL_comp
avec_bagg=bagg_MSE_tot
df <- data.frame(cbind(modeles, sans_bagg, avec_bagg)) # les 2 dernières variables sont devenues des facteurs
# convertir en numéric
for (i in 2:3) {  df[, i] <- as.numeric(as.character(df[, i])) }
str(df) # y en numerique

library(lattice)
barchart(sans_bagg+avec_bagg~ modeles, data = df, auto.key= T) 



```

meilleurs modeles
```{r}
modeles=c("RL","GAM" ,"RF", "SVR","XGB")
sans_bagg=c(MSE_RL, MSE_GAM_SP,MSE_RF, MSE_SVR, MSE_XGB)
avec_bagg=c(bagg_MSE_RL, bagg_MSE_GAM, bagg_MSE_RF, bagg_MSE_SVR, bagg_MSE_XGB)
df <- data.frame(cbind(modeles, sans_bagg, avec_bagg)) # les 2 edernières variables sont facteur
# convertir en numéric
for (i in 2:3) {  df[, i] <- as.numeric(as.character(df[, i])) }
str(df) # y en numerique

library(lattice)
barchart(sans_bagg+avec_bagg~ modeles, data = df, auto.key= T) 

# la bagging n'améliore pas les MSE. Donc nous ne le presenterons pas et ne le generaliserons pas aux autres pays

```


## comparaison R² ajuste
```{r}
RL_NL_sum <-summary(RL_NL)
Radj_RL <- RL_NL_sum$adj.r.squared

RLI_NL_sum <-summary(RLI_NL)
Radj_RLI <- RLI_NL_sum$adj.r.squared

RLI_NL_multi_sum <-summary(RLI_NL_multi)
Radj_RLI_multi <- RLI_NL_multi_sum$adj.r.squared

RLI_NL_P2_sum <-summary(RLI_NL_P2)
Radj_RLI_P2 <- RLI_NL_P2_sum$adj.r.squared

POLY_NL_sum <-summary(POLY_NL)
Radj_POLY <- POLY_NL_sum$adj.r.squared

SP_NL_sum <-summary(SP_NL)
Radj_SP <- SP_NL_sum$adj.r.squared

GAM_NL_SP_sum <-summary(GAM_NL_SP)
Radj_GAM <- GAM_NL_SP_sum$adj.r.squared

# calcul pour R² ajuste pour RF
Rsq_RF <- mean(RF_NL_fin$rsq)
n <-nrow(don.train) # nombre d'observation
k <- ncol(don.train) # nombre de variables explicatives utilisées dans le modèle
Radj_RF <- 1-( (1-Rsq_RF)*(n-1)/(n-k-1))



# total
Radj_tot=c(Radj_RL,Radj_RLI, Radj_RLI_multi, Radj_RLI_P2, Radj_POLY, Radj_SP, Radj_GAM_SP, Radj_RF)
max_Radj <- which.max(Radj_tot)

# graphe des Radj
graph<-barplot(Radj_tot, xlab="modeles", ylab="R2 adj", main="R2 adj des modeles",las=0, col=ifelse(Radj_tot==Radj_tot[max_Radj], "red", "blue"), ylim = c(0.88, 1))
axis(1, labels=c("RL", "RLI","multi", "P2" ,"Poly" ,"SP", "GAM" ,"RF"), at = graph)
 
# c'est le modèle RLI_multi (interactions multiples entre Temp+lags de Temp et les autres variables de date)
# 
```






