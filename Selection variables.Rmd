---
title: "Selection variables"
author: "Nhu-Nguyen"
date: "2 avril 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



SELECTION DE VARIABLES AVEC REGSUBSET
```{r}

#install.packages('leaps')
#install.packages('ISLR')
library(ISLR)
library(leaps)

# Creation de l'echantillon test, 2/3 individus
set.seed(123)
dim<-nrow(don)
train=sample(dim,2*dim/3,replace=FALSE)# vecteur d'entier pour la population d'individus en base d'apprentissage
test=model.matrix(Y~.,data=don[-train,])# base de test

p=ncol(don) # nombre de variables explicatives
p

#---- SELECTION EXHAUSTIVE: A EVITER SI P GRAND !! (ex 30)
# On va obtenir 2^p modeles comprenant entre une et p variables
# par défaut, le nombre de variable est 8. Préciser le nombre de variables avec nvmax
best_full=regsubsets(Y~.,data=don[train,],nvmax=p,method='exhaustive')

# choisir les meilleures variables: evaluer chacun des modeles sur le test set et calculer la MSE
mse.full=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_full,id=i)
  pred=test[,names(coefi)]%*%coefi
  mse.full[i]=mean((don$Y[-train]-pred)^2)
}

# plot les RMSE des modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.full),ylab='Root MSE des p modeles',pch=19,type='b')

# Pour acceder aux coefficient du modele avec la RMSE la plus petite (à renseigner), on appelle la fonction coeff
# Pour acceder aux RSS des mod?les, on lance la fonction summary
coef(best_full,6)
summary(best_full)$rss


#---- FORWARD SELECTION: NB pas assuré d'avoir le modèle optimal, mais possible si n<p
best_fw=regsubsets(Y~.,data=don[train,],nvmax=p,method='forward')
fw_sum<-summary(best_fw)

# pour chacun des modeles sur le test set, calculer la MSE
mse.fw=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_fw,id=i)
  pred=test[,names(coefi)]%*%coefi
  mse.fw[i]=mean((don$Y[-train]-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.fw),ylab='Root MSE des p modeles FW',pch=19,type='b')


# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables à la place de 2)
# Pour acceder aux RSS des mod?les, on lance la fonction summary
coef(best_fw,6)
fw_sum
fw_sum$rss

# selection variables BACKWARD: NB pas assuré d'avoir le modèle optimal,pas possible si n<p
best_bw=regsubsets(Y~.,data=don[train,],nvmax=p,method='backward')
sum_bw<-summary(best_bw)

# pour chacun des modeles sur le test set, calculer la MSE
mse.bw=rep(NA,p)
for(i in 1:p){
  coefi=coef(best_bw,id=i)
  pred=test[,names(coefi)]%*%coefi
  mse.bw[i]=mean((don$Y[-train]-pred)^2)
}

# on plot les RMSE des p modeles sur le training et sur le test set
# On choisit le modele qui a la RMSE la plus petite sur le test set
plot(sqrt(mse.bw),ylab='Root MSE des p modeles',pch=19,type='b') 


# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables à la place de 2)
# Pour acceder aux RSS des modeles, on lance la fonction summary
coef(best_bw,6)
sum_bw$rss


# plot des RMSE pour tous les modèles
x=c(1:p)
x
y1=sqrt(mse.full)
y2=sqrt(mse.fw)
y3=sqrt(mse.bw)
plot(x, y1, type = "l", ylim = range(c(y1, y2)), xlab = "nb de variables", ylab = "")
lines(x, y1, col = "blue")
lines(x, y2, col = "red")
lines(x, y3, col = "green")  #### PB on obtient des résultats identiqueS pour les 3 modèles !!!

# library(lattice)
# xyplot(y1 + y2 ~ x, type = "l", col = c("blue", "red"), xlab = "", ylab = "")


# Pour acceder aux coefficient du meilleur modele (en renseignant le nb de variables à la place de 6)
# Pour acceder aux RSS des modeles, on lance la fonction summary
coef(best_full,6)
coef(best_fw,6)
coef(best_bw,6)

sum_full<-summary(best_full)
sum_fw<-summary(best_fw)
sum_bw<-summary(best_bw)

summary(best_models_p)$rss #### PB on obtient des résultats identique pour les 3 modèles !!!
summary(best_models_fw)$rss
summary(best_models_bw)$rss

plot(best_full, scale="bic") # graphe BIC autre: “Cp”, “adjr2”, “r2". classification des valeurs de BIC selon les modèles, en haut la plus petite valeur de BIC et en noir les variables inclusent dans le modèle
# Le $R^2$ ajusté permet de déterminer à quel point le modèle ajuste vos données lorsque vous souhaitez l'ajuster en fonction du nombre de prédicteurs inclus. La valeur du $R^2$ ajusté intègre le nombre de prédicteurs dans le modèle elle donc plus adaptée pour nous aider à choisir le modèle.

plot(best_full, scale="adjr2")

# par(mfrow=c(2,2))
# plot(sum_full$rss,xlab="nb de variables", ylab="RSS")
# plot(sum_full$adjr2,xlab="nb de variables", ylab="Adjusted Rsq")



######################## TD
# Afin de nous aider à choisir le modèle à sélectionner, identifiez l'emplacement du point maximum / minimum pour chaque critère : $RSS$, $R^2$ ajusté, $C_p$ et $BIC$. Dans chaque cas, afficher les variables sélectionnées.
reg.summary<-sum_full

min.rss <- which.min(reg.summary$rss)
max.adjr2 <- which.max(reg.summary$adjr2)
min.cp <- which.min(reg.summary$cp)
min.bic <- which.min(reg.summary$bic)
min.rss
max.adjr2
min.cp
min.bic
names(which(reg.summary$which[min.rss,]==TRUE))
names(which(reg.summary$which[max.adjr2,]==TRUE))
names(which(reg.summary$which[min.cp,]==TRUE))
names(which(reg.summary$which[min.bic,]==TRUE))

# Sur une même fenêtre graphique représenter les courbes des différents critère. Ajouter sur chaque courbe, le maximum/minimum correspondant.

par(mfrow =c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
points(min.rss,reg.summary$rss[min.rss],col ="red",cex =2, pch =20)
plot(reg.summary$adjr2,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(max.adjr2,reg.summary$adjr2[max.adjr2],col ="red",cex =2, pch =20)
plot(reg.summary$cp,xlab="Number of Variables ",ylab="Cp",type="l")
points(min.cp,reg.summary$cp[min.cp],col ="red",cex =2, pch =20)
plot(reg.summary$bic,xlab="Number of Variables ",ylab="BIC",type="l")
points(min.bic,reg.summary$bic[min.bic],col ="red",cex =2, pch =20)

```




SELECTION VARIABLES AVEC BESTGLM
```{r}
# avec criteres AIC et BIC
# Cp et AIC sont proportionnels
# BIC pénalise plus fortement les modèles avec beaucoup de variables que AIC (pour n>7)

library(bestglm)

#enlever les variables avec des factors de plus de deux niveaux
ind.quant <- sapply(don, function(x) is.numeric(x) | is.integer(x))
ind.qual <- sapply(don, function(x) is.factor(x))

# variables quantitative
don.quant <- don[ ,ind.quant]

# variables qualitative
don.qual <- don[ ,ind.qual]

# Attention ici on doit mettre la variable a expliquer Y cible dans don en dernier
#nb=which(colnames(don) == "Y") renvoi le numéro de la colonne de Y
Y=don.quant[,which(colnames(don.quant) == "Y")]
X=don.quant[,-which(colnames(don.quant) == "Y")]
data=cbind(X,Y)
# base de données data XY avec Y cible à la fin

# Selection FORWARD avec critere AIC
sel_AIC_fw=bestglm(data,family=gaussian,IC="AIC",method="forward")
attributes(sel_AIC_fw)
sel_AIC_fw$BestModels
sel_AIC_fw$BestModel # variables retenues meteo, tmoy2 et tmoy7

# Selection FORWARD avec critere BIC
sel_BIC_fw=bestglm(data,family=gaussian,IC="BIC",method="forward")
attributes(sel_BIC_fw)
sel_BIC_fw$BestModels
sel_BIC_fw$BestModel # variables retenues meteo et tmoy7


# Selection BACKWARD avec critere AIC
sel_AIC_bw=bestglm(data,family=gaussian,IC="AIC",method="backward")
attributes(sel_AIC_bw)
sel_AIC_bw$BestModels
sel_AIC_bw$BestModel # variables retenues meteo, tmoy2 et tmoy7


# Selection BACKWARD avec critere BIC
sel_BIC_bw<-bestglm(data,family=gaussian,IC="BIC",method="backward")
sel_BIC_bw$BestModels
sel_BIC_bw$BestModel # variables retenues meteo, tmoy7


# Selection EXHAUSTIVE avec critere BIC
sel_BIC_exh=bestglm(data,family=gaussian,IC="BIC")
attributes(sel_BIC_exh)
sel_BIC_exh$BestModels
sel_BIC_exh$BestModel # variables retenues meteo, tmoy7

# Selection avec critere LOOCV
sel_LOOCV=bestglm(data,family=gaussian,IC="LOOCV")
attributes(sel_LOOCV)
sel_LOOCV$BestModels
sel_LOOCV$BestModel # variables retenues meteo, tmoy7

# Selection exhaustive avecVALIDATION CROISEE 10 blocs 
sel.cv<-bestglm(data,family=gaussian,
        IC="CV",CVArgs=list(Method="HTF",K=10,REP=1))
attributes(sel.cv)
sel.cv$BestModels
sel.cv$BestModel # variablesretenue meteo

# Attention : on utisera pour la VC plutot la fonction train du package caret
library(caret)

```

